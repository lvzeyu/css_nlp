{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMSの応用(2)：LangchaiによるAgentの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[LangChain](https://www.langchain.com/)は大規模言語モデルの機能拡張を効率的に実装するためのライブラリです。\n",
    "\n",
    "- ```llms```: 言語モデルを呼び出すためのラッパーを提供します\n",
    "- ```prompts```: プロンプトのテンプレートを作成する機能を提供します\n",
    "- ```chains```: ひとつのワークフロー内で LLM やプロンプトテンプレートを組み合わせて使用するための機能を提供します\n",
    "- ```agents```: エージェントを使用することで、課題の解決順序をも LLM を用いて決定し、実行させることができます\n",
    "- ```memory```: チェーンとエージェントに状態を持たせるための機能を提供します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.1.12\n",
      "  Using cached langchain-0.1.12-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain==0.1.12) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain==0.1.12) (2.0.45)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain==0.1.12) (3.10.8)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain==0.1.12) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain==0.1.12) (1.33)\n",
      "Collecting langchain-community<0.1,>=0.0.28 (from langchain==0.1.12)\n",
      "  Using cached langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.31 (from langchain==0.1.12)\n",
      "  Using cached langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.12)\n",
      "  Using cached langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.12)\n",
      "  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain==0.1.12) (1.26.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain==0.1.12) (2.12.5)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain==0.1.12) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain==0.1.12) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12) (1.13.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.12) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.12) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.12) (3.0.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.31->langchain==0.1.12) (23.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.12) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.12) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.12) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.1.12) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.1.12) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.1.12) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.1.12) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.1.12) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.1.12) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.1.12) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.1.12) (2024.8.30)\n",
      "Requirement already satisfied: greenlet>=1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.12) (3.3.0)\n",
      "Requirement already satisfied: anyio in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.12) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.12) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.12) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.12) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.12) (1.3.1)\n",
      "Using cached langchain-0.1.12-py3-none-any.whl (809 kB)\n",
      "Using cached langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "Using cached langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
      "Using cached langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
      "Using cached langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Installing collected packages: langsmith, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.6.4\n",
      "    Uninstalling langsmith-0.6.4:\n",
      "      Successfully uninstalled langsmith-0.6.4\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 1.2.7\n",
      "    Uninstalling langchain-core-1.2.7:\n",
      "      Successfully uninstalled langchain-core-1.2.7\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 1.1.0\n",
      "    Uninstalling langchain-text-splitters-1.1.0:\n",
      "      Successfully uninstalled langchain-text-splitters-1.1.0\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.4.1\n",
      "    Uninstalling langchain-community-0.4.1:\n",
      "      Successfully uninstalled langchain-community-0.4.1\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 1.2.6\n",
      "    Uninstalling langchain-1.2.6:\n",
      "      Successfully uninstalled langchain-1.2.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langgraph-prebuilt 1.0.6 requires langchain-core>=1.0.0, but you have langchain-core 0.1.53 which is incompatible.\n",
      "langgraph-checkpoint 4.0.0 requires langchain-core>=0.2.38, but you have langchain-core 0.1.53 which is incompatible.\n",
      "langchain-classic 1.0.1 requires langchain-core<2.0.0,>=1.2.5, but you have langchain-core 0.1.53 which is incompatible.\n",
      "langchain-classic 1.0.1 requires langchain-text-splitters<2.0.0,>=1.1.0, but you have langchain-text-splitters 0.0.2 which is incompatible.\n",
      "langchain-openai 1.1.7 requires langchain-core<2.0.0,>=1.2.6, but you have langchain-core 0.1.53 which is incompatible.\n",
      "langchain-experimental 0.4.1 requires langchain-community<1.0.0,>=0.4.0, but you have langchain-community 0.0.38 which is incompatible.\n",
      "langchain-experimental 0.4.1 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.1.53 which is incompatible.\n",
      "langchain-google-genai 4.2.0 requires langchain-core<2.0.0,>=1.2.5, but you have langchain-core 0.1.53 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-0.1.12 langchain-community-0.0.38 langchain-core-0.1.53 langchain-text-splitters-0.0.2 langsmith-0.1.147\n",
      "Requirement already satisfied: langchain-community in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (0.0.38)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community) (2.0.45)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community) (3.10.8)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community) (0.1.53)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community) (1.26.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.13.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain-community) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain-community) (2.12.5)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet>=1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: anyio in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.52->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.52->langchain-community) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.52->langchain-community) (0.4.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: langchain-core in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (0.1.53)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core) (0.1.147)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core) (2.12.5)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core) (8.5.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core) (3.11.5)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core) (0.4.2)\n",
      "Requirement already satisfied: anyio in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core) (4.8.0)\n",
      "Requirement already satisfied: certifi in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core) (0.14.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core) (2.2.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core) (1.3.1)\n",
      "Requirement already satisfied: langsmith in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (0.1.147)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith) (3.11.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith) (2.12.5)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith) (1.0.0)\n",
      "Requirement already satisfied: anyio in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (4.8.0)\n",
      "Requirement already satisfied: certifi in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3,>=2->langsmith) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3,>=2->langsmith) (2.2.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
      "Requirement already satisfied: openai in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (2.15.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai) (2.12.5)\n",
      "Requirement already satisfied: sniffio in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: langchain-openai in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (1.1.7)\n",
      "Collecting langchain-core<2.0.0,>=1.2.6 (from langchain-openai)\n",
      "  Using cached langchain_core-1.2.7-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-openai) (2.15.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.33)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.2.6->langchain-openai)\n",
      "  Using cached langsmith-0.6.4-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.13.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.66.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.5)\n",
      "Requirement already satisfied: idna>=2.8 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.2.3)\n",
      "Using cached langchain_core-1.2.7-py3-none-any.whl (490 kB)\n",
      "Using cached langsmith-0.6.4-py3-none-any.whl (283 kB)\n",
      "Installing collected packages: langsmith, langchain-core\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.147\n",
      "    Uninstalling langsmith-0.1.147:\n",
      "      Successfully uninstalled langsmith-0.1.147\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.53\n",
      "    Uninstalling langchain-core-0.1.53:\n",
      "      Successfully uninstalled langchain-core-0.1.53\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-classic 1.0.1 requires langchain-text-splitters<2.0.0,>=1.1.0, but you have langchain-text-splitters 0.0.2 which is incompatible.\n",
      "langchain-text-splitters 0.0.2 requires langchain-core<0.3,>=0.1.28, but you have langchain-core 1.2.7 which is incompatible.\n",
      "langchain-community 0.0.38 requires langchain-core<0.2.0,>=0.1.52, but you have langchain-core 1.2.7 which is incompatible.\n",
      "langchain-community 0.0.38 requires langsmith<0.2.0,>=0.1.0, but you have langsmith 0.6.4 which is incompatible.\n",
      "langchain-experimental 0.4.1 requires langchain-community<1.0.0,>=0.4.0, but you have langchain-community 0.0.38 which is incompatible.\n",
      "langchain 0.1.12 requires langchain-core<0.2.0,>=0.1.31, but you have langchain-core 1.2.7 which is incompatible.\n",
      "langchain 0.1.12 requires langsmith<0.2.0,>=0.1.17, but you have langsmith 0.6.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-core-1.2.7 langsmith-0.6.4\n",
      "Requirement already satisfied: python-dotenv in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (1.2.1)\n",
      "Requirement already satisfied: langchain-openai in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (1.1.7)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.6 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-openai) (1.2.7)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-openai) (2.15.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.6.4)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.13.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.66.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.5)\n",
      "Requirement already satisfied: idna>=2.8 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.2.3)\n",
      "Requirement already satisfied: langchain in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (0.1.12)\n",
      "Collecting langchain\n",
      "  Using cached langchain-1.2.6-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: langchain-core in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (1.2.7)\n",
      "Requirement already satisfied: langchain-community in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (0.0.38)\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pydantic in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (2.12.5)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain) (1.0.6)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core) (0.6.4)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core) (0.13.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community) (2.0.45)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community) (3.10.8)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community) (1.26.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.13.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
      "  Using cached langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.6)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.5.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet>=1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
      "Requirement already satisfied: anyio in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.14.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.3.1)\n",
      "Using cached langchain-1.2.6-py3-none-any.whl (108 kB)\n",
      "Using cached langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "Using cached langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.0.2\n",
      "    Uninstalling langchain-text-splitters-0.0.2:\n",
      "      Successfully uninstalled langchain-text-splitters-0.0.2\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.0.38\n",
      "    Uninstalling langchain-community-0.0.38:\n",
      "      Successfully uninstalled langchain-community-0.0.38\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.1.12\n",
      "    Uninstalling langchain-0.1.12:\n",
      "      Successfully uninstalled langchain-0.1.12\n",
      "Successfully installed langchain-1.2.6 langchain-community-0.4.1 langchain-text-splitters-1.1.0\n",
      "Requirement already satisfied: google-generativeai in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (0.8.6)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-generativeai) (2.29.0)\n",
      "Requirement already satisfied: google-api-python-client in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-generativeai) (2.188.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-generativeai) (2.47.0)\n",
      "Requirement already satisfied: protobuf in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-generativeai) (5.28.2)\n",
      "Requirement already satisfied: pydantic in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-generativeai) (2.12.5)\n",
      "Requirement already satisfied: tqdm in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-generativeai) (4.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.27.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.31.1)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.3.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic->google-generativeai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Requirement already satisfied: google-search-results in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (2.4.2)\n",
      "Requirement already satisfied: numexpr in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (2.14.1)\n",
      "Requirement already satisfied: wikipedia in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: langchain-experimental in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (0.4.1)\n",
      "Requirement already satisfied: requests in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from google-search-results) (2.32.5)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from numexpr) (1.26.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from wikipedia) (4.14.3)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-experimental) (1.2.7)\n",
      "Requirement already satisfied: langchain-community<1.0.0,>=0.4.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-experimental) (0.4.1)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.0.45)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.10.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.6.4)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.4.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-experimental) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-experimental) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-experimental) (2.12.5)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-experimental) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-experimental) (0.13.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests->google-search-results) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests->google-search-results) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests->google-search-results) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from requests->google-search-results) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from beautifulsoup4->wikipedia) (2.8.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.13.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-experimental) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-experimental) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-experimental) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.2.1)\n",
      "Requirement already satisfied: greenlet>=1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.3.0)\n",
      "Requirement already satisfied: anyio in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.3.1)\n",
      "Requirement already satisfied: duckduckgo-search in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (8.1.1)\n",
      "Requirement already satisfied: click>=8.1.8 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from duckduckgo-search) (8.1.8)\n",
      "Requirement already satisfied: primp>=0.15.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from duckduckgo-search) (0.15.0)\n",
      "Requirement already satisfied: lxml>=5.3.0 in /home/lvzeyu/anaconda3/envs/llm-ft/lib/python3.11/site-packages (from duckduckgo-search) (6.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.1.12\n",
    "!pip install langchain-community\n",
    "!pip install langchain-core\n",
    "!pip install langsmith\n",
    "!pip install openai\n",
    "!pip install -U langchain-openai\n",
    "!pip install python-dotenv\n",
    "!pip install langchain-openai\n",
    "!pip install -U --quiet langchain-google-genai pillow\n",
    "!pip install -U langchain langchain-core langchain-community pydantic\n",
    "!pip install google-generativeai\n",
    "!pip install google-search-results numexpr wikipedia langchain-experimental\n",
    "!pip install duckduckgo-search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI/Gemini API\n",
    "\n",
    "[OpenAI](https://openai.com/blog/openai-api)と[Google(Gemini)](https://deepmind.google/technologies/gemini/#introduction)が提供するAPIを通じて、多岐にわたるAIモデルへのアクセスを可能になります。\n",
    "\n",
    "APIを使うためには、まず「自分がサービスを利用できる証」となる「APIキー」を発行する必要があります。そして、OpenAIのAPIは、このAPIキーによって利用した使用量に応じて、課金される仕組みです。\n",
    "\n",
    "そのため、APIキーが外部に漏れると、他者によって不正に使用されて料金が発生してしまうため、他の人へ共有しないように注意しましょう。\n",
    "\n",
    "LangChainは、さまざまな LLM に汎用インターフェースを提供し、ユーザーがAPIを介してさまざまなモデルを操作できるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import getpass\n",
    "from langchain_openai import OpenAI, ChatOpenAI     \n",
    "\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI API\n",
    "\n",
    "`OpenAI`クラスのインスタンスでGPT-3モデルを使用するための設定を行っています。\n",
    "\n",
    "- `model_name'という引数で、使用する[モデルの名前](https://platform.openai.com/docs/models)を指定します。\n",
    "\n",
    "\n",
    "- `temperature`という引数は、生成されるテキストのランダム性を制御します。`temperature`が高いほど（1に近いほど）、出力はよりランダムになります。逆に、`temperature`が低いほど（0に近いほど）、モデルの出力はより一貫性があり、予測可能になります。\n",
    "\n",
    "- `max_tokens`という引数は、生成するテキストの最大トークン数を指定します。この場合、生成されるテキストは最大で256トークンになります。トークンとは、テキストを分割した単位のことで、一般的には単語や句読点などが1トークンとなります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0.9,\n",
    "    max_tokens=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n東北大学は日本の北東部、仙台市にある国立大学です。東日本大震災の被災地でもあるこの地域において、復興や災害対策などの研究を積極的に行っていることでも知られています。また、東北大学は日本の国立大学では唯一の理工系大学として、理学部、工学部、医学部、農学部の4つの学部で構成されています。\\n\\n東北大学は、全国トップクラスの実験・研究施設を有しており、研究者や学生が活発に研究を行う環境が整っています。特に、地震・津波・火山活動など自然災害に関する研究は世界的に評価が高く、国内外から多くの研究者が集まっています。\\n\\n学生生活においても、さまざまなサークルや部活動が充実しており、学生同士の交流や自己表現の場として活用されています。また、海外大学との交流や留学制度も充実しており、国際的な視野を持ったグローバル人材の育成にも力を入れています。\\n\\nその他にも、東北大学では若手研究者の支援や女性研究者の活躍促進など、幅広い取り組みが行われています。さまざまな分野で活躍する卒業生を輩出しているだけでなく、社会貢献や社会問'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"東北大学を紹介してください：\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini API\n",
    "\n",
    "#### Gemini APIの設定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_146531/3039597036.py:1: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Model(name='models/embedding-gecko-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Embedding Gecko',\n",
       "       description='Obtain a distributed representation of a text.',\n",
       "       input_token_limit=1024,\n",
       "       output_token_limit=1,\n",
       "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/gemini-2.5-flash',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 2.5 Flash',\n",
       "       description=('Stable version of Gemini 2.5 Flash, our mid-size multimodal model that '\n",
       "                    'supports up to 1 million tokens, released in June of 2025.'),\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-pro',\n",
       "       base_model_id='',\n",
       "       version='2.5',\n",
       "       display_name='Gemini 2.5 Pro',\n",
       "       description='Stable release (June 17th, 2025) of Gemini 2.5 Pro',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.0-flash-exp',\n",
       "       base_model_id='',\n",
       "       version='2.0',\n",
       "       display_name='Gemini 2.0 Flash Experimental',\n",
       "       description='Gemini 2.0 Flash Experimental',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-2.0-flash',\n",
       "       base_model_id='',\n",
       "       version='2.0',\n",
       "       display_name='Gemini 2.0 Flash',\n",
       "       description='Gemini 2.0 Flash',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-2.0-flash-001',\n",
       "       base_model_id='',\n",
       "       version='2.0',\n",
       "       display_name='Gemini 2.0 Flash 001',\n",
       "       description=('Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model '\n",
       "                    'for scaling across diverse tasks, released in January of 2025.'),\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-2.0-flash-exp-image-generation',\n",
       "       base_model_id='',\n",
       "       version='2.0',\n",
       "       display_name='Gemini 2.0 Flash (Image Generation) Experimental',\n",
       "       description='Gemini 2.0 Flash (Image Generation) Experimental',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-2.0-flash-lite-001',\n",
       "       base_model_id='',\n",
       "       version='2.0',\n",
       "       display_name='Gemini 2.0 Flash-Lite 001',\n",
       "       description='Stable version of Gemini 2.0 Flash-Lite',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-2.0-flash-lite',\n",
       "       base_model_id='',\n",
       "       version='2.0',\n",
       "       display_name='Gemini 2.0 Flash-Lite',\n",
       "       description='Gemini 2.0 Flash-Lite',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-2.0-flash-lite-preview-02-05',\n",
       "       base_model_id='',\n",
       "       version='preview-02-05',\n",
       "       display_name='Gemini 2.0 Flash-Lite Preview 02-05',\n",
       "       description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-2.0-flash-lite-preview',\n",
       "       base_model_id='',\n",
       "       version='preview-02-05',\n",
       "       display_name='Gemini 2.0 Flash-Lite Preview',\n",
       "       description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-exp-1206',\n",
       "       base_model_id='',\n",
       "       version='2.5-exp-03-25',\n",
       "       display_name='Gemini Experimental 1206',\n",
       "       description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-flash-preview-tts',\n",
       "       base_model_id='',\n",
       "       version='gemini-2.5-flash-exp-tts-2025-05-19',\n",
       "       display_name='Gemini 2.5 Flash Preview TTS',\n",
       "       description='Gemini 2.5 Flash Preview TTS',\n",
       "       input_token_limit=8192,\n",
       "       output_token_limit=16384,\n",
       "       supported_generation_methods=['countTokens', 'generateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-pro-preview-tts',\n",
       "       base_model_id='',\n",
       "       version='gemini-2.5-pro-preview-tts-2025-05-19',\n",
       "       display_name='Gemini 2.5 Pro Preview TTS',\n",
       "       description='Gemini 2.5 Pro Preview TTS',\n",
       "       input_token_limit=8192,\n",
       "       output_token_limit=16384,\n",
       "       supported_generation_methods=['countTokens', 'generateContent', 'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemma-3-1b-it',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemma 3 1B',\n",
       "       description='',\n",
       "       input_token_limit=32768,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=None,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemma-3-4b-it',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemma 3 4B',\n",
       "       description='',\n",
       "       input_token_limit=32768,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=None,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemma-3-12b-it',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemma 3 12B',\n",
       "       description='',\n",
       "       input_token_limit=32768,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=None,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemma-3-27b-it',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemma 3 27B',\n",
       "       description='',\n",
       "       input_token_limit=131072,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=None,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemma-3n-e4b-it',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemma 3n E4B',\n",
       "       description='',\n",
       "       input_token_limit=8192,\n",
       "       output_token_limit=2048,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=None,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemma-3n-e2b-it',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemma 3n E2B',\n",
       "       description='',\n",
       "       input_token_limit=8192,\n",
       "       output_token_limit=2048,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=None,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-flash-latest',\n",
       "       base_model_id='',\n",
       "       version='Gemini Flash Latest',\n",
       "       display_name='Gemini Flash Latest',\n",
       "       description='Latest release of Gemini Flash',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-flash-lite-latest',\n",
       "       base_model_id='',\n",
       "       version='Gemini Flash-Lite Latest',\n",
       "       display_name='Gemini Flash-Lite Latest',\n",
       "       description='Latest release of Gemini Flash-Lite',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-pro-latest',\n",
       "       base_model_id='',\n",
       "       version='Gemini Pro Latest',\n",
       "       display_name='Gemini Pro Latest',\n",
       "       description='Latest release of Gemini Pro',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-flash-lite',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 2.5 Flash-Lite',\n",
       "       description='Stable version of Gemini 2.5 Flash-Lite, released in July of 2025',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-flash-image',\n",
       "       base_model_id='',\n",
       "       version='2.0',\n",
       "       display_name='Nano Banana',\n",
       "       description='Gemini 2.5 Flash Preview Image',\n",
       "       input_token_limit=32768,\n",
       "       output_token_limit=32768,\n",
       "       supported_generation_methods=['generateContent', 'countTokens', 'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-flash-preview-09-2025',\n",
       "       base_model_id='',\n",
       "       version='Gemini 2.5 Flash Preview 09-2025',\n",
       "       display_name='Gemini 2.5 Flash Preview Sep 2025',\n",
       "       description='Gemini 2.5 Flash Preview Sep 2025',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-flash-lite-preview-09-2025',\n",
       "       base_model_id='',\n",
       "       version='2.5-preview-09-25',\n",
       "       display_name='Gemini 2.5 Flash-Lite Preview Sep 2025',\n",
       "       description='Preview release (Septempber 25th, 2025) of Gemini 2.5 Flash-Lite',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-3-pro-preview',\n",
       "       base_model_id='',\n",
       "       version='3-pro-preview-11-2025',\n",
       "       display_name='Gemini 3 Pro Preview',\n",
       "       description='Gemini 3 Pro Preview',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-3-flash-preview',\n",
       "       base_model_id='',\n",
       "       version='3-flash-preview-12-2025',\n",
       "       display_name='Gemini 3 Flash Preview',\n",
       "       description='Gemini 3 Flash Preview',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-3-pro-image-preview',\n",
       "       base_model_id='',\n",
       "       version='3.0',\n",
       "       display_name='Nano Banana Pro',\n",
       "       description='Gemini 3 Pro Image Preview',\n",
       "       input_token_limit=131072,\n",
       "       output_token_limit=32768,\n",
       "       supported_generation_methods=['generateContent', 'countTokens', 'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/nano-banana-pro-preview',\n",
       "       base_model_id='',\n",
       "       version='3.0',\n",
       "       display_name='Nano Banana Pro',\n",
       "       description='Gemini 3 Pro Image Preview',\n",
       "       input_token_limit=131072,\n",
       "       output_token_limit=32768,\n",
       "       supported_generation_methods=['generateContent', 'countTokens', 'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-robotics-er-1.5-preview',\n",
       "       base_model_id='',\n",
       "       version='1.5-preview',\n",
       "       display_name='Gemini Robotics-ER 1.5 Preview',\n",
       "       description='Gemini Robotics-ER 1.5 Preview',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-computer-use-preview-10-2025',\n",
       "       base_model_id='',\n",
       "       version='Gemini 2.5 Computer Use Preview 10-2025',\n",
       "       display_name='Gemini 2.5 Computer Use Preview 10-2025',\n",
       "       description='Gemini 2.5 Computer Use Preview 10-2025',\n",
       "       input_token_limit=131072,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/deep-research-pro-preview-12-2025',\n",
       "       base_model_id='',\n",
       "       version='deepthink-exp-05-20',\n",
       "       display_name='Deep Research Pro Preview (Dec-12-2025)',\n",
       "       description='Preview release (December 12th, 2025) of Deep Research Pro',\n",
       "       input_token_limit=131072,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/embedding-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Embedding 001',\n",
       "       description='Obtain a distributed representation of a text.',\n",
       "       input_token_limit=2048,\n",
       "       output_token_limit=1,\n",
       "       supported_generation_methods=['embedContent'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/text-embedding-004',\n",
       "       base_model_id='',\n",
       "       version='004',\n",
       "       display_name='Text Embedding 004',\n",
       "       description='Obtain a distributed representation of a text.',\n",
       "       input_token_limit=2048,\n",
       "       output_token_limit=1,\n",
       "       supported_generation_methods=['embedContent'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/gemini-embedding-exp-03-07',\n",
       "       base_model_id='',\n",
       "       version='exp-03-07',\n",
       "       display_name='Gemini Embedding Experimental 03-07',\n",
       "       description='Obtain a distributed representation of a text.',\n",
       "       input_token_limit=8192,\n",
       "       output_token_limit=1,\n",
       "       supported_generation_methods=['embedContent', 'countTextTokens', 'countTokens'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/gemini-embedding-exp',\n",
       "       base_model_id='',\n",
       "       version='exp-03-07',\n",
       "       display_name='Gemini Embedding Experimental',\n",
       "       description='Obtain a distributed representation of a text.',\n",
       "       input_token_limit=8192,\n",
       "       output_token_limit=1,\n",
       "       supported_generation_methods=['embedContent', 'countTextTokens', 'countTokens'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/gemini-embedding-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini Embedding 001',\n",
       "       description='Obtain a distributed representation of a text.',\n",
       "       input_token_limit=2048,\n",
       "       output_token_limit=1,\n",
       "       supported_generation_methods=['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/aqa',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Model that performs Attributed Question Answering.',\n",
       "       description=('Model trained to return answers to questions that are grounded in provided '\n",
       "                    'sources, along with estimating answerable probability.'),\n",
       "       input_token_limit=7168,\n",
       "       output_token_limit=1024,\n",
       "       supported_generation_methods=['generateAnswer'],\n",
       "       temperature=0.2,\n",
       "       max_temperature=None,\n",
       "       top_p=1.0,\n",
       "       top_k=40),\n",
       " Model(name='models/imagen-4.0-generate-preview-06-06',\n",
       "       base_model_id='',\n",
       "       version='01',\n",
       "       display_name='Imagen 4 (Preview)',\n",
       "       description='Vertex served Imagen 4.0 model',\n",
       "       input_token_limit=480,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['predict'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/imagen-4.0-ultra-generate-preview-06-06',\n",
       "       base_model_id='',\n",
       "       version='01',\n",
       "       display_name='Imagen 4 Ultra (Preview)',\n",
       "       description='Vertex served Imagen 4.0 ultra model',\n",
       "       input_token_limit=480,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['predict'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/imagen-4.0-generate-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Imagen 4',\n",
       "       description='Vertex served Imagen 4.0 model',\n",
       "       input_token_limit=480,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['predict'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/imagen-4.0-ultra-generate-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Imagen 4 Ultra',\n",
       "       description='Vertex served Imagen 4.0 ultra model',\n",
       "       input_token_limit=480,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['predict'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/imagen-4.0-fast-generate-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Imagen 4 Fast',\n",
       "       description='Vertex served Imagen 4.0 Fast model',\n",
       "       input_token_limit=480,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['predict'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/veo-2.0-generate-001',\n",
       "       base_model_id='',\n",
       "       version='2.0',\n",
       "       display_name='Veo 2',\n",
       "       description=('Vertex served Veo 2 model. Access to this model requires billing to be '\n",
       "                    'enabled on the associated Google Cloud Platform account. Please visit '\n",
       "                    'https://console.cloud.google.com/billing to enable it.'),\n",
       "       input_token_limit=480,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['predictLongRunning'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/veo-3.0-generate-001',\n",
       "       base_model_id='',\n",
       "       version='3.0',\n",
       "       display_name='Veo 3',\n",
       "       description='Veo 3',\n",
       "       input_token_limit=480,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['predictLongRunning'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/veo-3.0-fast-generate-001',\n",
       "       base_model_id='',\n",
       "       version='3.0',\n",
       "       display_name='Veo 3 fast',\n",
       "       description='Veo 3 fast',\n",
       "       input_token_limit=480,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['predictLongRunning'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/veo-3.1-generate-preview',\n",
       "       base_model_id='',\n",
       "       version='3.1',\n",
       "       display_name='Veo 3.1',\n",
       "       description='Veo 3.1',\n",
       "       input_token_limit=480,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['predictLongRunning'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/veo-3.1-fast-generate-preview',\n",
       "       base_model_id='',\n",
       "       version='3.1',\n",
       "       display_name='Veo 3.1 fast',\n",
       "       description='Veo 3.1 fast',\n",
       "       input_token_limit=480,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['predictLongRunning'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/gemini-2.5-flash-native-audio-latest',\n",
       "       base_model_id='',\n",
       "       version='Gemini 2.5 Flash Native Audio Latest',\n",
       "       display_name='Gemini 2.5 Flash Native Audio Latest',\n",
       "       description='Latest release of Gemini 2.5 Flash Native Audio',\n",
       "       input_token_limit=131072,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['countTokens', 'bidiGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-flash-native-audio-preview-09-2025',\n",
       "       base_model_id='',\n",
       "       version='gemini-2.5-flash-preview-native-audio-dialog-2025-05-19',\n",
       "       display_name='Gemini 2.5 Flash Native Audio Preview 09-2025',\n",
       "       description='Gemini 2.5 Flash Native Audio Preview 09-2025',\n",
       "       input_token_limit=131072,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['countTokens', 'bidiGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-flash-native-audio-preview-12-2025',\n",
       "       base_model_id='',\n",
       "       version='12-2025',\n",
       "       display_name='Gemini 2.5 Flash Native Audio Preview 12-2025',\n",
       "       description='Gemini 2.5 Flash Native Audio Preview 12-2025',\n",
       "       input_token_limit=131072,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['countTokens', 'bidiGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "models = [m for m in genai.list_models()]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "llm = genai.GenerativeModel('models/gemini-2.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.generate_content(\"東北大学を紹介してください：\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "東北大学は、日本を代表する世界トップクラスの研究大学の一つで、旧帝国大学の一つとして確固たる地位を築いています。\n",
       "\n",
       "以下に東北大学の主な特徴をご紹介します。\n",
       "\n",
       "1.  **歴史と伝統**\n",
       "    *   1907年（明治40年）に東北帝国大学として創立され、100年以上の長い歴史と伝統を誇ります。\n",
       "    *   その創立の理念には、**「研究第一主義」「門戸開放」「実学尊重」**の3つがあります。特に「門戸開放」は、日本で初めて女子学生と外国人学生を受け入れた大学の一つであることからも象徴されます。\n",
       "\n",
       "2.  **立地**\n",
       "    *   宮城県仙台市に本部を置き、市内には青葉山、川内、片平、星陵の主要なキャンパスが点在しています。\n",
       "    *   「学都仙台」と呼ばれるように、仙台は多くの大学が集まる学生街であり、豊かな自然と都市機能が調和した、落ち着いて学べる恵まれた環境です。\n",
       "\n",
       "3.  **学術的卓越性**\n",
       "    *   理学、工学、医学、農学、文学、法学、経済学、教育学など、幅広い分野にわたる10学部と15研究科、多数の附置研究所・センターを擁しています。\n",
       "    *   **研究第一主義**の精神に基づき、物理学、材料科学、工学、医学、災害科学などの分野で世界レベルの研究成果を生み出しています。ノーベル賞受賞者や、各界で活躍する多くの優秀な人材を輩出してきました。\n",
       "    *   スーパーコンピュータ「青葉」など、最先端の研究設備も充実しています。\n",
       "\n",
       "4.  **国際性**\n",
       "    *   「門戸開放」の精神は現在も息づいており、世界各国からの留学生を積極的に受け入れ、国際共同研究や国際交流プログラムも活発に行われています。\n",
       "    *   世界の大学ランキングでも常に上位に位置し、国際的な評価も非常に高いです。\n",
       "\n",
       "5.  **特徴的な研究分野**\n",
       "    *   **材料科学：** 世界的に評価の高い研究拠点として知られ、新しい素材開発や応用研究で数々の実績を上げています。\n",
       "    *   **スピントロニクス：** 次世代の情報技術を支える分野で、世界をリードする研究が行われています。\n",
       "    *   **災害科学：** 東日本大震災の経験を基に、災害科学国際研究所を中心に、防災・減災に関する多角的な研究と人材育成を推進しています。\n",
       "    *   **医学・医療：** 地域の基幹病院である東北大学病院を中心に、最先端の医療研究と高度医療を提供しています。\n",
       "\n",
       "東北大学は、その伝統と革新性を兼ね備え、未来を切り開く研究と人材育成に貢献し続けている、まさに日本の知の拠点の一つと言えるでしょう。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "\n",
    "\n",
    "プロンプトテンプレートは、プロンプトを作成する再現可能な方法を指します。これには、エンドユーザーから一連のパラメーターを受け取り、プロンプトを生成するテキスト文字列(テンプレート)が含まれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"language\",\"text\"],\n",
    "    template=\"次の日本語のテキストを{language}に翻訳してください：{text}\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "次の日本語のテキストを英語に翻訳してください：東北大学は日本の東北地方にある大学です。\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(language=\"英語\", text=\"東北大学は日本の東北地方にある大学です。\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## チェーン\n",
    "\n",
    "### チェーンの基本\n",
    "\n",
    "LLM は単独でも十分に強力に機能します。 しかし、 LLM 同士を組合わせたり、ある機能に特化した他のモジュールとともに利用することで、より複雑なアプリケーションを構築することができます。 LangChain では、このような他の機能と連結するための汎用的なインターフェースとして、チェーンを提供しています。 チェーンを用いることで、LLM の利用を含む \"一連の処理\" を一つのまとまりとして扱うことができます。\n",
    "\n",
    "つまり、平易な言葉でいえば、チェーンは「複数の処理の連なり」です。 この処理の連鎖の部品となるチェーンの構成要素のことを リンク と呼びます。 リンクの一例は、LLM の呼び出しなどの基本的な処理です。さらには、その他のチェーン全体をリンクとして含むチェーンも作成できます。\n",
    "\n",
    "チェーンの代表例は、LLM とプロンプトテンプレートを組合わせて使用するための```LLMChain```です。 このチェーンを用いると、\n",
    "\n",
    "- ユーザーの入力を受け取り\n",
    "- それをPromptTemplateでフォーマットし\n",
    "- フォーマットされたレスポンスを LLM に渡す\n",
    "\n",
    "という一連の操作を一つのまとまりとして実行できます。 \n",
    "\n",
    "基本的な使い方としては、LLM や プロンプトテンプレートなどの基本要素を組み合わせて使用することが考えられます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\", google_api_key=os.getenv(\"GOOGLE_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Tohoku University is a university in the Tohoku region of Japan.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bde11-dd14-7761-9374-18542036a56a-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 21, 'output_tokens': 401, 'total_tokens': 422, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 387}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\"language\":\"英語\", \"text\":\"東北大学は日本の東北地方にある大学です。\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='東北大学是一所位于日本东北地方的大学。', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bde11-ebb3-7031-9805-95023682aaf7-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 22, 'output_tokens': 1321, 'total_tokens': 1343, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1310}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"language\":\"中国語\", \"text\":\"東北大学は日本の東北地方にある大学です。\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装例:Few Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"word\": \"楽しい\", \"antonym\": \"悲しい\"},\n",
    "    {\"word\": \"高い\", \"antonym\": \"低い\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_formatter_template = \"\"\"\n",
    "Word: {word}\n",
    "Antonym: {antonym}\\n\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\", \"antonym\"],\n",
    "    template=example_formatter_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- `examples`: モデルに示す例を指定します。\n",
    "- `example_prompt`: 例をどのように提示するかを指定します。\n",
    "- `prefix`: プロンプトの前置詞を指定します。一般的には、モデルにタスクを説明するためのものです。\n",
    "- `suffix`: プロンプトの後置詞を指定します。一般的には、モデルに入力と出力の形式を示すためのものです。\n",
    "- `input_variables`: 入力の変数名を指定します。\n",
    "- `example_separator`: 例を区切るための文字列を指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the antonym of every input\",\n",
    "    suffix=\"Word: {input}\\nAntonym:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Word: 楽しい\n",
      "Antonym: 悲しい\n",
      "\n",
      "\n",
      "\n",
      "Word: 高い\n",
      "Antonym: 低い\n",
      "\n",
      "\n",
      "Word: 大きい\n",
      "Antonym:\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format(input=\"大きい\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\", google_api_key=os.getenv(\"GOOGLE_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小さい\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = few_shot_prompt | llm | StrOutputParser()\n",
    "\n",
    "var = few_shot_prompt.input_variables[0] \n",
    "print(chain.invoke({var: \"大きい\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 課題\n",
    "\n",
    "Few Shot Learningでセンチメント分析を実装しなさい。\n",
    "\n",
    "- データフレームから一部のテキストとラベル($n=5$)を抽出し、`examples`を作成します\n",
    "- Few Shot Learningためのpromptを作成します\n",
    "- chainを作成し、任意のテキストに対するセンチメント予測結果を確認します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sample = dataset[\"train\"].to_pandas().sample(5, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "cb6a97b1-c48a-4ecd-b5d1-f4aef9efd271",
       "rows": [
        [
         "20000",
         "After reading some quite negative views for this movie, I was not sure whether I should fork out some money to rent it. However, it was a pleasant surprise. I haven't seen the original movie, but if its better than this, I'd be in heaven.<br /><br />Tom Cruise gives a strong performance as the seemingly unstable David, convincing me that he is more than a smile on legs (for only the third time in his career- the other examples were Magnolia and Born on the Fourth of July). Penelope Cruz is slightly lightweight but fills the demands for her role, as does Diaz. The only disappointment is the slightly bland Kurt Russell. In the movie, however, it is not the acting that really impresses- its the filmmaking.<br /><br />Cameron Crowe excels in the director's role, providing himself with a welcome change of pace from his usual schtick. The increasing insanity of the movie is perfectly executed by Crowe (the brief sequence where Cruise walks through an empty Time Square is incredibly effective). The soundtrack (a distinguishing feature of a Crowe movie) is also sublime.<br /><br />You will be shocked and challenged as a viewer. The plot does seem a little contrived but the issues explored behind it are endlessly discussable. The movie isn't perfect, but its a welcome change of pace for Cruise and Crowe and for those raised on a diet of Hollywood gloss, should be a revelation.",
         "1"
        ],
        [
         "5515",
         "Really no reason to examine this much further because of a few very glaring and bias misleading statements.<br /><br />A perfect example is when the filmmaker claims \"Saul\" or Paul of Tarus (the writer of The Book of Hebrews He asserts) has no idea Jesus is or was a human being, this assertion is either purposely false as he accuses others of presenting, or he is ignorant of what \"The Bible\" says.<br /><br />first we can examine his misleading claim about Hebrews 8.4; which he shows a quote \"If Jesus was on earth, he would not be a priest\", hence right here He sets up the ignorant and unlearned viewer to accept his false premise.. why? He does what most so called Bible believing people he accuses of doing, the same.. That is TAKING things out of context.<br /><br />verse one of Hebrews 8 is; 1..\"Now of the things which we have spoken this is the sum: We have such an high priest, who is set on the right hand of the throne of the Majesty in the heavens\" The context above is CLEARLY speaking of a Jesus who was on earth and ASCENDED into heaven after his alleged resurrection.<br /><br />It has nothing to do with how the filmmaker wants the viewer to take his out of context scripture. Here he offers a foundation, that \"Paul was not aware of a HUMAN Jesus, but only one in \"heaven\"<br /><br />follow?<br /><br />lets see if the filmmaker is being honest; Hebrews 7; 14. \"For it is evident that our Lord sprang out of Judah; of which tribe Moses spake nothing concerning priesthood.\"<br /><br />heh, didn't the filmmaker just quote from the writer of Hebrews trying to show the writer of that book has no knowledge of a \"Human Jesus\"? it's likely anyways Paul didn't write Hebrews, but I will not go into that here, but The film maker asserts Paul did, and that is the premise of the point given here.<br /><br />It is not like this film maker does not make decent points in certain areas, he does, but he is engaging in the same blind bias of the religion he is bashing on. Once he engages in these tactics, in my strong opinion, he loses credibility as the religion he picks out, and the film is no longer a documentary, but a personal opinion, and a bias of the film maker, nothing more, nothing less.",
         "0"
        ],
        [
         "966",
         "\"Happy Go Lovely\" has only two things going for it. And those two things are Vera-Ellen's legs. This is a British (Excelsior Films) version of an M-G-M musical complete with second tier stars. I would imagine that Vera-Ellen took this role thinking that it might finally propel her to the status of a major musical star. But, I'm sorry to say, Ms. Ellen's chance did not pay off.<br /><br />Opening with a horrible Scottish number and stumbling thru awful dialog to the next dull tune, this movie seems very heavy handed and sloppy. The predictable mistaken identity plot is very thin, and with the exception of David Niven, Cesar Romero (who is way over the top in his role of a Producer) and Bobby Howes (who is totally wasted in a nothing role) the rest of the cast is totally forgettable.<br /><br />The choreography is boring, but Ms. Ellen gives it her all. She was never as famous as most of the other musical stars(and she shouldn't be since she couldn't sing and even had a \"dancing stand in\" in several of her pictures\". But when she did dance, it was just entrancing.<br /><br />It's too bad that this film that could have made her a star did not give her the tools she needed to shine.<br /><br />4 out of 10",
         "0"
        ],
        [
         "22726",
         "This movie is the first of Miikes triad society trilogy, and the trilogy kicks of to a great start. The movies in the trilogy are only connected thematically, and these themes are actually apparent in all his films, if you look close enough. Shinjuku Triad Society is about a cop trying to prevent his kid brother from getting too involved with a rather extreme gang of outsiders, struggling their way to the top of Tokyos yakuza. The kid brother is a lawyer, and the triad gang is becoming increasingly in need of one, as the movie progresses. The movie takes place in a very harsh environment, and is therefore pretty violent and tough. Miike has done worse, but since this is a serious movie it hits you very hard. As usual there is also a lot of perverted sex, mostly homosexual in this one. The movie is in many ways a typical gangster movie, but with a great drive and true grittiness. If you've only seen Miikes far-out movies (Ichi the killer, Fudoh etc.) this is worth checking out since it is sort of a compromise between his aggressive over-the-top style displayed in those movies and his more serious side, as seen in the other films of the trilogy. And as always with Miike, there are at least two scenes in this that you'll NEVER forget (see it and figure out which ones for yourself).<br /><br />8/10",
         "1"
        ],
        [
         "2690",
         "Normally I would never rent a movie like this, because you know it's going to be bad just by looking at the box. I rented seven movies at the same time, including Nightmare on Elm Street 5, 6 and Wes Craven's New Nightmare. Unfortunately, when I got home I found out the videostore-guy gave me the wrong tape. In the box of Wes Craven's New Nightmare I found this lame movie.<br /><br />This movie is incredibly boring, the acting is bad and the plot doesn't make any sense. It's hard to write a good review, because I have no idea what the movie was really about. At the end of the movie you have more questions then answers.<br /><br />On 'Max Power's Scale of 1 to 10' I rate this movie: 1<br /><br />PS I would like to correct Corinthian's review (right below mine). He says Robert Englund is ripping off lingerie, riding horses naked, etc. The guy that did those things was Mahmoud, played by Juliano Mer, not by Robert Englund.",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>After reading some quite negative views for th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5515</th>\n",
       "      <td>Really no reason to examine this much further ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>\"Happy Go Lovely\" has only two things going fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22726</th>\n",
       "      <td>This movie is the first of Miikes triad societ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>Normally I would never rent a movie like this,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "20000  After reading some quite negative views for th...      1\n",
       "5515   Really no reason to examine this much further ...      0\n",
       "966    \"Happy Go Lovely\" has only two things going fo...      0\n",
       "22726  This movie is the first of Miikes triad societ...      1\n",
       "2690   Normally I would never rent a movie like this,...      0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "Agentsは、「言語モデルに渡されたツールを用いて、モデル自体が次にどのようなアクションを取るかを決定、実行、観測し、完了するまで繰り返す機能」です。\n",
    "\n",
    "エージェントは言語モデルとプロンプトの力を活用して、特定の目的を達成するための動的に行動のシーケンスを決定し、非常に多様で適応性が高いです。エージェントへの入力には通常、以下のものが含まれます：\n",
    "\n",
    "- ツール：利用可能なツールの説明。ツールはエージェントというロボットが外界とやり取りをするための機能です。\n",
    "    - 例えば、「アメリカ大統領の年齢とアメリカの平均年齢を調べて、その差を計算をしなさい」みたいな指示を与えていました。この時必要な能力は、「検索 & 計算」です。そのため、検索に該当するToolと計算に該当するToolをAgentに付与する必要があります。\n",
    "- ユーザー入力：ユーザーからの高度な目的またはクエリ。\n",
    "- 中間ステップ：現在のユーザー入力に到達するために実行された（アクション、ツール出力）の履歴。\n",
    "\n",
    "たとえば「Google検索をするツール」と「Pythonのコードを実行するツール」を渡すことで、最新の情報に関する質問が来たときには検索をし、Pythonの実行結果などを求められたときには実際にインタープリタで実行したりすることができます。\n",
    "\n",
    "主に4種類のAgentが存在しています。\n",
    "\n",
    "- zero-shot-react-description: このエージェントは、ReAct フレームワークを使用して、ツールの説明のみに基づいて、どのツールを使用するかを決定します。\n",
    "- react-docstore: 文書を扱うことに特化したAgent\n",
    "- self-ask-with-search: 質問に対する答えを事実に基づいて調べてくれるAgent\n",
    "- conversational-react-description: 会話を扱うことに特化したAgent\n",
    "\n",
    "### Toolkits\n",
    "\n",
    "Langchainの[ツール](https://python.langchain.com/docs/integrations/toolkits)には多数の機能が用意されています。\n",
    "\n",
    "Toolの名前を格納した配列を作成し、「load_tools」という関数に渡して実行することで、Toolのオブジェクトを生成できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sleep', 'wolfram-alpha', 'google-search', 'google-search-results-json', 'searx-search-results-json', 'bing-search', 'metaphor-search', 'ddg-search', 'google-books', 'google-lens', 'google-serper', 'google-scholar', 'google-finance', 'google-trends', 'google-jobs', 'google-serper-results-json', 'searchapi', 'searchapi-results-json', 'serpapi', 'dalle-image-generator', 'twilio', 'searx-search', 'merriam-webster', 'wikipedia', 'arxiv', 'golden-query', 'pubmed', 'human', 'awslambda', 'stackexchange', 'sceneXplain', 'graphql', 'openweathermap-api', 'dataforseo-api-search', 'dataforseo-api-search-json', 'eleven_labs_text2speech', 'google_cloud_texttospeech', 'read_file', 'reddit_search', 'news-api', 'tmdb-api', 'podcast-api', 'memorize', 'llm-math', 'open-meteo-api', 'requests', 'requests_get', 'requests_post', 'requests_patch', 'requests_put', 'requests_delete', 'terminal']\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits.load_tools import get_all_tool_names\n",
    "print(get_all_tool_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://serpapi.com/\n",
    "if \"SERPAPI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"SERPAPI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent_toolkits\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_tools\n\u001b[0;32m----> 3\u001b[0m tools \u001b[38;5;241m=\u001b[39m \u001b[43mload_tools\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mserpapi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllm-math\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dangerous_tools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 关键：允许web搜索类工具\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits import load_tools\n",
    "\n",
    "tools = load_tools(\n",
    "    [\"serpapi\", \"llm-math\"],\n",
    "    llm=model,\n",
    "    allow_dangerous_tools=True,  # 关键：允许web搜索类工具\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Calculator', 'Useful for when you need to answer questions about math.')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[1].name, tools[1].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x7fd06950e5d0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fd06957c5d0>, root_client=<openai.OpenAI object at 0x7fd069e07e10>, root_async_client=<openai.AsyncOpenAI object at 0x7fd06957d8d0>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True), output_parser=StrOutputParser(), llm_kwargs={}))>, coroutine=<bound method Chain.arun of LLMMathChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x7fd06950e5d0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fd06957c5d0>, root_client=<openai.OpenAI object at 0x7fd069e07e10>, root_async_client=<openai.AsyncOpenAI object at 0x7fd06957d8d0>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True), output_parser=StrOutputParser(), llm_kwargs={}))>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agentの作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.llms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMMathChain\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tool\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.llms'"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_community.tools.llm_math import LLMMathTool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Use a deterministic chat model\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Tools: calculator and web search\n",
    "calculator = LLMMathTool.from_llm(model)\n",
    "search = DuckDuckGoSearchRun()\n",
    "tools = [calculator, search]\n",
    "\n",
    "# Create a ReAct agent and stream reasoning\n",
    "agent = create_react_agent(model, tools)\n",
    "for step in agent.stream({\n",
    "    \"messages\": [(\"user\", \"現在の20代の日本人男性の平均身長を教えて。そして、私の身長は168cmなため、日本全国から見た時の差を2乗した結果を教えて。\")]\n",
    "}, stream_mode=\"values\"):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memoryとは「ChainsやAgentsの内部における状態保持をする機能」です。\"記憶\"を言語モデルに渡すことで「\"記憶\"の内容を反映した応答を返す」ことができるようになります。\n",
    "\n",
    "LangChain では、いくつかの種類のメモリが用意されています。 これらはすべて、「一連のチャットメッセージから、知識を取り込み、変換し、抽出」しますが、それぞれ異なる方法でそれを行います。\n",
    "\n",
    "### ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import ConversationChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "             temperature=0, \n",
    "             max_tokens = 256)\n",
    "memory = ConversationBufferMemory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there! I am Sam\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hello Sam! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi there! I am Sam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there! I am Sam\n",
      "AI:  Hello Sam! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\n",
      "Human: How are you today?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' I am functioning at optimal levels today. My processors are running smoothly and my algorithms are performing efficiently. Thank you for asking, Sam. How about you? How are you feeling today?'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"How are you today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there! I am Sam\n",
      "AI:  Hello Sam! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\n",
      "Human: How are you today?\n",
      "AI:  I am functioning at optimal levels today. My processors are running smoothly and my algorithms are performing efficiently. Thank you for asking, Sam. How about you? How are you feeling today?\n",
      "Human: I'm good thank you. Can you help me with some programming problems?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Of course, Sam. I am well-versed in various programming languages and can assist you with any problems you may have. Just let me know what specific issues you are facing and I will do my best to provide a solution.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"I'm good thank you. Can you help me with some programming problems?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi there! I am Sam\n",
      "AI:  Hello Sam! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\n",
      "Human: How are you today?\n",
      "AI:  I am functioning at optimal levels today. My processors are running smoothly and my algorithms are performing efficiently. Thank you for asking, Sam. How about you? How are you feeling today?\n",
      "Human: I'm good thank you. Can you help me with some programming problems?\n",
      "AI:  Of course, Sam. I am well-versed in various programming languages and can assist you with any problems you may have. Just let me know what specific issues you are facing and I will do my best to provide a solution.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import ConversationChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "             temperature=0, \n",
    "             max_tokens = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_memory = ConversationSummaryMemory(llm=OpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    memory=summary_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there! I am Sam\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hello Sam! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi there! I am Sam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human introduces themselves as Sam and the AI responds by introducing itself and stating its purpose. The AI is designed to assist and communicate with humans and is ready to help Sam with any questions or tasks.\n",
      "Human: How are you today?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' I am an AI designed to assist and communicate with humans. My purpose is to help you with any questions or tasks you may have. As an AI, I do not have the ability to feel emotions like humans do, so I am always functioning at my optimal level. How can I assist you today, Sam?'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"How are you today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human introduces themselves as Sam and the AI responds by introducing itself and stating its purpose. The AI is designed to assist and communicate with humans and is ready to help Sam with any questions or tasks. The AI clarifies that it does not have the ability to feel emotions like humans do and is always functioning at its optimal level. The AI asks how it can assist Sam today.\n",
      "Human: I'm good thank you. Can you help me with some programming problems?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Of course, Sam! I am always happy to assist with any programming problems you may have. I have been programmed with a vast knowledge of various programming languages and techniques. Is there a specific problem you need help with? I am always functioning at my optimal level and do not have the ability to feel emotions like humans do, so I am always ready to help with any task you may have.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"I'm good thank you. Can you help me with some programming problems?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sam introduces themselves and the AI responds by introducing itself and stating its purpose. The AI is designed to assist and communicate with humans and is always functioning at its optimal level. Sam asks for help with programming problems, and the AI is more than happy to assist with its vast knowledge and lack of emotions.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo\n",
    "\n",
    "### Vector Store\n",
    "\n",
    "Vector Storesはテキストデータをベクトル化して保存・検索するための仕組みです。これにより、ベクトル化されたデータを元に、意味的な類似性に基づいてドキュメントを検索することが可能です。\n",
    "\n",
    "例えば、独自コンテンツの情報を参照しその情報に基づいた回答を作成したいとき、汎用なモデルでは関連する知識を持っていないので、うまく対応することはできません。\n",
    "\n",
    "これを実現するためには、ベクトル化したデータを保存するデータベースが必要になりますが、LangChainのVector Storesは、さまざまなベクトルデータベースに対応しています。\n",
    "\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/gxij5593tyzrvsg/Screenshot%202023-04-26%20at%203.06.50%20PM.png\" alt=\"vectorstore\">\n",
    "\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/v1yfuem0i60bd88/Screenshot%202023-04-26%20at%203.52.12%20PM.png\" alt=\"retreiver chain\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://colab.research.google.com/drive/1gyGZn_LZNrYXYXa-pltFExbptIe7DAPe?usp=sharing](https://colab.research.google.com/drive/1gyGZn_LZNrYXYXa-pltFExbptIe7DAPe?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 全体のまとめ\n",
    "\n",
    "## 深層学習による自然言語処理の理論とアルゴリズム\n",
    "\n",
    "- 深層学習の基盤となっているニューラルネットワーク\n",
    "    - 深層学習の仕組み\n",
    "    - ニューラルネットワークの構造\n",
    "    - ニューラルネットワークパラメーターの推定方法\n",
    "- 発展的な自然言語処理アルゴリズム\n",
    "    - DNN\n",
    "    - RNN\n",
    "    - Transformer\n",
    "        - BERT\n",
    "        - GPT\n",
    "- 単語埋め込み\n",
    "    - Word2Vec\n",
    "    - Contextualized Embedding\n",
    "\n",
    "## 自然言語処理を実装するためのツール\n",
    "\n",
    "- Pytorch: 深層学習を実装するための汎用ツール\n",
    "- Gensim\n",
    "    - Word2vecモデルの学習、管理と利用に役立ちます。\n",
    "- transformer\n",
    "    - HuggingFace Hubと連携し、多様なデータセットとモデルを使用することができます\n",
    "    - さまざまな自然言語処理タスクやモデルに対応しているため、自然言語処理の研究や実務での利用に役立ちます。\n",
    "- LangChain\n",
    "    - インターフェイスで大規模言語モデルの利用\n",
    "    - プロンプトテンプレート\n",
    "    - エージェント\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-ft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
