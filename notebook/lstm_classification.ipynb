{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTMによる文書分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/lyuzeyu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ準備\n",
    "\n",
    "### CSVファイルを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>brand</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        brand sentiment  \\\n",
       "0   2401  Borderlands  Positive   \n",
       "1   2401  Borderlands  Positive   \n",
       "2   2401  Borderlands  Positive   \n",
       "3   2401  Borderlands  Positive   \n",
       "4   2401  Borderlands  Positive   \n",
       "\n",
       "                                                text  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('./Data/twitter_training.csv',names=['index','brand','sentiment','text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ラベルデータの処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>brand</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        brand sentiment  \\\n",
       "0   2401  Borderlands  Positive   \n",
       "1   2401  Borderlands  Positive   \n",
       "2   2401  Borderlands  Positive   \n",
       "3   2401  Borderlands  Positive   \n",
       "4   2401  Borderlands  Positive   \n",
       "\n",
       "                                                text  label  \n",
       "0  im getting on borderlands and i will murder yo...    2.0  \n",
       "1  I am coming to the borders and I will kill you...    2.0  \n",
       "2  im getting on borderlands and i will kill you ...    2.0  \n",
       "3  im coming on borderlands and i will murder you...    2.0  \n",
       "4  im getting on borderlands 2 and i will murder ...    2.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"]=df[\"sentiment\"].replace({\"Positive\":2,\"Negative\":0,\"Neutral\":1,\"Irrelevant\":np.nan})\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テキストデータの前処理\n",
    "\n",
    "- テキストを小文字に変換\n",
    "- 句読点を削除\n",
    "- トークン化\n",
    "- 単語ID化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = re.sub(r'\\W+', ' ', text)  # Remove punctuation\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"processed_text\"]=df[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>brand</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[im, getting, on, borderlands, and, i, will, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[i, am, coming, to, the, borders, and, i, will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[im, getting, on, borderlands, and, i, will, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[im, coming, on, borderlands, and, i, will, mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[im, getting, on, borderlands, 2, and, i, will...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        brand sentiment  \\\n",
       "0   2401  Borderlands  Positive   \n",
       "1   2401  Borderlands  Positive   \n",
       "2   2401  Borderlands  Positive   \n",
       "3   2401  Borderlands  Positive   \n",
       "4   2401  Borderlands  Positive   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  im getting on borderlands and i will murder yo...    2.0   \n",
       "1  I am coming to the borders and I will kill you...    2.0   \n",
       "2  im getting on borderlands and i will kill you ...    2.0   \n",
       "3  im coming on borderlands and i will murder you...    2.0   \n",
       "4  im getting on borderlands 2 and i will murder ...    2.0   \n",
       "\n",
       "                                      processed_text  \n",
       "0  [im, getting, on, borderlands, and, i, will, m...  \n",
       "1  [i, am, coming, to, the, borders, and, i, will...  \n",
       "2  [im, getting, on, borderlands, and, i, will, k...  \n",
       "3  [im, coming, on, borderlands, and, i, will, mu...  \n",
       "4  [im, getting, on, borderlands, 2, and, i, will...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 単語辞書\n",
    "\n",
    "`Vocab`は、各単語（トークン）に対して一意のインデックス（またはID）を割り当てます。このマッピングにより、テキストデータを数値データに変換することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "for line in df[\"processed_text\"]:\n",
    "    counter.update(line)\n",
    "Vocab = vocab(counter, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'partition': 26882\n",
      "'gfn': 26881\n",
      "'unnoticed': 26880\n",
      "'intend': 26878\n",
      "'techsall': 26874\n"
     ]
    }
   ],
   "source": [
    "# 単語からインデックスへのマッピング\n",
    "word_to_index = Vocab.get_stoi()\n",
    "\n",
    "# 最初の5つのアイテムを取得して表示\n",
    "for i, (word, index) in enumerate(word_to_index.items()):\n",
    "    if i >= 5:  # 最初の5つのアイテムのみ表示\n",
    "        break\n",
    "    print(f\"'{word}': {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['numericalized_text'] = df[\"processed_text\"].apply(lambda x: [Vocab[token] for token in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>brand</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>numericalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[im, getting, on, borderlands, and, i, will, m...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[i, am, coming, to, the, borders, and, i, will...</td>\n",
       "      <td>[5, 10, 11, 12, 13, 14, 4, 5, 6, 15, 8, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[im, getting, on, borderlands, and, i, will, k...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 15, 8, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[im, coming, on, borderlands, and, i, will, mu...</td>\n",
       "      <td>[0, 11, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[im, getting, on, borderlands, 2, and, i, will...</td>\n",
       "      <td>[0, 1, 2, 3, 16, 4, 5, 6, 7, 8, 17, 9]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        brand sentiment  \\\n",
       "0   2401  Borderlands  Positive   \n",
       "1   2401  Borderlands  Positive   \n",
       "2   2401  Borderlands  Positive   \n",
       "3   2401  Borderlands  Positive   \n",
       "4   2401  Borderlands  Positive   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  im getting on borderlands and i will murder yo...    2.0   \n",
       "1  I am coming to the borders and I will kill you...    2.0   \n",
       "2  im getting on borderlands and i will kill you ...    2.0   \n",
       "3  im coming on borderlands and i will murder you...    2.0   \n",
       "4  im getting on borderlands 2 and i will murder ...    2.0   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  [im, getting, on, borderlands, and, i, will, m...   \n",
       "1  [i, am, coming, to, the, borders, and, i, will...   \n",
       "2  [im, getting, on, borderlands, and, i, will, k...   \n",
       "3  [im, coming, on, borderlands, and, i, will, mu...   \n",
       "4  [im, getting, on, borderlands, 2, and, i, will...   \n",
       "\n",
       "                           numericalized_text  \n",
       "0              [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  \n",
       "1  [5, 10, 11, 12, 13, 14, 4, 5, 6, 15, 8, 9]  \n",
       "2             [0, 1, 2, 3, 4, 5, 6, 15, 8, 9]  \n",
       "3             [0, 11, 2, 3, 4, 5, 6, 7, 8, 9]  \n",
       "4      [0, 1, 2, 3, 16, 4, 5, 6, 7, 8, 17, 9]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(seq, max_len):\n",
    "    padded = np.zeros((max_len,), dtype=np.int64)\n",
    "    if len(seq) > max_len: padded[:] = seq[:max_len]\n",
    "    else: padded[:len(seq)] = seq\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding\n",
    "\n",
    "ニューラルネットワークは、入力データが固定長であることを前提としていますので、テキストシーケンスを特定の最大長にパディング（埋める）する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_length\"]=df[\"numericalized_text\"].apply(lambda x: len(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    61121.000000\n",
       "mean        19.455212\n",
       "std         14.430986\n",
       "min          0.000000\n",
       "25%          8.000000\n",
       "50%         16.000000\n",
       "75%         27.000000\n",
       "max        198.000000\n",
       "Name: text_length, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text_length\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=30\n",
    "df['padded_text'] = df['numericalized_text'].apply(lambda x: pad_sequences(x, max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>brand</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>numericalized_text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>padded_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[im, getting, on, borderlands, and, i, will, m...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>10</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[i, am, coming, to, the, borders, and, i, will...</td>\n",
       "      <td>[5, 10, 11, 12, 13, 14, 4, 5, 6, 15, 8, 9]</td>\n",
       "      <td>12</td>\n",
       "      <td>[5, 10, 11, 12, 13, 14, 4, 5, 6, 15, 8, 9, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[im, getting, on, borderlands, and, i, will, k...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 15, 8, 9]</td>\n",
       "      <td>10</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 15, 8, 9, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[im, coming, on, borderlands, and, i, will, mu...</td>\n",
       "      <td>[0, 11, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>10</td>\n",
       "      <td>[0, 11, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[im, getting, on, borderlands, 2, and, i, will...</td>\n",
       "      <td>[0, 1, 2, 3, 16, 4, 5, 6, 7, 8, 17, 9]</td>\n",
       "      <td>12</td>\n",
       "      <td>[0, 1, 2, 3, 16, 4, 5, 6, 7, 8, 17, 9, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        brand sentiment  \\\n",
       "0   2401  Borderlands  Positive   \n",
       "1   2401  Borderlands  Positive   \n",
       "2   2401  Borderlands  Positive   \n",
       "3   2401  Borderlands  Positive   \n",
       "4   2401  Borderlands  Positive   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  im getting on borderlands and i will murder yo...    2.0   \n",
       "1  I am coming to the borders and I will kill you...    2.0   \n",
       "2  im getting on borderlands and i will kill you ...    2.0   \n",
       "3  im coming on borderlands and i will murder you...    2.0   \n",
       "4  im getting on borderlands 2 and i will murder ...    2.0   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  [im, getting, on, borderlands, and, i, will, m...   \n",
       "1  [i, am, coming, to, the, borders, and, i, will...   \n",
       "2  [im, getting, on, borderlands, and, i, will, k...   \n",
       "3  [im, coming, on, borderlands, and, i, will, mu...   \n",
       "4  [im, getting, on, borderlands, 2, and, i, will...   \n",
       "\n",
       "                           numericalized_text  text_length  \\\n",
       "0              [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]           10   \n",
       "1  [5, 10, 11, 12, 13, 14, 4, 5, 6, 15, 8, 9]           12   \n",
       "2             [0, 1, 2, 3, 4, 5, 6, 15, 8, 9]           10   \n",
       "3             [0, 11, 2, 3, 4, 5, 6, 7, 8, 9]           10   \n",
       "4      [0, 1, 2, 3, 16, 4, 5, 6, 7, 8, 17, 9]           12   \n",
       "\n",
       "                                         padded_text  \n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, ...  \n",
       "1  [5, 10, 11, 12, 13, 14, 4, 5, 6, 15, 8, 9, 0, ...  \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 15, 8, 9, 0, 0, 0, 0, 0,...  \n",
       "3  [0, 11, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0,...  \n",
       "4  [0, 1, 2, 3, 16, 4, 5, 6, 7, 8, 17, 9, 0, 0, 0...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習用データセットの作成(Batch Datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the original dataset into training plus validation and testing sets\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.2)\n",
    "\n",
    "# Split the training plus validation set into separate training and validation sets\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3912/2868894412.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449201450/work/torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  train_data = TensorDataset(torch.LongTensor(train_df['padded_text'].tolist()), torch.LongTensor(train_df['label'].tolist()))\n"
     ]
    }
   ],
   "source": [
    "# Create TensorDatasets\n",
    "train_data = TensorDataset(torch.LongTensor(train_df['padded_text'].tolist()), torch.LongTensor(train_df['label'].tolist()))\n",
    "val_data = TensorDataset(torch.LongTensor(val_df['padded_text'].tolist()), torch.LongTensor(val_df['label'].tolist()))\n",
    "test_data = TensorDataset(torch.LongTensor(test_df['padded_text'].tolist()), torch.LongTensor(test_df['label'].tolist()))\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの作成\n",
    "\n",
    "### メソッドの説明\n",
    "\n",
    "#### `nn.Embedding`\n",
    "\n",
    "- `nn.Embedding`は単語の埋め込みを行うために使用されます。単語の埋め込みとは、単語を固定長のベクトルに変換することを指します。このベクトルは、単語の意味的な特性を捉えることができます。`nn.Embedding`の主なパラメータは以下の通りです：\n",
    "    - `num_embeddings`：埋め込みを行う単語の総数。通常は語彙のサイズに設定します。\n",
    "    - `embedding_dim`：各単語の埋め込みベクトルの次元数。\n",
    "- `nn.Embedding`は、整数のインデックスを入力として受け取り、それに対応する埋め込みベクトルを出力します。\n",
    "- 下の例では、`input`の各インデックスが対応する埋め込みベクトルに置き換えられ、`embedded`はサイズ`(batch_size, sequence_length, embedding_dim)`のテンソルになります。\n",
    "\n",
    "#### `nn.Dropout`\n",
    "\n",
    "- ドロップアウトは、ニューラルネットワークの訓練中にランダムにノードを「ドロップアウト」（つまり無効化）することで、過学習を防ぐための一般的なテクニックです`nn.Dropout`の主なパラメータは以下の通りです：\n",
    "    - `p`：ノードをドロップアウトする確率。0.0（ノードをドロップアウトしない）から1.0（全てのノードをドロップアウトする）までの値を取ります。デフォルトは0.5です。\n",
    "- `nn.Dropout`は、訓練中にのみドロップアウトを適用し、評価（つまりモデルが`.eval()`モードにあるとき）中にはドロップアウトを適用しません。これは、訓練中にはモデルのロバスト性を向上させるためにランダム性が必要である一方、評価中にはモデルの全ての学習特性を使用して一貫した出力を得る必要があるためです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 300])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(num_embeddings=10000, embedding_dim=300)\n",
    "input = torch.LongTensor([[1, 2, 4, 5], [4, 3, 2, 9]])\n",
    "embedded = embedding(input)\n",
    "embedded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの定義\n",
    "\n",
    "`hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))`\n",
    "\n",
    "ここでは、双方向LSTMの最後の隠れ状態を取り扱っています。\n",
    "\n",
    "双方向LSTMは、順方向と逆方向の2つのLSTMを使用します。順方向のLSTMはシーケンスを通常の順序で処理し、逆方向のLSTMはシーケンスを逆順で処理します。その結果、各時間ステップで2つの隠れ状態（順方向と逆方向のそれぞれから1つずつ）が得られます。\n",
    "\n",
    "- `hidden[-2,:,:]`と`hidden[-1,:,:]`は、それぞれ最後の時間ステップでの順方向と逆方向の隠れ状態を取得しています。\n",
    "\n",
    "- `torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)`は、これら2つの隠れ状態を結合しています。結合は`dim=1`（つまり、特徴量の次元）に沿って行われます。\n",
    "\n",
    "その結果、順方向と逆方向の隠れ状態が1つのベクトルに結合され、そのベクトルは次の全結合層に入力されます。\n",
    "\n",
    "`self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)`\n",
    "\n",
    "`self.fc`は全結合層で、LSTMからの出力を最終的な出力次元に変換します。この出力は、分類タスクのクラス数に等しいなります。\n",
    "\n",
    "全結合層の入力次元は、LSTMの隠れ状態の次元数に依存します。\n",
    "\n",
    "- LSTMが双方向の場合（`bidirectional=True`）、順方向と逆方向の隠れ状態が結合されるため、隠れ状態の次元数は`hidden_dim * 2`になります。\n",
    "- LSTMが一方向の場合（`bidirectional=False`）、隠れ状態の次元数は`hidden_dim`になります。\n",
    "\n",
    "したがって、`nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)`は、LSTMの方向性に応じて全結合層の入力次元を適切に設定します。\n",
    "\n",
    "出力次元`output_dim`は、タスクのクラス数または回帰の出力次元に設定します。\n",
    "\n",
    "`batch_first=True`\n",
    "\n",
    "`batch_first=True`を設定すると、\n",
    "\n",
    "- 入力テンソルの形状は`(batch_size, sequence_length, input_size)`と解釈されます。つまり、バッチの次元が最初に来ます。\n",
    "- `output`テンソルの形状は`(batch_size, seq_len, num_directions * hidden_size)`になります。\n",
    "\n",
    "`batch_first=True`を使用する主な理由は、多くの場合、バッチの次元を最初に持ってくると、テンソル操作が直感的になり、コードが読みやすくなります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            num_layers=n_layers, \n",
    "                            bidirectional=bidirectional, \n",
    "                            dropout=dropout, \n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.bidirectional = bidirectional\n",
    "    \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        if self.bidirectional:\n",
    "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        else:\n",
    "            hidden = hidden[-1,:,:]\n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(Vocab)\n",
    "embedding_dim = 100  \n",
    "hidden_dim = 256     \n",
    "output_dim = 3 \n",
    "n_layers = 2        \n",
    "bidirectional = True \n",
    "dropout = 0.2        \n",
    "\n",
    "model = LSTMClassifier(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyuzeyu/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, criterion, n_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        for texts, labels in train_loader:\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(texts)\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_labels = []\n",
    "            val_preds = []\n",
    "            for texts, labels in val_loader:\n",
    "                texts, labels = texts.to(device), labels.to(device)\n",
    "                predictions = model(texts)\n",
    "                val_labels.extend(labels.tolist())\n",
    "                val_preds.extend(torch.argmax(predictions, dim=1).tolist())\n",
    "\n",
    "            accuracy = accuracy_score(val_labels, val_preds)\n",
    "            f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "            print(f\"Epoch {epoch+1}, Loss: {loss.item()}, Accuracy: {accuracy}, F1 Score: {f1}\")\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, n_epochs, tensorboard=False, tensorboard_path='./runs'):\n",
    "    # Initialize TensorBoard writer if tensorboard logging is enabled\n",
    "    writer = SummaryWriter(tensorboard_path) if tensorboard else None\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        for texts, labels in train_loader:\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(texts)\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_labels = []\n",
    "            val_preds = []\n",
    "            for texts, labels in val_loader:\n",
    "                texts, labels = texts.to(device), labels.to(device)\n",
    "                predictions = model(texts)\n",
    "                val_labels.extend(labels.tolist())\n",
    "                val_preds.extend(torch.argmax(predictions, dim=1).tolist())\n",
    "\n",
    "            accuracy = accuracy_score(val_labels, val_preds)\n",
    "            f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "            # Log metrics to TensorBoard\n",
    "            if tensorboard:\n",
    "                writer.add_scalar('Loss/train', loss.item(), epoch)\n",
    "                writer.add_scalar('Accuracy/val', accuracy, epoch)\n",
    "                writer.add_scalar('F1-Score/val', f1, epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}, Loss: {loss.item()}, Accuracy: {accuracy}, F1 Score: {f1}\")\n",
    "\n",
    "        model.train()\n",
    "\n",
    "    # Close the TensorBoard writer\n",
    "    if tensorboard:\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8449880480766296, Accuracy: 0.7099149214659686, F1 Score: 0.7069928140558078\n",
      "Epoch 2, Loss: 0.27576813101768494, Accuracy: 0.8080824607329843, F1 Score: 0.8078143110550561\n",
      "Epoch 3, Loss: 0.25769510865211487, Accuracy: 0.8552846858638743, F1 Score: 0.8556345042458001\n",
      "Epoch 4, Loss: 0.133466899394989, Accuracy: 0.8779450261780105, F1 Score: 0.8779570294645823\n",
      "Epoch 5, Loss: 0.07853778451681137, Accuracy: 0.8778632198952879, F1 Score: 0.8778019069945747\n",
      "Epoch 6, Loss: 0.027475230395793915, Accuracy: 0.8825261780104712, F1 Score: 0.8824995447047637\n",
      "Epoch 7, Loss: 0.06441111117601395, Accuracy: 0.8891524869109948, F1 Score: 0.8891206407865168\n",
      "Epoch 8, Loss: 0.12298416346311569, Accuracy: 0.8826897905759162, F1 Score: 0.8824670066456229\n",
      "Epoch 9, Loss: 0.2005656212568283, Accuracy: 0.8898887434554974, F1 Score: 0.8895207743291376\n",
      "Epoch 10, Loss: 0.16960707306861877, Accuracy: 0.8851439790575916, F1 Score: 0.884828326545353\n",
      "Epoch 11, Loss: 0.03594233840703964, Accuracy: 0.8913612565445026, F1 Score: 0.8914158403839844\n",
      "Epoch 12, Loss: 0.14152638614177704, Accuracy: 0.8898069371727748, F1 Score: 0.8898291036122973\n",
      "Epoch 13, Loss: 0.0760403648018837, Accuracy: 0.8875163612565445, F1 Score: 0.8873445655093417\n",
      "Epoch 14, Loss: 0.07936086505651474, Accuracy: 0.8931609947643979, F1 Score: 0.8932776720810208\n",
      "Epoch 15, Loss: 0.08110363781452179, Accuracy: 0.8954515706806283, F1 Score: 0.8954183179394585\n",
      "Epoch 16, Loss: 0.07532665878534317, Accuracy: 0.896351439790576, F1 Score: 0.8963204817227336\n",
      "Epoch 17, Loss: 0.07237569242715836, Accuracy: 0.8911976439790575, F1 Score: 0.8910795608652415\n",
      "Epoch 18, Loss: 0.060508258640766144, Accuracy: 0.8989692408376964, F1 Score: 0.8989776235955858\n",
      "Epoch 19, Loss: 0.13377350568771362, Accuracy: 0.894142670157068, F1 Score: 0.8939793777843631\n",
      "Epoch 20, Loss: 0.00022401123715098947, Accuracy: 0.8988874345549738, F1 Score: 0.8989533844793711\n",
      "Epoch 21, Loss: 0.00010444450163049623, Accuracy: 0.9007689790575916, F1 Score: 0.900850760087712\n",
      "Epoch 22, Loss: 0.08742760121822357, Accuracy: 0.903059554973822, F1 Score: 0.903120167324036\n",
      "Epoch 23, Loss: 0.04664722457528114, Accuracy: 0.897169502617801, F1 Score: 0.8970790038895362\n",
      "Epoch 24, Loss: 0.08958390355110168, Accuracy: 0.8956151832460733, F1 Score: 0.8956088849815662\n",
      "Epoch 25, Loss: 0.03755480796098709, Accuracy: 0.9012598167539267, F1 Score: 0.9013136085662616\n",
      "Epoch 26, Loss: 0.09691934287548065, Accuracy: 0.9038776178010471, F1 Score: 0.9038292441738486\n",
      "Epoch 27, Loss: 0.03982943668961525, Accuracy: 0.8986420157068062, F1 Score: 0.8985824039497624\n",
      "Epoch 28, Loss: 0.03090355172753334, Accuracy: 0.9064136125654451, F1 Score: 0.9064679349789694\n",
      "Epoch 29, Loss: 0.038370802998542786, Accuracy: 0.9024869109947644, F1 Score: 0.9024392713431985\n",
      "Epoch 30, Loss: 0.0055753798224031925, Accuracy: 0.9024051047120419, F1 Score: 0.902401755072242\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "n_epochs = 30\n",
    "train_model(model, train_loader, val_loader, optimizer, criterion, n_epochs, tensorboard=True, tensorboard_path='./runs/lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
