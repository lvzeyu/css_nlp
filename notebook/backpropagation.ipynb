{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 誤差逆伝播法\n",
    "\n",
    "これまでは、ニューラルネットワークの各パラメータについての目的関数の数値微分を計算することで勾配の計算を求める方法を説明しました。\n",
    "\n",
    "しかし、ニューラルネットワークの層数が多くなると、数値微分の計算は膨大な時間がかかるでしょう。\n",
    "\n",
    "ここで、パラメータの勾配の計算を効率よく行う手法である「誤差逆伝播法」について学びます。\n",
    "\n",
    "![誤差逆伝播法 (backpropagation) の計算過程](https://tutorials.chainer.org/ja/_images/13_backpropagation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 連鎖律"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "複数の関数によって構成される関数を合成関数と呼びます。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "z &= t^2 \\\\\n",
    "t &= x + y\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "合成関数の微分は、「$t$に関する$z$の微分$\\frac{\\partial z}{\\partial t}$」と「$x$に関する$t$の微分$\\frac{\\partial t}{\\partial 1}$」の積のように、それぞれの関数の微分の積で求められます。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x}\n",
    "    = \\frac{\\partial z}{\\partial t}\n",
    "      \\frac{\\partial t}{\\partial x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 線形変換の逆伝播の導出\n",
    "\n",
    "入力データ$\\mathbf{x}$は$(N \\times D)$の行列、$\\mathbf{W}$は$(D \\times H)$の行列、$\\mathbf{b}$は要素数$H$のベクトルと考え、線形変換の計算は以下の式で表します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{y}\n",
    "   &= \\mathbf{x} \\mathbf{W} + \\mathbf{b}\n",
    "\\\\\n",
    "   &= \\begin{pmatrix}\n",
    "          x_{0,0} & x_{0,1} & \\cdots & x_{0,D-1} \\\\\n",
    "          x_{1,0} & x_{1,1} & \\cdots & x_{1,D-1} \\\\\n",
    "          \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "          x_{N-1,0} & x_{N-1,1} & \\cdots & x_{N-1,D-1}\n",
    "      \\end{pmatrix}\n",
    "      \\begin{pmatrix}\n",
    "          w_{0,0} & w_{0,1} & \\cdots & w_{0,H-1} \\\\\n",
    "          w_{1,0} & w_{1,1} & \\cdots & w_{1,H-1} \\\\\n",
    "          \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "          w_{D-1,0} & w_{D-1,1} & \\cdots & w_{D-1,H-1}\n",
    "      \\end{pmatrix}\n",
    "      + \\begin{pmatrix}\n",
    "          b_0 & b_1 & \\cdots & b_{H-1}\n",
    "        \\end{pmatrix}\n",
    "\\\\\n",
    "   &= \\begin{pmatrix}\n",
    "          \\sum_{d=0}^{D-1} x_{0,d} w_{d,0} + b_0 & \n",
    "          \\sum_{d=0}^{D-1} x_{0,d} w_{d,1} + b_1 & \n",
    "          \\cdots & \n",
    "          \\sum_{d=0}^{D-1} x_{0,d} w_{d,H-1} + b_{H-1} \\\\\n",
    "          \\sum_{d=0}^{D-1} x_{1,d} w_{d,0} + b_0 & \n",
    "          \\sum_{d=0}^{D-1} x_{1,d} w_{d,1} + b_1 & \n",
    "          \\cdots & \n",
    "          \\sum_{d=0}^{D-1} x_{1,d} w_{d,H-1} + b_{H-1}  \\\\\n",
    "          \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "          \\sum_{d=0}^{D-1} x_{N-1,d} w_{d,0} + b_0 & \n",
    "          \\sum_{d=0}^{D-1} x_{N-1,d} w_{d,1} + b_1 & \n",
    "          \\cdots & \n",
    "          \\sum_{d=0}^{D-1} x_{N-1,d} w_{d,H-1} + b_{H-1} \n",
    "      \\end{pmatrix}\n",
    "\\\\\n",
    "   &= \\begin{pmatrix}\n",
    "          y_{0,0} & y_{0,1} & \\cdots & y_{0,H-1} \\\\\n",
    "          y_{1,0} & y_{1,1} & \\cdots & y_{1,H-1} \\\\\n",
    "          \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "          y_{N-1,0} & y_{N-1,1} & \\cdots & y_{N-1,H-1}\n",
    "      \\end{pmatrix}\n",
    "\\end{aligned}\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、「$n$番目の出力データの$h$番目の項$y_{n,h}$」は、\n",
    "\n",
    "$$\n",
    "y_{n,h}\n",
    "    = \\sum_{d=0}^{D-1} x_{n,d} w_{d,h} + b_h\n",
    "$$\n",
    "\n",
    "で計算できるのが分かります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重みの勾配"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "連鎖律より、$\\frac{\\partial L}{\\partial w_{d,h}}$は次の式で求められます\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_{d,h}}\n",
    "    = \\sum_{n=0}^{N-1}\n",
    "          \\frac{\\partial L}{\\partial y_{n,h}}\n",
    "          \\frac{\\partial y_{n,h}}{\\partial w_{d,h}}\n",
    "$$\n",
    "\n",
    "- $\\frac{\\partial L}{\\partial y_{n,h}}$は、$y_{n,h}$に関する$L$の微分です。\n",
    "- $\\frac{\\partial y_{n,h}}{\\partial w_{d,h}}$は、$w_{d,h}$に関する$y_{n,h}$の微分です。\n",
    "\n",
    "ここで、$\\frac{\\partial y_{n,h}}{\\partial w_{d,h}}$は、"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial y_{n,h}}{\\partial w_{d,h}}\n",
    "   &= \\frac{\\partial}{\\partial w_{d,h}} \\left\\{\n",
    "          \\sum_{d=0}^{D-1} x_{n,d} w_{d,h} + b_h\n",
    "      \\right\\}\n",
    "\\\\\n",
    "   &= \\frac{\\partial}{\\partial x_{n,d}} \\Bigl\\{\n",
    "          x_{n,0} w_{0,h} + \\cdots + x_{n,d} w_{d,h} + \\cdots + x_{n,D-1} w_{D-1,h} + b_h\n",
    "      \\Bigr\\}\n",
    "\\\\\n",
    "   &= 0 + \\cdots + x_{n,d} + \\cdots + 0 + 0\n",
    "\\\\\n",
    "   &= x_{n,d}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "になりますため、\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_{d,h}}\n",
    "    = \\sum_{n=0}^{N-1}\n",
    "          \\frac{\\partial L}{\\partial y_{n,h}}\n",
    "          x_{n,d}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### バイアスの勾配\n",
    "\n",
    "同じく連鎖律より、$\\frac{\\partial L}{\\partial b_h}$は次の式で求められます。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b_h}\n",
    "    = \\sum_{n=0}^{N-1}\n",
    "          \\frac{\\partial L}{\\partial y_{n,h}}\n",
    "          \\frac{\\partial y_{n,h}}{\\partial b_h}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial y_{n,h}}{\\partial b_h}\n",
    "   &= \\frac{\\partial}{\\partial w_{d,h}} \\left\\{\n",
    "          \\sum_{d=0}^{D-1} x_{n,d} w_{d,h} + b_h\n",
    "      \\right\\}\n",
    "\\\\\n",
    "   &= 0 + 1\n",
    "\\\\\n",
    "   &= 1\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "まとめると、\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b_h}\n",
    "    = \\sum_{n=0}^{N-1}\n",
    "          \\frac{\\partial L}{\\partial y_{n,h}}\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ニューラルネットワークにおける誤差逆伝播法\n",
    "\n",
    "連鎖律より勾配を計算する考え方をニューラルネットワークにも適用することができます。具体的には、ニューラルネットワークを構成する関数が持つパラメータについての**目的関数の勾配**を、順伝播で通った経路を逆向きにたどるようにして**途中の関数の勾配の掛け算**によって求めます。\n",
    "\n",
    "```{margin}\n",
    "ニューラルネットワークには、活性化関数によて変換し、次の層へ伝播するといった計算の流れになりますが、逆伝播による勾配を計算できる原理は変わらないです。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここから、手計算を通じて誤差逆伝播法の実装を理解しましよう。\n",
    "\n",
    "- 入力\n",
    "\n",
    "$$\n",
    "i_{1} = 0.05,i_{2} = 0.10\n",
    "\n",
    "$$\n",
    "- 初期パラメータ\n",
    "\n",
    "$$\n",
    "w_{1} = 0.15,w_{2} = 0.20,w_{3} = 0.25,w_{4} = 0.30\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_{5} = 0.40,w_{6} = 0.45,w_{7} = 0.50,w_{8} = 0.55\n",
    "$$\n",
    "\n",
    "- 活性化関数: シグモイド関数\n",
    "\n",
    "$$\n",
    "h(x)\n",
    "    = \\frac{1}{1 + \\exp(-x)}\n",
    "$$\n",
    "\n",
    "- 教師データ\n",
    "$$\n",
    "o_{1} = 0.01,o_{2} = 0.99\n",
    "$$\n",
    "\n",
    "- 目的関数は平均二乗誤差関数を用いることにします。\n",
    "\n",
    "$$\n",
    "L = \\dfrac{1}{N} \\sum_{n=1}^{N} (t_{n} - y_{n})^2\n",
    "$$\n",
    "\n",
    "<img src=\"https://images2015.cnblogs.com/blog/853467/201606/853467-20160630142019140-402363317.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 順伝播の流れ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net_h1=0.3775\n"
     ]
    }
   ],
   "source": [
    "net_h1= (0.15)*(0.05)+(0.2)*(0.1)+0.35\n",
    "print(\"net_h1={}\".format(net_h1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_h2=0.39249999999999996\n"
     ]
    }
   ],
   "source": [
    "net_h2= (0.25)*(0.05)+(0.3)*(0.1)+0.35\n",
    "print(\"out_h2={}\".format(net_h2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_o1=0.7165932011681534\n",
      "out_o2=0.7319669364891265\n"
     ]
    }
   ],
   "source": [
    "net_o1 = (0.4)*net_h1+(0.45)*net_h2+0.6\n",
    "out_o1= sigmoid(net_o1)\n",
    "print(\"out_o1={}\".format(out_o1))\n",
    "net_o2 = (0.5)*net_h1+(0.55)*net_h2+0.6\n",
    "out_o2= sigmoid(net_o2)\n",
    "print(\"out_o2={}\".format(out_o2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=0.2829275069009325\n"
     ]
    }
   ],
   "source": [
    "L_1 = 0.5 * np.square(0.01-out_o1)\n",
    "L_2 = 0.5 * np.square(0.99-out_o2)\n",
    "L = L_1+L_2\n",
    "print(\"Loss={}\".format(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例えば、$w_5$の勾配を計算する際には、\n",
    "\n",
    "<img src=\"https://images2015.cnblogs.com/blog/853467/201606/853467-20160630152018906-1524325812.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_5} = \\frac{\\partial L}{\\partial out_{o1}}\\frac{\\partial out_{o1}}{\\partial net_{o1}}\\frac{\\partial net_{o1}}{\\partial w_5}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial L}{\\partial out_{o1}}$を計算する\n",
    "\n",
    "$$\n",
    "L= \\frac{1}{2}(target_{o_{1}}-out_{o_{1}})^2+\\frac{1}{2}(target_{o_{2}}-out_{o_{2}})^2\n",
    "$$\n",
    "合成関数の微分$g(f(x))= g^{\\prime}(f(x))f^{\\prime}(x)$によって\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial out_{o1}}= 2*\\frac{1}{2}(target_{o_{1}}-out_{o_{1}})*-1+0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_out_o1=0.7065932011681534\n"
     ]
    }
   ],
   "source": [
    "d_out_o1 = -(0.01-out_o1)\n",
    "print(\"d_out_o1={}\".format(d_out_o1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial out_{o1}}{\\partial net_{o1}}$を計算する\n",
    "$$\n",
    "out_{o1}= sigmod(net_{o_{1}})\n",
    "$$\n",
    "Sigmoid関数の微分は$f^{\\prime}(x)=f(x)(1-f(X))$なので\n",
    "$$\n",
    "\\frac{\\partial out_{o1}}{\\partial net_{o1}}= out_{o1}(1-out_{o1})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "\n",
    "シグモイド関数の勾配の証明\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{d y}{d x}\n",
    "   &= \\frac{d}{d x} \\Bigl\\{\n",
    "          \\frac{1}{1 + \\exp(-x)}\n",
    "      \\Bigr\\}\n",
    "\\\\\n",
    "   &= - \\frac{1}{(1 + \\exp(-x))^2}\n",
    "        \\frac{d}{d x} \\Bigl\\{\n",
    "            1 + \\exp(-x)\n",
    "        \\Bigr\\}\n",
    "\\\\\n",
    "   &= - \\frac{1}{(1 + \\exp(-x))^2} \\Bigl(\n",
    "            - \\exp(-x)\n",
    "        \\Bigr)\n",
    "\\\\\n",
    "   &= \\frac{\\exp(-x)}{(1 + \\exp(-x))^2}\n",
    "\\\\\n",
    "  &= \\frac{1}{1 + \\exp(-x)}\n",
    "      \\frac{\\exp(-x)}{1 + \\exp(-x)}\n",
    "\\\\\n",
    "   &= \\frac{1}{1 + \\exp(-x)}\n",
    "      \\frac{1 + \\exp(-x) - 1}{1 + \\exp(-x)}\n",
    "\\\\\n",
    "   &= \\frac{1}{1 + \\exp(-x)} \\left(\n",
    "          \\frac{1 + \\exp(-x)}{1 + \\exp(-x)}\n",
    "          - \\frac{1}{1 + \\exp(-x)}\n",
    "      \\right)\n",
    "\\\\\n",
    "   &= y (1 - y)\n",
    "    \\end{aligned}\n",
    "$$\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_net_o1=0.20308738520773184\n"
     ]
    }
   ],
   "source": [
    "d_net_o1 = out_o1*(1-out_o1)\n",
    "print(\"d_net_o1={}\".format(d_net_o1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial net_{o1}}{\\partial w_5}$を計算する\n",
    "$$\n",
    "net_{o_{1}}=w_{5}*net_{h_{1}}+w_{6}*net_{h_{2}}+b_{2}*1\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial net_{o1}}{\\partial w_5}= net_{h_{1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_w5=0.05417131252562742\n"
     ]
    }
   ],
   "source": [
    "d_w5= d_out_o1*d_net_o1*net_h1\n",
    "print(\"d_w5={}\".format(d_w5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パラメータを更新する\n",
    "$$w_5^+ = w_{5}- \\eta \\frac{\\partial {L}}{\\partial w_5}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
