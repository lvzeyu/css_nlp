{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 機械学習の基本概念\n",
    "\n",
    "\n",
    "## 教師あり学習\n",
    "\n",
    "機械学習は、コンピュータが大量のデータを学習することで、データの中に潜むパターンと規則性を抽出する技術です。ここで、「学習」は、観察されたデータをモデルに適合させるための調整可能な「パラメータ」を与えるために行われます。\n",
    "\n",
    "機械学習は「教師あり学習」や「教師なし学習」、「強化学習」などの枠組が存在します。ここでは、教師あり学習に注目します。\n",
    "\n",
    "教師あり学習（Supervised Learning）では、入力データ（特徴量）とそれに対応する正解ラベル（目標値）のペアを使用してモデルを訓練します。モデルは、入力データと正解ラベルの間の関係やパターンを学習し、未知の入力データに対して正しい予測や分類を行うことが期待されます。テキスト分類、構文解析、機械通訳などの様々な自然言語処理タスクは、教師あり学習の問題として定式化できます。\n",
    "\n",
    "教師データで学習した入出力の関係性がラベルを持たない未知の入力データにも使えるような関係性である必要があります。このように未知のデータにも対応できる性質を汎用性と言います。\n",
    "\n",
    "高い推定精度を持ちかつ汎用性の高い関係性を見つけるのは教師あり学習の目的になります。\n",
    "\n",
    "\n",
    "```{note} 機械学習モデルの基本概念\n",
    "- モデル：入力データと出力（ラベル）の関係を内部に持つ識別器。例えば、ニューラルネットワークを使うのか、あるいはサポートベクターマシンを使うのかなど枠組み（識別手法）の部分は人間が決める必要があります。\n",
    "- ハイパーパラメータ： モデルの構造・構成に関わる値。例えば、ニューラルネットワークの層数、学習率などの数値のこと．この数値で決められたモデルの構造に従って学習は進められます\n",
    "- 重み：モデルが内部に持っている、入力と出力の関係性を示す関数の係数にあたる部分。学習はこの重みをコンピュータが試行錯誤して決めていく作業になります．\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データ、検証データとテストデータ\n",
    "\n",
    "教師あり学習ではデータセットを「学習データ」、「検証データ」、「テストデータ」の3つに分けて使うのが一般的です。\n",
    "\n",
    "- 学習データ（Training Data）:モデルのパラメータを調整するために使用されます。学習データから、モデルがデータのパターンや関連性を「学び」ます。\n",
    "- 検証データ（Validation Data）: 検証データを使用してモデルの性能を評価し、その結果に基づいてハイパーパラメータを調整することができます。\n",
    "- テストデータ（Test Data）: このデータセットは、学習や検証のプロセスには一切使用されず、モデルの最終的な性能を評価するためだけに使用されます。テストデータを使用してモデルの性能を評価することで、実際の未知のデータに対するモデルの予測性能を推定することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 機械学習モデルの評価指標\n",
    "\n",
    "機械学習のモデルが良いか悪いかを評価するための評価基準は「評価指標」と言います。\n",
    "\n",
    "## 回帰タスク評価指標\n",
    "$y_i$は$i$個目サンプルの真の値、$p_i$は$i$個目サンプルの予測値とすると、\n",
    "\n",
    "- MAE（Mean Absolute Error）:平均絶対誤差\n",
    "$$\n",
    "MAE = \\frac{1}{N} \\cdot \\sum_{i=1}^{N} |y_i - p_i|\n",
    "$$\n",
    "\n",
    "- RMSE（Root Mean Squared Error）: 平均二乗誤差平方根\n",
    "\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{N} \\cdot \\sum_{i=1}^{N} (y_i - p_i)^2}\n",
    "$$\n",
    "\n",
    "## 分類タスク評価指標\n",
    "\n",
    "分類タスクの評価指標は、よくある二分類タスクで説明します。分類の実際値と予測値は下記の４種類があります。\n",
    "\n",
    "![](./Figure/metrics.png)\n",
    "\n",
    "- TP：True Positive 真陽性\n",
    "- FN：False Negative 偽陰性\n",
    "- FP：False Positive 偽陽性\n",
    "- TN：True Negative 真陰性\n",
    "\n",
    "### 正解率（Accuracy）\n",
    "\n",
    "正解率は、正や負と予測したデータのうち、実際にそうであるものの割合です。\n",
    "\n",
    "$$\n",
    "{Accuracy= \\frac{TP+TN}{TP+FP+TN+FN}\n",
    "}\n",
    "$$\n",
    "\n",
    "### 適合率（Precision）\n",
    "適合率は、正と予測したデータのうち，実際に正であるものの割合です。\n",
    "\n",
    "$$\n",
    "{Precision= \\frac{TP}{TP+FP}\n",
    "}\n",
    "$$\n",
    "\n",
    "### 再現率（Recall）\n",
    "\n",
    "再現率は、実際に正であるもののうち，正であると予測されたものの割合です。\n",
    "\n",
    "$$\n",
    "{Recall = \\frac{TP}{TP+FN}\n",
    "}\n",
    "$$\n",
    "\n",
    "### F-1値（F-1 score）\n",
    "\n",
    "F値は、再現率と適合率の調和平均です。\n",
    "\n",
    "$$\n",
    "{F = \\frac{2\\cdot Recall \\cdot Precision}{Recall+Precision}\n",
    "}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 過学習\n",
    "\n",
    "過学習(Overfitting)とは、データの傾向に沿うようにモデルを学習させた結果、学習時のデータに対してはよい精度を出すが、未知データに対しては同様の精度を出せないモデルが構築されてしまうことです。\n",
    "\n",
    "![](./Figure/overfitting.jpeg)\n",
    "\n",
    "過学習を防ぐための一つの方法としては、交差検証法を使うことです。\n",
    "\n",
    "交差検証とは、1つのデータを訓練データと検証データに分けるときに複数の分け方をして平均をとるという方法です。データの分け方を複数作ることでリスクを分散し、訓練データと検証データの傾向の違いにより生じる過学習を最小化します。\n",
    "\n",
    "最もよく使われるK-交差検証では、\n",
    "\n",
    "- 全体データをK個にデータを分割します。\n",
    "- A～Kまであるうち、最初にAを検証データにしてB～Kのデータから予測モデルを作成。\n",
    "- Bを検証データにしてAとC～Kのデータから予測モデルを作成という流れで順番にK回検証していきます.\n",
    "![](./Figure/k-val.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習では、実数値を要素とするベクトルで入力を表現することが多いです。適切な特徴(feature)を生データから作成すること、機械学習モデル性能も向上につながります。テキストデータもベクトク化する必要があります。\n",
    "\n",
    "### n-gramベクトル\n",
    "\n",
    "n-gramは、テキストデータやシーケンスデータの連続するN個のアイテム（文字、単語など）を指す言葉です。特に$n=1$の場合をuni-gram, $n=2$の場合をbi-gramと呼びます。\n",
    "\n",
    "例えば、```I love machine learning```という文をn-gramで表現してみます。$n=1$の場合は```[\"I\", \"love\", \"machine\", \"learning\"]```、$n=2$の場合は```[\"I love\", \"love machine\", \"machine learning\"]```、$n=3$の場合は```[\"I love machine\", \"love machine learning\"]```のようにテキストを表現できます。\n",
    "\n",
    "抽出されたN-gramを一意なものとしてリストアップし、各n-gramに対して重複のないように数値を割り当てます。これを語彙(vocabulary)と呼びます。\n",
    "\n",
    "次に、 テキストごとに、語彙に含まれるN-gramの出現頻度や存在をベクトルとして表現します。\n",
    "\n",
    "```{note}\n",
    "n-gramでは、ある程度にローカルな情報、文の構造や単語の順序を考慮することができます。一方、語彙のサイズが大きくなると、スパースなベクトルが生成され、計算コストが高くになるなどの欠点もあります。そのため、N-gramベクトルはある意味で「古典的な」特徴量表現になります。現在のNLPの分野では、埋め込みベクトルや事前学習済みモデルを使用する手法が主流になっています。\n",
    "```\n",
    "\n",
    "### one-hotエンコーディング\n",
    "\n",
    "one-hotエンコーディングでは、ある単語がテキストに存在するかどうかでベクトルを作成します。具体的には、\n",
    "\n",
    "- 語彙（ユニークな単語のリスト）を作成する。\n",
    "- この語彙のサイズをベクトルの長さとし、各単語が語彙のどの位置に存在するかに応じて1の値を持つベクトルを生成する。\n",
    "\n",
    "例えば、以下の語彙に基づいて、“like a banana”のone-hotエンコーディング結果は```[0, 0, 0, 1, 1, 0, 0, 1]```\n",
    "\n",
    "![](./Figure/one_hot.png)\n",
    "\n",
    "### tf-idf\n",
    "\n",
    "tf-idfとは、「ある文書内」で「ある単語」が「どれくらい多い頻度で出現するか」を表すtf（term frequency：単語頻度）値と、「全文書中」で「ある単語を含む文書」が「（逆に）どれくらい少ない頻度で存在するか」を表すidf（inverse document frequency：逆文書頻度）値を掛け合わせた値のことです。\n",
    "\n",
    "- Term Frequency (TF): 特定の文書内の単語の出現頻度を表します。\n",
    "- Inverse Document Frequency (IDF): コーパス全体において、特定の単語がどれほど珍しいかを評価する指標です。\n",
    "\n",
    "$$\n",
    "td-idf(t,d)=tf(t,d) \\times idf(t)\n",
    "$$\n",
    "\n",
    "$$\n",
    "idf(t)=log (\\frac{全文書の数}{単語が含まれる文書の数})\n",
    "$$\n",
    "\n",
    "要するには、tf-idfの基本的な考え方は、ある単語が多くの文書に出現するなら、その単語は一般的に重要でないと考えられます。例えば、ある文書で「の」の出現頻度は高いが、同時に多くの文書に出現すると重要性が小さくなります。\n",
    "\n",
    "\n",
    "```{note}\n",
    "ここまでテキストベクトル化の手法を説明しましたが、実に、これらの手法では単語の意味や関係をうまく捉えない、大規模のテキストデータに対応できない、汎用性は低いなどの欠点が挙げられます。これらの制約を克服するため、現在のNLPの分野では、埋め込みベクトルや事前学習済みモデルを使用する手法が主流になっています。\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
