
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>機械学習の基本概念 &#8212; 計算社会科学のための自然言語処理</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="&lt;no title&gt;" href="math_basis.html" />
    <link rel="prev" title="自然言語処理の基礎" href="nlp_basis.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/tohoku-university-logo-vector.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">計算社会科学のための自然言語処理</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    計算社会科学と自然言語処理
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  イントロダクション
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="introduction.html">
   ガイダンス
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  基礎知識
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="nlp_basis.html">
   自然言語処理の基礎
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   機械学習の基本概念
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ニューラルネットワーク
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="NN.html">
   ニューラルネットワーク
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="backpropagation.html">
   誤差逆伝播法
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="pytorch.html">
   Pytorch
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/lvzeyu/css_nlp/master?urlpath=lab/tree/notebook/ml_basis.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/lvzeyu/css_nlp/blob/master/notebook/ml_basis.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/lvzeyu/css_nlp/tree/master"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/lvzeyu/css_nlp/tree/master/issues/new?title=Issue%20on%20page%20%2Fnotebook/ml_basis.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/notebook/ml_basis.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   教師あり学習
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   機械学習のデータ構造
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     学習データ、検証データとテストデータ
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     学習データの投入方法
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id6">
   ミニバッチ学習
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   機械学習モデルの評価指標
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   回帰タスク評価指標
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id9">
   分類タスク評価指標
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#accuracy">
     正解率（Accuracy）
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#precision">
     適合率（Precision）
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recall">
     再現率（Recall）
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#f-1-f-1-score">
     F-1値（F-1 score）
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id10">
   過学習
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id11">
   機械学習のハイパーパラメータ
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#epoch">
     エポック(epoch)数
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#iteration">
     イテレーション (Iteration)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learning-rate">
     学習率(Learning Rate)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id12">
   特徴量表現
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#n-gram">
     n-gramベクトル
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-hot">
     one-hotエンコーディング
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tf-idf">
     tf-idf
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>機械学習の基本概念</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   教師あり学習
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   機械学習のデータ構造
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     学習データ、検証データとテストデータ
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     学習データの投入方法
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id6">
   ミニバッチ学習
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   機械学習モデルの評価指標
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   回帰タスク評価指標
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id9">
   分類タスク評価指標
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#accuracy">
     正解率（Accuracy）
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#precision">
     適合率（Precision）
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recall">
     再現率（Recall）
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#f-1-f-1-score">
     F-1値（F-1 score）
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id10">
   過学習
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id11">
   機械学習のハイパーパラメータ
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#epoch">
     エポック(epoch)数
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#iteration">
     イテレーション (Iteration)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learning-rate">
     学習率(Learning Rate)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id12">
   特徴量表現
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#n-gram">
     n-gramベクトル
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-hot">
     one-hotエンコーディング
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tf-idf">
     tf-idf
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1>機械学習の基本概念<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h1>
<section id="id2">
<h2>教師あり学習<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h2>
<p>機械学習は、コンピュータが大量のデータを学習することで、データの中に潜むパターンと規則性を抽出する技術です。ここで、「学習」は、観察されたデータをモデルに適合させるための調整可能な「パラメータ」を与えるために行われます。</p>
<p>機械学習は「教師あり学習」や「教師なし学習」、「強化学習」などの枠組が存在します。ここでは、教師あり学習に注目します。</p>
<p><strong><u>教師あり学習（Supervised Learning）では、入力データ（特徴量）とそれに対応する正解ラベル（目標値）のペアを使用してモデルを訓練します。</strong></u></p>
<p>モデルは、<strong><u>入力データと正解ラベルの間の関係やパターンを学習し、未知の入力データに対して正しい予測や分類を行うことが期待されます。</strong></u>テキスト分類、構文解析、機械通訳などの様々な自然言語処理タスクは、教師あり学習の問題として定式化できます。</p>
<p>教師データで学習した入出力の関係性がラベルを持たない未知の入力データにも使えるような関係性である必要があります。このように未知のデータにも対応できる性質を <strong><u>汎用性</strong></u> と言います。</p>
<p>高い推定精度を持ちかつ汎用性の高い関係性を見つけるのは教師あり学習の目的になります。</p>
</section>
<section id="id3">
<h2>機械学習のデータ構造<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h2>
<section id="id4">
<h3>学習データ、検証データとテストデータ<a class="headerlink" href="#id4" title="Permalink to this headline">#</a></h3>
<p>教師あり学習ではデータセットを「学習データ」、「検証データ」、「テストデータ」の3つに分けて使うのが一般的です。</p>
<ul class="simple">
<li><p><strong>学習データ（Training Data）</strong>:モデルのパラメータを調整するために使用されます。学習データから、モデルがデータのパターンや関連性を「学び」ます。</p></li>
<li><p><strong>検証データ（Validation Data）</strong>: 検証データを使用してモデルの性能を評価し、その結果に基づいてハイパーパラメータを調整することができます。</p></li>
<li><p><strong>テストデータ（Test Data）</strong>: このデータセットは、学習や検証のプロセスには一切使用されず、モデルの最終的な性能を評価するためだけに使用されます。テストデータを使用してモデルの性能を評価することで、実際の未知のデータに対するモデルの予測性能を推定することができます。</p></li>
</ul>
</section>
<section id="id5">
<h3>学習データの投入方法<a class="headerlink" href="#id5" title="Permalink to this headline">#</a></h3>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>機械学習のにおける「バッチ」は、学習アルゴリズムに一度に供給されるデータのサブセットを指します。「バッチサイズ」とは、学習プロセスにおいて、一度にモデルに供給されるサンプルの数を指します。</p>
</aside>
<ul class="simple">
<li><p>バッチ学習: 全ての学習データを利用して学習する手法です。つまり、バッチサイズはトレーニングデータの全サンプル数と等しくなります。この方法の利点は、計算が効率的であることですが、大量のメモリが必要になることや局所的な最適解にトラップされやすいという欠点もあります。</p></li>
<li><p>オンライン学習:ひとつひとつの学習データごとに学習処理を行います。具体的には、n個の学習データ<span class="math notranslate nohighlight">\(x_1、x_2、…、x_n\)</span>からランダムに1つの学習データ<span class="math notranslate nohighlight">\(x_i\)</span>を抽出し、その1つのデータをモデルに投入します。オンライン学習は一件ずつの計算処理を採用しているため、常に更新される最新データ情報も柔軟に取り入れることができます。一方で、パラメータの更新をデータ一件ごとに行うので、学習を安定させることが難しいのもオンライン学習の懸念点です。</p></li>
<li><p><strong>ミニバッチ学習</strong>: バッチ学習とオンライン学習の中間のような学習手法であり、<strong><u>データをミニバッチという小さなグループに分割してモデルを学習します。</strong></u>バッチ学習は、計算効率とメモリの使用のバランスが良いこと、および学習の収束速度が適切であるため、一般的に最も使用される方法です。</p></li>
</ul>
</section>
</section>
<section id="id6">
<h2>ミニバッチ学習<a class="headerlink" href="#id6" title="Permalink to this headline">#</a></h2>
</section>
<section id="id7">
<h2>機械学習モデルの評価指標<a class="headerlink" href="#id7" title="Permalink to this headline">#</a></h2>
<p>機械学習のモデルが良いか悪いかを評価するための評価基準は「評価指標」と言います。</p>
</section>
<section id="id8">
<h2>回帰タスク評価指標<a class="headerlink" href="#id8" title="Permalink to this headline">#</a></h2>
<p><span class="math notranslate nohighlight">\(y_i\)</span>は<span class="math notranslate nohighlight">\(i\)</span>個目サンプルの真の値、<span class="math notranslate nohighlight">\(p_i\)</span>は<span class="math notranslate nohighlight">\(i\)</span>個目サンプルの予測値とすると、</p>
<ul class="simple">
<li><p>MAE（Mean Absolute Error）:平均絶対誤差</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
MAE = \frac{1}{N} \cdot \sum_{i=1}^{N} |y_i - p_i|
\]</div>
<ul class="simple">
<li><p>RMSE（Root Mean Squared Error）: 平均二乗誤差平方根</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
RMSE = \sqrt{\frac{1}{N} \cdot \sum_{i=1}^{N} (y_i - p_i)^2}
\]</div>
</section>
<section id="id9">
<h2>分類タスク評価指標<a class="headerlink" href="#id9" title="Permalink to this headline">#</a></h2>
<p>分類タスクの評価指標は、よくある二分類タスクで説明します。分類の実際値と予測値は下記の４種類があります。</p>
<p><img alt="" src="../_images/metrics.png" /></p>
<ul class="simple">
<li><p>TP：True Positive 真陽性</p></li>
<li><p>FN：False Negative 偽陰性</p></li>
<li><p>FP：False Positive 偽陽性</p></li>
<li><p>TN：True Negative 真陰性</p></li>
</ul>
<section id="accuracy">
<h3>正解率（Accuracy）<a class="headerlink" href="#accuracy" title="Permalink to this headline">#</a></h3>
<p>正解率は、正や負と予測したデータのうち、実際にそうであるものの割合です。</p>
<div class="math notranslate nohighlight">
\[
{Accuracy= \frac{TP+TN}{TP+FP+TN+FN}
}
\]</div>
</section>
<section id="precision">
<h3>適合率（Precision）<a class="headerlink" href="#precision" title="Permalink to this headline">#</a></h3>
<p>適合率は、正と予測したデータのうち，実際に正であるものの割合です。</p>
<div class="math notranslate nohighlight">
\[
{Precision= \frac{TP}{TP+FP}
}
\]</div>
</section>
<section id="recall">
<h3>再現率（Recall）<a class="headerlink" href="#recall" title="Permalink to this headline">#</a></h3>
<p>再現率は、実際に正であるもののうち，正であると予測されたものの割合です。</p>
<div class="math notranslate nohighlight">
\[
{Recall = \frac{TP}{TP+FN}
}
\]</div>
</section>
<section id="f-1-f-1-score">
<h3>F-1値（F-1 score）<a class="headerlink" href="#f-1-f-1-score" title="Permalink to this headline">#</a></h3>
<p>F値は、再現率と適合率の調和平均です。</p>
<div class="math notranslate nohighlight">
\[
{F = \frac{2\cdot Recall \cdot Precision}{Recall+Precision}
}
\]</div>
</section>
</section>
<section id="id10">
<h2>過学習<a class="headerlink" href="#id10" title="Permalink to this headline">#</a></h2>
<p><strong><u>過学習(Overfitting)</strong></u>とは、データの傾向に沿うようにモデルを学習させた結果、学習時のデータに対してはよい精度を出すが、未知データに対しては同様の精度を出せないモデルが構築されてしまうことです。</p>
<p><img alt="" src="../_images/overfitting.jpeg" /></p>
<p>過学習を防ぐための一つの方法としては、交差検証法を使うことです。</p>
<p><strong><u>交差検証とは、1つのデータを訓練データと検証データに分けるときに複数の分け方をして平均をとるという方法です。</strong></u>　データの分け方を複数作ることでリスクを分散し、訓練データと検証データの傾向の違いにより生じる過学習を最小化します。</p>
<p>最もよく使われるK-交差検証では、</p>
<ul class="simple">
<li><p>全体データをK個にデータを分割します。</p></li>
<li><p>A～Kまであるうち、最初にAを検証データにしてB～Kのデータから予測モデルを作成。</p></li>
<li><p>Bを検証データにしてAとC～Kのデータから予測モデルを作成という流れで順番にK回検証していきます.
<img alt="" src="../_images/k-val.png" /></p></li>
</ul>
</section>
<section id="id11">
<h2>機械学習のハイパーパラメータ<a class="headerlink" href="#id11" title="Permalink to this headline">#</a></h2>
<p><strong><u>機械学習のハイパーパラメータは、学習アルゴリズムの動作を制御するためのパラメータです。</strong></u></p>
<p>これらのハイパーパラメータは、モデルの学習プロセスの前に設定され、学習中には通常変わりません。ハイパーパラメータの設定に応じてモデルの精度やパフォーマンスが大きく変わることがあります。</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>対照的に、パラメータとは、おもに機械学習モデルが学習過程において最適化を行う重みを指します。</p>
</aside>
<p>ここでは、多くの機械学習・深層学習モデルに共通しているくつかのハイパーパラメータを紹介します。</p>
<section id="epoch">
<h3>エポック(epoch)数<a class="headerlink" href="#epoch" title="Permalink to this headline">#</a></h3>
<p>機械学習・深層学習ようにパラメータの数が多いものになると、訓練データを何回も繰り返する必要があります。<strong><u>エポック数とは、学習において、データセットを何週繰り返してパラメータを調整するかを表す数を指します。1エポックは、トレーニングデータセット全体が一度、モデルを通過することを意味します。</strong></u></p>
<p>例えば、データ件数が<span class="math notranslate nohighlight">\(1000\)</span>件で、バッチサイズが<span class="math notranslate nohighlight">\(100\)</span>なら、<span class="math notranslate nohighlight">\(10\)</span>回繰り返すと、<span class="math notranslate nohighlight">\(1000件\)</span>のデータに相当する件数分処理したことになります。この１単位のことを「エポック」と呼びます。</p>
<p>一般的には、エポック数が増えるほどモデルは訓練データに適応しやすくなります。しかし、エポック数が大きすぎると過学習のリスクが高まります。適切なエポック数を選ぶことで、モデルの性能を最大限引き出すことができます。</p>
</section>
<section id="iteration">
<h3>イテレーション (Iteration)<a class="headerlink" href="#iteration" title="Permalink to this headline">#</a></h3>
<p>イテレーション数はデータセットに含まれるデータが少なくとも1回は学習に用いられるのに必要な学習回数であり、バッチサイズが決まれば自動的に決まる数値です。先程の<span class="math notranslate nohighlight">\(1000\)</span>件のデータセットを<span class="math notranslate nohighlight">\(100\)</span>件ずつのサブセットに分ける場合では、イテレーション数は<span class="math notranslate nohighlight">\(10\)</span>となります。</p>
<p><img alt="" src="../_images/batch_learning.png" /></p>
</section>
<section id="learning-rate">
<h3>学習率(Learning Rate)<a class="headerlink" href="#learning-rate" title="Permalink to this headline">#</a></h3>
<p><strong><u>学習率とは、機械学習の最適化において、重みパラメータを一度にどの程度変化させるかを表すハイパーパラメータのことです。</strong></u></p>
<p>機械学習とは、反復的に重みパラメータを変更していきますが、学習率の値が高いほど一度に変更する重みパラメータの大きさが大きくなるので学習のスピードは上がり、反対に低ければ学習のスピードは下がります。</p>
<p><img alt="" src="../_images/learning_rate.png" /></p>
</section>
</section>
<section id="id12">
<h2>特徴量表現<a class="headerlink" href="#id12" title="Permalink to this headline">#</a></h2>
<p>機械学習では、実数値を要素とするベクトルで入力を表現することが多いです。適切な特徴(feature)を生データから作成すること、機械学習モデル性能も向上につながります。</p>
<p>テキストデータもベクトク化する必要があります。</p>
<section id="n-gram">
<h3>n-gramベクトル<a class="headerlink" href="#n-gram" title="Permalink to this headline">#</a></h3>
<p>n-gramは、テキストデータやシーケンスデータの連続するN個のアイテム（文字、単語など）を指す言葉です。特に<span class="math notranslate nohighlight">\(n=1\)</span>の場合をuni-gram, <span class="math notranslate nohighlight">\(n=2\)</span>の場合をbi-gramと呼びます。</p>
<p>例えば、<code class="docutils literal notranslate"><span class="pre">I</span> <span class="pre">love</span> <span class="pre">machine</span> <span class="pre">learning</span></code>という文をn-gramで表現してみます。<span class="math notranslate nohighlight">\(n=1\)</span>の場合は<code class="docutils literal notranslate"><span class="pre">[&quot;I&quot;,</span> <span class="pre">&quot;love&quot;,</span> <span class="pre">&quot;machine&quot;,</span> <span class="pre">&quot;learning&quot;]</span></code>、<span class="math notranslate nohighlight">\(n=2\)</span>の場合は<code class="docutils literal notranslate"><span class="pre">[&quot;I</span> <span class="pre">love&quot;,</span> <span class="pre">&quot;love</span> <span class="pre">machine&quot;,</span> <span class="pre">&quot;machine</span> <span class="pre">learning&quot;]</span></code>、<span class="math notranslate nohighlight">\(n=3\)</span>の場合は<code class="docutils literal notranslate"><span class="pre">[&quot;I</span> <span class="pre">love</span> <span class="pre">machine&quot;,</span> <span class="pre">&quot;love</span> <span class="pre">machine</span> <span class="pre">learning&quot;]</span></code>のようにテキストを表現できます。</p>
<p>抽出されたN-gramを一意なものとしてリストアップし、各n-gramに対して重複のないように数値を割り当てます。これを語彙(vocabulary)と呼びます。</p>
<p>次に、 テキストごとに、語彙に含まれるN-gramの出現頻度や存在をベクトルとして表現します。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>n-gramでは、ある程度にローカルな情報、文の構造や単語の順序を考慮することができます。一方、語彙のサイズが大きくなると、スパースなベクトルが生成され、計算コストが高くになるなどの欠点もあります。そのため、N-gramベクトルはある意味で「古典的な」特徴量表現になります。現在のNLPの分野では、埋め込みベクトルや事前学習済みモデルを使用する手法が主流になっています。</p>
</div>
</section>
<section id="one-hot">
<h3>one-hotエンコーディング<a class="headerlink" href="#one-hot" title="Permalink to this headline">#</a></h3>
<p>one-hotエンコーディングでは、ある単語がテキストに存在するかどうかでベクトルを作成します。具体的には、</p>
<ul class="simple">
<li><p>語彙（ユニークな単語のリスト）を作成する。</p></li>
<li><p>この語彙のサイズをベクトルの長さとし、各単語が語彙のどの位置に存在するかに応じて1の値を持つベクトルを生成する。</p></li>
</ul>
<p>例えば、以下の語彙に基づいて、“like a banana”のone-hotエンコーディング結果は<code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">0,</span> <span class="pre">0,</span> <span class="pre">1,</span> <span class="pre">1,</span> <span class="pre">0,</span> <span class="pre">0,</span> <span class="pre">1]</span></code></p>
<p><img alt="" src="../_images/one_hot.png" /></p>
</section>
<section id="tf-idf">
<h3>tf-idf<a class="headerlink" href="#tf-idf" title="Permalink to this headline">#</a></h3>
<p>tf-idfとは、「ある文書内」で「ある単語」が「どれくらい多い頻度で出現するか」を表すtf（term frequency：単語頻度）値と、「全文書中」で「ある単語を含む文書」が「（逆に）どれくらい少ない頻度で存在するか」を表すidf（inverse document frequency：逆文書頻度）値を掛け合わせた値のことです。</p>
<ul class="simple">
<li><p>Term Frequency (TF): 特定の文書内の単語の出現頻度を表します。</p></li>
<li><p>Inverse Document Frequency (IDF): コーパス全体において、特定の単語がどれほど珍しいかを評価する指標です。</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
td-idf(t,d)=tf(t,d) \times idf(t)
\]</div>
<div class="math notranslate nohighlight">
\[
idf(t)=log (\frac{全文書の数}{単語が含まれる文書の数})
\]</div>
<p>要するには、tf-idfの基本的な考え方は、ある単語が多くの文書に出現するなら、その単語は一般的に重要でないと考えられます。例えば、ある文書で「の」の出現頻度は高いが、同時に多くの文書に出現すると重要性が小さくなります。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>ここまでテキストベクトル化の手法を説明しましたが、実に、これらの手法では単語の意味や関係をうまく捉えない、大規模のテキストデータに対応できない、汎用性は低いなどの欠点が挙げられます。これらの制約を克服するため、現在のNLPの分野では、埋め込みベクトルや事前学習済みモデルを使用する手法が主流になっています。</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>モデル：入力データから出力を予測するための数学的表現やアルゴリズムです。例として、線形回帰、決定木、ニューラルネットワークなどが挙げられます。</p></li>
<li><p>ハイパーパラメータ：モデルの学習プロセスを制御するための外部から設定されるパラメータです。ハイパーパラメータは学習データから自動的に学習されるものではなく、手動で設定されるか、ハイパーパラメータチューニングの技法を用いて最適な値を探索します。例えば、学習率、バッチサイズ、エポック数、ドロップアウト率のこと．この数値で決められたモデルの構造に従って学習は進められます。</p></li>
<li><p>重み：重みは、モデルの学習プロセス中にデータから自動的に調整・学習される内部パラメータです。重みは、入力特徴との関係性を学習し、最終的な予測を形成するのに役立ちます。一般的には、重みは、モデルの出力を調整して、実際のターゲットとの差を最小化することを目指します。学習はこの重みを試行錯誤して決めていく作業になります．</p></li>
</ul>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebook"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="nlp_basis.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">自然言語処理の基礎</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="math_basis.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">&lt;no title&gt;</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By 呂　沢宇<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>