
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>センチメント分析の実装 &#8212; 計算社会科学のための自然言語処理</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=bd9e20870c6007c4c509" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=bd9e20870c6007c4c509" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=bd9e20870c6007c4c509" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=bd9e20870c6007c4c509" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=bd9e20870c6007c4c509" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=bd9e20870c6007c4c509" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=bd9e20870c6007c4c509"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebook/bert_sentiment_jp';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <header>
  
    <div class="bd-header navbar navbar-expand-lg bd-navbar">
    </div>
  
  </header>

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/tohoku-university-logo-vector.svg" class="logo__image only-light" alt="計算社会科学のための自然言語処理 - Home"/>
    <script>document.write(`<img src="../_static/tohoku-university-logo-vector.svg" class="logo__image only-dark" alt="計算社会科学のための自然言語処理 - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    計算社会科学と自然言語処理
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">イントロダクション</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">ガイダンス</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">基礎知識</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="nlp_basis2.html">自然言語処理の基礎</a></li>
<li class="toctree-l1"><a class="reference internal" href="ml_basis2.html">機械学習の基本概念</a></li>
<li class="toctree-l1"><a class="reference internal" href="math_basis2.html">数学基礎</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ニューラルネットワーク</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="NN.html">ニューラルネットワーク</a></li>
<li class="toctree-l1"><a class="reference internal" href="backpropagation.html">誤差逆伝播法</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">PyTorch</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="pytorch.html">Pytorch</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">単語分散表現</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="word2vec_1.html">単語分散表現</a></li>
<li class="toctree-l1"><a class="reference internal" href="word2vec_2_embedding.html">word2vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="word2vec_gensim.html">GensimによるWord2Vecの学習と使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="word2vec_sentiment.html">Word2Vecを用いるセンチメント分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="word2vec_application.html">Word2Vecが人文・社会科学研究における応用</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">RNN</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="rnn.html">RNNの基礎</a></li>
<li class="toctree-l1"><a class="reference internal" href="lstm.html">LSTM</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_lstm.html">LSTMの実装</a></li>
<li class="toctree-l1"><a class="reference internal" href="lstm_classification.html">LSTMによる文書分類</a></li>
<li class="toctree-l1"><a class="reference internal" href="seq2seq.html">Seq2seq</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Transformer</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="attention.html">Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="self-attention.html">Self-Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="transformer.html">Transformerアーキテクチャ</a></li>
<li class="toctree-l1"><a class="reference internal" href="BERT.html">BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="bert_sentiment.html">BERTによるセンチメント分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="bert_topic.html">BERTopic</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">大規模言語モデル</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="GPT.html">GPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm.html">大規模言語モデルの基本</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/lvzeyu/css_nlp/blob/master/notebook/bert_sentiment_jp.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/lvzeyu/css_nlp" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/lvzeyu/css_nlp/issues/new?title=Issue%20on%20page%20%2Fnotebook/bert_sentiment_jp.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebook/bert_sentiment_jp.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>センチメント分析の実装</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">データセット</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hugging-face">Hugging Faceからサンプルデータの取得</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">サンプルデータの確認</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">テキストの確認</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">トークン化</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">トークナイザの動作確認</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">データセット全体のトークン化</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">分類器の実装</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">事前学習モデルの導入</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">分類器の学習</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#automodelforsequenceclassification">AutoModelForSequenceClassificationのファインチューニング</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">学習の準備</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">学習済みモデルの使用</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">モデル精度の検証</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">モデル保存</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">学習済みモデルの読み込み</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="id1">
<h1>センチメント分析の実装<a class="headerlink" href="#id1" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>nvidia-smi
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>zsh:1: command not found: nvidia-smi
</pre></div>
</div>
</div>
</div>
<section id="id2">
<h2>データセット<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<section id="hugging-face">
<h3>Hugging Faceからサンプルデータの取得<a class="headerlink" href="#hugging-face" title="Link to this heading">#</a></h3>
<p>Hugging Faceのには色々なデータセットが用意されております。ここでは、多言語のセンチメントデータセットを例として使用することにします。その中に、英語と日本語のサプセットが含まれます。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">wandb</span>
<span class="n">wandb</span><span class="o">.</span><span class="n">login</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Blue">wandb</span>: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Blue">wandb</span>: Currently logged in as: <span class=" -Color -Color-Yellow">lvzeyu1995</span> (<span class=" -Color -Color-Yellow">lvzeyu1995-tohoku-university</span>). Use <span class=" -Color -Color-Bold">`wandb login --relogin`</span> to force relogin
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;WANDB_PROJECT&quot;</span><span class="p">]</span><span class="o">=</span><span class="s2">&quot;sentiment_analysis_jp&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;tyqiangz/multilingual-sentiments&quot;</span><span class="p">,</span> <span class="s2">&quot;japanese&quot;</span><span class="p">)</span>
<span class="c1">#dataset = load_dataset(&quot;tyqiangz/multilingual-sentiments&quot;, &quot;english&quot;)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id3">
<h3>サンプルデータの確認<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<p>取得したデータセットの中身を確認します。</p>
<p>データセットはこのようにtrain, validation, testに分かれています。
[‘text’, ‘source’, ‘label’]といった情報を持っています。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DatasetDict({
    train: Dataset({
        features: [&#39;text&#39;, &#39;source&#39;, &#39;label&#39;],
        num_rows: 10000
    })
    validation: Dataset({
        features: [&#39;text&#39;, &#39;source&#39;, &#39;label&#39;],
        num_rows: 3000
    })
    test: Dataset({
        features: [&#39;text&#39;, &#39;source&#39;, &#39;label&#39;],
        num_rows: 3000
    })
})
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">)</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][:]</span>
<span class="n">train_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>source</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4つ購入したが、2つは使用できず。接触が悪いのかわからないが、2度と購入しません</td>
      <td>amazon_reviews_multi</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>キャンプでカセットコンロを使用しています。 キャンプでちょっと変わった事がしたくて購入！笑 ...</td>
      <td>amazon_reviews_multi</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>こちらのiTunesカード200＄分を購入しました。 50＄４枚購入したはずが、届いたのは5...</td>
      <td>amazon_reviews_multi</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>macbook pro 13インチと書いてあったので書いてあったので購入しましたが2016l...</td>
      <td>amazon_reviews_multi</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>安かろう悪かろうです。 TVはが悪く暗く自動サーチなしでいちいちサーチしなおさなければダメ。...</td>
      <td>amazon_reviews_multi</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">features</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;text&#39;: Value(dtype=&#39;string&#39;, id=None),
 &#39;source&#39;: Value(dtype=&#39;string&#39;, id=None),
 &#39;label&#39;: ClassLabel(names=[&#39;positive&#39;, &#39;neutral&#39;, &#39;negative&#39;], id=None)}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;barh&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Train Dataset&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: title={&#39;center&#39;: &#39;Train Dataset&#39;}, ylabel=&#39;label&#39;&gt;
</pre></div>
</div>
<img alt="../_images/df8f11de3004f44b22b8dda92f7974d412a647746e100a06dc0882ce4312631c.png" src="../_images/df8f11de3004f44b22b8dda92f7974d412a647746e100a06dc0882ce4312631c.png" />
</div>
</div>
</section>
<section id="id4">
<h3>テキストの確認<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<p>Transformerモデルは、最大コンテキストサイズ(maximum context size)と呼ばれる最大入力系列長があります。</p>
<p>モデルのコンテキストサイズより長いテキストは切り捨てる必要があり、切り捨てたテキストに重要な情報が含まれている場合、性能の低下につながることがあります。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;text_length&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="s2">&quot;text_length&quot;</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: title={&#39;center&#39;: &#39;text_length&#39;}, xlabel=&#39;label&#39;&gt;
</pre></div>
</div>
<img alt="../_images/8047a8a35b88b8ea566f68e46f46f62866c0e046c9746011e36d256c3cd797ca.png" src="../_images/8047a8a35b88b8ea566f68e46f46f62866c0e046c9746011e36d256c3cd797ca.png" />
</div>
</div>
</section>
</section>
<section id="id5">
<h2>トークン化<a class="headerlink" href="#id5" title="Link to this heading">#</a></h2>
<p>コンピュータは、入力として生の文字列を受け取ることができません。その代わりに、テキストがトークン化され、数値ベクトルとしてエンコードされていることが想定しています。</p>
<p>トークン化は、文字列をモデルで使用される最小単位に分解するステップです。</p>
<p>Transformerライブラリー は便利なAutoTokenizerクラスを提供しており、事前学習済みモデルに関連つけられたトークナイザーを素早く使用することができます。</p>
<section id="id6">
<h3>トークナイザの動作確認<a class="headerlink" href="#id6" title="Link to this heading">#</a></h3>
<p>tokenizerテキストを数値形式（トークン）に変換します。</p>
<ul class="simple">
<li><p>入力テキストをトークンに分割します</p></li>
<li><p>特殊トークンが自動的に付加されます</p></li>
<li><p>トークンをトークンIDに変換します</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="n">model_ckpt</span> <span class="o">=</span> <span class="s2">&quot;tohoku-nlp/bert-base-japanese&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_ckpt</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/ryozawau/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/Users/ryozawau/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;4つ購入したが、2つは使用できず。接触が悪いのかわからないが、2度と購入しません&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_text_encoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sample_text_encoded</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;input_ids&#39;: [2, 57, 181, 2630, 15, 10, 14, 6, 25, 181, 9, 406, 203, 255, 8, 5278, 14, 6981, 5, 29, 11183, 80, 14, 6, 25, 559, 13, 2630, 15, 6769, 1058, 3], &#39;token_type_ids&#39;: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
</pre></div>
</div>
</div>
</div>
<p>結果にinput_idsとattention_maskが含まれます。</p>
<ul class="simple">
<li><p>input_ids: 数字にエンコードされたトークン</p></li>
<li><p>attention_mask: モデルで有効なトークンかどうかを判別するためのマスクです。無効なトークン（例えば、PADなど）に対しては、attention_maskを
として処理します。</p></li>
</ul>
<p>各batchにおいて、入力系列はbatch内最大系列長までpaddingされます。</p>
<p><img alt="" src="../_images/attention_id.png" /></p>
<p>トークナイザの結果は数字にエンコードされているため、トークン文字列を得るには、convert_ids_to_tokensを用います。</p>
<p>文の開始が[CLS]、文の終了が[SEP]という特殊なトークンとなっています。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">sample_text_encoded</span><span class="o">.</span><span class="n">input_ids</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;[CLS]&#39;, &#39;4&#39;, &#39;つ&#39;, &#39;購入&#39;, &#39;し&#39;, &#39;た&#39;, &#39;が&#39;, &#39;、&#39;, &#39;2&#39;, &#39;つ&#39;, &#39;は&#39;, &#39;使用&#39;, &#39;でき&#39;, &#39;ず&#39;, &#39;。&#39;, &#39;接触&#39;, &#39;が&#39;, &#39;悪い&#39;, &#39;の&#39;, &#39;か&#39;, &#39;わから&#39;, &#39;ない&#39;, &#39;が&#39;, &#39;、&#39;, &#39;2&#39;, &#39;度&#39;, &#39;と&#39;, &#39;購入&#39;, &#39;し&#39;, &#39;ませ&#39;, &#39;ん&#39;, &#39;[SEP]&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="id7">
<h3>データセット全体のトークン化<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="o">.</span><span class="n">reset_format</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_encoded</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Parameter &#39;function&#39;=&lt;function tokenize at 0x346102b60&gt; of the transform datasets.arrow_dataset.Dataset._map_single couldn&#39;t be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won&#39;t be showed.
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "c98088cc3bdf422d86a3a5e15268a7a8"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "0f69e1bbff324a96bc7c39b4a291d25e"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "8c79676fd6e643abb38f74061a960ed6"}</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">sample_encoded</span> <span class="o">=</span> <span class="n">dataset_encoded</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">[</span><span class="n">sample_encoded</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>
     <span class="p">,</span> <span class="n">sample_encoded</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>
     <span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">sample_encoded</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])],</span>
    <span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s2">&quot;tokens&quot;</span><span class="p">]</span>
<span class="p">)</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>input_ids</th>
      <th>attention_mask</th>
      <th>tokens</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>1</td>
      <td>[CLS]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>57</td>
      <td>1</td>
      <td>4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>181</td>
      <td>1</td>
      <td>つ</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2630</td>
      <td>1</td>
      <td>購入</td>
    </tr>
    <tr>
      <th>4</th>
      <td>15</td>
      <td>1</td>
      <td>し</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>507</th>
      <td>0</td>
      <td>0</td>
      <td>[PAD]</td>
    </tr>
    <tr>
      <th>508</th>
      <td>0</td>
      <td>0</td>
      <td>[PAD]</td>
    </tr>
    <tr>
      <th>509</th>
      <td>0</td>
      <td>0</td>
      <td>[PAD]</td>
    </tr>
    <tr>
      <th>510</th>
      <td>0</td>
      <td>0</td>
      <td>[PAD]</td>
    </tr>
    <tr>
      <th>511</th>
      <td>0</td>
      <td>0</td>
      <td>[PAD]</td>
    </tr>
  </tbody>
</table>
<p>512 rows × 3 columns</p>
</div></div></div>
</div>
</section>
</section>
<section id="id8">
<h2>分類器の実装<a class="headerlink" href="#id8" title="Link to this heading">#</a></h2>
<section id="id9">
<h3>事前学習モデルの導入<a class="headerlink" href="#id9" title="Link to this heading">#</a></h3>
<p>Transformerライブラリは事前学習モデルの使用ため<code class="docutils literal notranslate"><span class="pre">AutoModel</span></code>クラスを提供します。</p>
<p><code class="docutils literal notranslate"><span class="pre">AutoModel</span></code>クラスはトークンエンコーディングを埋め込みに変換し、エンコーダスタックを経由して<strong>最後の</strong>隠れ状態を返します。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span>

<span class="c1"># GPUある場合はGPUを使う</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_ckpt</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/ryozawau/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/ryozawau/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/Users/ryozawau/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/transformers/modeling_utils.py:519: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don&#39;t have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(checkpoint_file, map_location=map_location)
</pre></div>
</div>
</div>
</div>
<p>最初に、文字列をエンコーダしてトークンをPyTorchのテンソルに変換する必要があります。</p>
<p>結果として得られるテンソルは<code class="docutils literal notranslate"><span class="pre">[batch_size,n_tokens]</span></code>という形状です。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;this is a test&quot;</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input tensor shape: </span><span class="si">{</span><span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Input tensor shape: torch.Size([1, 8])
</pre></div>
</div>
</div>
</div>
<p>得られるテンソルをモデルの入力として渡します。</p>
<ul class="simple">
<li><p>モデルと同じデバイス(GPU or CPU)に設置します。</p></li>
<li><p>計算のメモリを減らせるため、<code class="docutils literal notranslate"><span class="pre">torch.no_grad()</span></code>で、勾配の自動計算を無効します。</p></li>
<li><p>出力には隠れ状態、損失、アテンションのオブジェクトが含まれます。</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 3.4831e-01, -3.4548e-01,  4.8135e-02,  ..., -2.1422e-01,
           3.4672e-01,  4.4654e-01],
         [ 3.6010e-01,  3.3539e-01, -8.0582e-01,  ...,  9.8438e-01,
          -1.5404e-01,  1.0238e-03],
         [ 4.4720e-01, -5.0319e-01, -7.8903e-01,  ...,  4.6996e-01,
          -1.4486e-01,  3.4748e-01],
         ...,
         [-1.8473e-01, -6.0161e-01,  3.5366e-01,  ...,  7.5156e-02,
          -5.3383e-01,  4.8803e-01],
         [ 5.2880e-01,  1.9102e-01, -3.0294e-01,  ..., -5.4689e-03,
          -1.3497e-01,  7.4433e-01],
         [-1.6111e-01,  2.1320e-01, -5.7311e-01,  ...,  5.9892e-01,
          -2.0213e-01,  1.2702e+00]]]), pooler_output=tensor([[ 2.2298e-01,  7.6244e-01,  4.4263e-01,  5.0896e-02,  3.1429e-01,
         -2.8330e-01,  1.2347e-01,  2.5323e-01,  3.4149e-02, -1.4088e-01,
          4.2941e-01,  1.0587e-01,  7.9725e-01, -4.1017e-01,  1.9951e-01,
         -3.3257e-01,  6.6790e-01, -7.1064e-03, -3.9288e-01, -3.7357e-01,
         -4.1540e-01,  2.3092e-01,  1.1811e-01,  2.3485e-01,  1.7110e-01,
         -4.2608e-01, -4.2713e-01, -4.2256e-01, -1.8450e-01,  2.4407e-01,
         -3.9266e-01, -7.5142e-02,  6.6324e-02, -3.4763e-01,  3.5933e-01,
          3.6197e-01, -9.8375e-01, -5.6798e-03,  3.1257e-01,  7.4621e-01,
         -1.7843e-01,  3.7183e-01,  6.0902e-01,  3.4821e-01,  4.8099e-02,
          8.7713e-02, -3.6119e-01,  1.8020e-01,  7.4405e-02, -9.0160e-02,
         -2.4099e-01, -2.0694e-01, -3.1699e-02, -1.1253e-02,  1.7694e-01,
         -1.4904e-01,  3.3228e-01,  9.2301e-01,  2.5406e-01,  5.3044e-01,
         -5.3539e-01,  5.0996e-02,  6.6786e-01, -6.2789e-02, -5.8192e-02,
         -1.3206e-01, -4.7112e-01, -8.2009e-01, -3.0091e-01, -2.0574e-01,
         -6.9378e-01, -3.9933e-01, -3.3880e-01,  3.4293e-01, -4.1251e-01,
         -3.2877e-01,  2.1093e-01,  6.3274e-02, -1.5533e-01,  1.9514e-01,
          1.1287e-01,  1.6499e-01,  2.8643e-01,  7.5180e-01,  1.3793e-01,
          2.1924e-02, -3.2505e-03, -4.2947e-01,  1.5910e-01, -6.6509e-02,
         -1.1761e-01, -3.3458e-01, -2.4050e-01, -1.1537e-01,  2.2014e-01,
          1.4790e-01, -1.7508e-01,  1.6716e-01, -3.2631e-01,  1.4127e-01,
          3.5041e-01,  1.4764e-01,  3.8886e-01, -4.6176e-01,  9.4673e-01,
         -7.5572e-01, -3.7856e-01,  4.8963e-02, -3.8338e-01,  2.7642e-02,
          2.2737e-01,  2.4176e-01, -3.6205e-01, -3.6183e-01,  3.9202e-01,
         -7.5570e-03, -3.9856e-01, -1.7768e-01, -9.0520e-01, -4.7406e-01,
         -3.5902e-01,  1.3107e-01, -2.4261e-01,  9.8489e-01, -4.5657e-01,
          3.0467e-01,  1.9760e-01,  1.8846e-01,  3.1723e-01,  9.2376e-01,
          9.8800e-01, -2.3519e-02,  2.5763e-01, -4.8617e-01,  6.9956e-02,
         -8.6297e-01, -4.6487e-01, -4.3983e-01, -2.9584e-01, -3.3446e-01,
          8.7251e-02, -8.8606e-01,  4.4327e-01,  4.6397e-01, -3.3098e-02,
          2.6677e-01, -3.1090e-01, -1.9337e-01, -1.5578e-01, -1.8890e-01,
         -2.2698e-01, -3.8289e-01, -2.3437e-01, -7.7160e-01, -9.3185e-01,
         -2.2937e-01,  2.9079e-01,  3.6067e-01,  2.8412e-01,  9.1425e-02,
         -1.9411e-01,  1.9267e-01,  4.5167e-01,  1.5984e-01,  4.3080e-01,
          2.0993e-01,  1.7093e-01, -4.7006e-01, -2.9836e-01,  4.1175e-01,
          2.5997e-01, -7.6086e-02, -3.7476e-02,  3.8681e-01,  3.2327e-01,
          2.3939e-01,  4.6785e-01, -3.4575e-01, -3.4872e-01, -5.0410e-01,
         -4.9620e-01,  4.4309e-01,  6.8982e-02,  1.7721e-01, -2.4516e-01,
          6.6002e-03, -3.2303e-01,  6.6278e-01, -9.4421e-01, -2.2318e-01,
          4.3470e-01, -2.8004e-01,  2.6338e-02,  7.8891e-02, -2.4594e-02,
          5.6611e-01,  6.2564e-01,  8.1610e-02, -4.8649e-01,  4.6752e-02,
          4.4386e-01, -8.4283e-01, -1.3361e-01,  4.1866e-01,  2.1240e-01,
          2.5145e-01,  1.2309e-01,  3.9450e-01,  2.8185e-01, -3.0286e-01,
          1.7999e-01, -2.3846e-01, -5.4318e-01, -1.7834e-01,  9.8089e-01,
          7.1334e-01, -3.5175e-01, -1.4402e-01,  3.9285e-01, -7.8911e-01,
         -2.7846e-01,  1.2690e-02,  2.2188e-01,  3.3263e-01, -6.6972e-01,
          9.6824e-01, -3.2956e-01, -2.2593e-01, -9.4615e-01, -6.2825e-02,
          1.8122e-01,  2.3362e-02, -4.1159e-01, -5.3727e-01,  2.4917e-01,
         -2.4802e-01,  4.2281e-01,  1.5705e-01, -3.6458e-01, -5.7218e-02,
         -3.3397e-01,  7.8804e-01, -9.4872e-01, -4.6163e-04, -6.5387e-01,
         -9.2627e-02, -6.6151e-02,  1.1133e-01,  2.3202e-01,  1.4315e-01,
          3.8081e-03,  5.8655e-01, -5.7565e-02,  3.6145e-01,  9.1022e-01,
         -8.7444e-02, -2.1320e-01,  1.6584e-01,  2.2477e-01, -3.0444e-01,
         -2.0129e-02,  5.7439e-01, -3.1261e-02,  2.7481e-01, -1.4118e-01,
          1.3276e-01, -2.6654e-01,  3.3493e-01, -1.7360e-01, -1.4234e-01,
          7.3472e-01, -5.8705e-02,  6.3162e-01, -5.7182e-01, -3.0725e-01,
          1.2387e-01,  4.7722e-02,  3.0593e-01, -2.6052e-01, -6.1749e-02,
          3.9496e-02,  8.2161e-01, -1.1814e-01, -8.5529e-01,  2.4897e-01,
         -3.9399e-02, -1.4425e-01, -2.5694e-01, -2.9105e-02,  3.5781e-01,
         -7.0841e-01,  3.0531e-01, -3.4789e-01,  8.1954e-01,  1.3923e-01,
         -6.3467e-02,  1.8828e-01,  3.1783e-01, -3.5058e-01,  1.0045e-01,
          3.7793e-01, -1.0355e-01, -6.4546e-02,  7.9368e-02,  1.3093e-01,
          9.9317e-01,  1.4390e-01, -1.3011e-01,  3.4721e-01, -1.8289e-02,
         -1.0962e-02,  4.3390e-01, -2.8129e-02, -4.5712e-02,  2.3000e-01,
          3.4125e-01, -9.4349e-01, -2.0517e-01, -9.8742e-02,  8.5053e-02,
         -6.5596e-01,  3.3630e-01, -7.5888e-02,  1.5441e-01,  1.1125e-01,
          7.2764e-01,  4.3085e-01, -8.0836e-02, -9.5485e-01,  4.9775e-01,
          3.1041e-01, -8.7167e-02,  2.3585e-01, -2.4058e-01, -2.7720e-01,
          6.7482e-01,  1.0765e-01, -1.2833e-01,  9.3817e-01, -1.9709e-01,
          2.1660e-01,  4.6962e-01, -5.5782e-02, -4.2417e-01, -3.0670e-01,
         -3.2489e-01, -9.6224e-01,  3.3816e-01,  3.9498e-01, -9.7682e-01,
          5.0423e-01, -4.7597e-02,  2.6774e-01, -1.9325e-01,  2.8873e-01,
          4.1484e-02,  3.8003e-01, -5.2977e-01, -1.7961e-01,  4.9601e-02,
          3.9365e-02, -7.1031e-02, -1.8058e-01, -5.9941e-01,  2.8423e-01,
          2.0694e-01,  3.3221e-01,  2.8001e-01,  2.4831e-01,  1.4843e-01,
         -1.1471e-01,  1.8596e-01, -2.5708e-01, -3.6218e-01, -3.1290e-01,
          7.3265e-02,  3.5640e-01, -1.3453e-01, -2.4186e-01,  4.2983e-01,
         -4.0499e-01,  3.3164e-02,  2.1840e-01, -1.9754e-01,  8.3227e-02,
          3.5285e-02,  9.7240e-01, -3.3916e-01, -3.0205e-02,  3.9725e-01,
          3.8723e-01, -2.8017e-01,  2.4031e-02,  6.2782e-01,  8.4391e-03,
          2.5965e-01,  2.9028e-01, -3.2906e-02, -1.9256e-01,  4.5230e-02,
          9.9433e-01, -2.4176e-01,  2.9353e-01,  8.0959e-02,  7.5917e-02,
          1.8479e-01,  3.6573e-01, -2.6316e-01,  1.5211e-01,  2.0238e-01,
         -2.8108e-01,  2.7869e-01, -3.2385e-01,  9.2690e-01, -3.6964e-01,
         -6.9191e-01, -3.5357e-01,  1.5083e-01, -7.7831e-01, -1.1813e-01,
          3.7571e-02, -1.2678e-01,  6.0834e-01,  9.2693e-01,  1.9730e-01,
         -2.7197e-01,  4.2255e-02,  2.3146e-01,  2.3927e-01,  2.6563e-02,
         -3.1665e-01,  6.7677e-03,  1.9026e-01, -2.3947e-01,  2.4902e-01,
          1.7358e-01,  7.4014e-02, -1.6367e-01, -1.7125e-01,  2.5290e-01,
          3.4083e-01,  1.2784e-01,  1.4356e-01,  1.6572e-01,  1.6448e-01,
         -8.3425e-01, -1.8582e-01, -3.1895e-01, -1.0173e-01, -2.2153e-01,
         -3.5943e-01, -1.9716e-01, -2.4522e-01,  2.5005e-01,  2.3225e-01,
         -4.0590e-01, -1.0997e-01,  4.2891e-02, -5.3924e-01,  1.3963e-01,
         -1.2468e-01, -2.9005e-01,  1.0228e-01, -1.8502e-01, -6.1796e-01,
          4.0672e-01,  2.9492e-01, -3.1004e-01, -5.4929e-01,  7.0043e-02,
          9.7190e-01, -1.6935e-02, -1.5364e-01,  4.4221e-01,  3.5123e-01,
          1.0982e-01, -5.9538e-01, -1.6160e-02,  8.4905e-01,  3.0038e-01,
         -2.4761e-01,  3.2998e-01, -7.3236e-02,  4.4324e-01,  2.9852e-02,
          1.3227e-01,  4.3074e-01, -2.8121e-01,  3.1774e-01,  1.3403e-01,
         -4.1241e-01, -6.9126e-01, -7.5103e-01, -2.4412e-01,  3.7442e-01,
          1.3798e-01,  4.0156e-03, -1.1013e-01, -6.9277e-01, -2.7960e-01,
         -7.0625e-01,  8.6410e-02,  8.1732e-02,  9.8702e-01, -4.7115e-01,
         -5.7864e-01, -5.4459e-01, -6.9215e-02, -9.7683e-01, -1.7464e-01,
          5.8493e-01,  5.9353e-01, -5.4230e-01,  1.2485e-01,  9.6393e-02,
         -2.5119e-02,  3.8569e-01,  1.4936e-01,  3.0521e-01,  2.5859e-01,
          1.3202e-01,  2.7384e-01, -1.4201e-01, -9.2615e-02,  3.4552e-01,
          9.5215e-01, -3.9715e-01,  4.0085e-01,  4.1817e-02, -1.1841e-01,
          4.1752e-01,  5.0502e-01, -3.7605e-03,  2.5371e-01,  9.1288e-02,
         -1.3633e-01,  6.8352e-03, -2.6008e-01,  3.3058e-01, -2.1531e-01,
         -2.6542e-01,  2.5503e-01,  3.6980e-02, -1.8999e-01,  1.3004e-01,
          2.8914e-01,  2.9757e-01, -1.0454e-02,  3.8448e-01, -1.2070e-01,
         -6.2515e-02,  3.8344e-01, -7.9928e-01,  1.4358e-01,  2.9193e-01,
          4.8618e-02,  2.3874e-01, -2.9285e-01, -1.9456e-01, -9.9884e-01,
          2.9647e-01, -4.4963e-01, -1.2764e-01,  6.2168e-01, -2.1336e-02,
          1.1105e-01,  3.3670e-01, -7.8048e-03,  2.3518e-01,  2.4693e-01,
          1.1898e-01, -3.1484e-02,  3.8864e-01, -3.2615e-01, -8.1739e-01,
          3.5997e-01,  1.3933e-02, -5.9680e-04, -5.5312e-02,  2.5939e-01,
         -4.5971e-01,  4.1987e-02,  3.8398e-01, -1.3667e-01, -7.1320e-02,
          7.2092e-01,  1.3139e-02, -3.9333e-01,  1.6909e-01, -1.5589e-01,
         -1.2358e-01,  4.1938e-01,  2.6420e-01,  2.4029e-01,  9.4900e-02,
          9.4510e-02, -1.7087e-01, -8.5042e-02,  2.1009e-01,  4.8892e-01,
         -9.6758e-01,  5.1112e-03,  2.6382e-01,  1.2156e-01,  9.2353e-02,
         -1.2321e-01,  1.3363e-02,  1.8430e-01, -6.3338e-01, -2.5408e-01,
         -3.5117e-02, -1.1534e-01,  2.4780e-01,  2.0680e-01,  9.6709e-01,
          5.2147e-01,  9.9896e-01, -5.5434e-02, -4.9439e-01, -3.8075e-01,
          3.0386e-01, -2.1375e-01, -1.7044e-01, -1.2773e-01, -2.8067e-01,
          1.8761e-01, -3.2978e-01, -5.8609e-01,  9.1584e-01,  4.7974e-03,
         -4.1758e-02,  2.5588e-01,  6.6578e-02,  8.9769e-01, -1.3329e-01,
          2.4214e-01,  3.3821e-01,  3.4928e-01, -4.5163e-01,  3.1140e-01,
         -1.7107e-01, -1.9049e-01, -1.7848e-01, -3.8705e-01, -3.6698e-01,
          9.5848e-01,  9.7629e-01, -9.6143e-01,  3.0052e-01, -1.9631e-01,
         -3.8528e-01,  3.8932e-01, -3.9923e-01,  2.5351e-01,  1.8071e-01,
          3.4036e-01, -3.3698e-01, -5.1668e-01,  3.8609e-01,  9.0657e-01,
          5.2898e-01, -3.1928e-01,  3.1616e-01,  9.1037e-01, -2.1774e-01,
         -3.8693e-01,  8.9498e-02,  2.0651e-02, -9.9152e-01,  3.1665e-02,
          2.7543e-03, -3.1481e-01,  5.5987e-01,  1.4479e-01, -4.0589e-01,
          4.6586e-01, -3.9368e-01, -8.6508e-02, -5.9760e-01,  5.3393e-01,
          1.0417e-02, -2.8233e-01, -8.3792e-01, -2.3276e-02,  3.5350e-02,
          2.6455e-01,  2.0246e-01, -2.5519e-01, -2.8122e-01, -4.7778e-01,
          4.0094e-01,  1.6850e-01,  1.4338e-01,  1.7688e-01, -2.9089e-01,
          2.0603e-01, -2.3228e-01,  8.5812e-02,  2.3361e-01, -3.6658e-01,
         -1.7900e-01, -4.0642e-01, -3.0715e-01,  1.3480e-01, -4.3553e-01,
          3.8548e-01,  9.2602e-02,  3.3163e-01,  1.5107e-01,  2.0176e-01,
         -6.8316e-01,  5.7352e-02, -7.2881e-01,  2.4838e-01,  9.3963e-01,
         -3.2364e-01, -5.2688e-02, -3.8795e-01, -8.0682e-02,  2.5028e-01,
          9.3099e-02, -3.7861e-01,  8.3035e-02, -1.7649e-02, -1.0887e-01,
          4.3412e-01,  3.0173e-01,  2.2109e-01, -5.3882e-02,  1.7439e-01,
         -2.1992e-01, -3.1811e-01, -7.3632e-02, -4.1028e-01,  4.0493e-02,
          5.0368e-01,  2.6268e-01, -2.9160e-01,  5.0257e-02,  3.1962e-01,
          1.9810e-01, -3.0221e-01,  3.2058e-01, -5.0162e-01, -4.7491e-02,
         -3.2807e-01, -1.5918e-01, -4.1394e-01,  4.7636e-01,  7.9980e-02,
         -4.0976e-01,  3.5625e-02,  3.6348e-01,  2.2401e-01, -2.1716e-02,
          3.5304e-01, -6.3559e-01, -3.6421e-01,  3.4131e-01, -3.0227e-01,
         -2.1084e-01, -2.2659e-01, -9.8652e-01,  1.9582e-01, -9.6609e-02,
         -3.9204e-01, -3.0935e-01,  4.2436e-01]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)
</pre></div>
</div>
</div>
</div>
<p>隠れた状態テンソルを見ると、その形状は [batch_size, n_tokens, hidden_dim] であることがわかります。つまり、6つの入力トークンのそれぞれに対して、768次元のベクトルが返されます。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([1, 8, 768])
</pre></div>
</div>
</div>
</div>
<p>分類タスクでは、<code class="docutils literal notranslate"><span class="pre">[CLS]</span></code> トークンに関連する隠れた状態を入力特徴として使用するのが一般的な方法です。このトークンは各シーケンスの始まりに現れるため、次のように outputs.last_hidden_state に単純にインデックスを付けることで抽出できます。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([1, 768])
</pre></div>
</div>
</div>
</div>
<p>最後の隠れ状態を取得する方法がわかりましたので、データ全体に対して処理を行うため、これまでのステップを関数でまとめます。</p>
<p>そして、データ全体に適用し、すべてのテキストの隠れ状態を抽出します。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">extract_hidden_states</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="c1"># Place model inputs on the GPU</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> 
              <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">model_input_names</span><span class="p">}</span>
    <span class="c1"># Extract last hidden states</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">last_hidden_state</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">last_hidden_state</span>
    <span class="c1"># Return vector for [CLS] token</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;hidden_state&quot;</span><span class="p">:</span> <span class="n">last_hidden_state</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_encoded</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_hidden</span><span class="o">=</span><span class="n">dataset_encoded</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">extract_hidden_states</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "9df4b72990f946d59735c93afa144790"}</script><div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">27</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">dataset_hidden</span><span class="o">=</span><span class="n">dataset_encoded</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">extract_hidden_states</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/datasets/dataset_dict.py:887,</span> in <span class="ni">DatasetDict.map</span><span class="nt">(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)</span>
<span class="g g-Whitespace">    </span><span class="mi">883</span> <span class="k">if</span> <span class="n">cache_file_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">884</span>     <span class="n">cache_file_names</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">}</span>
<span class="g g-Whitespace">    </span><span class="mi">885</span> <span class="k">return</span> <span class="n">DatasetDict</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">886</span>     <span class="p">{</span>
<span class="ne">--&gt; </span><span class="mi">887</span>         <span class="n">k</span><span class="p">:</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">888</span>             <span class="n">function</span><span class="o">=</span><span class="n">function</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">889</span>             <span class="n">with_indices</span><span class="o">=</span><span class="n">with_indices</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">890</span>             <span class="n">with_rank</span><span class="o">=</span><span class="n">with_rank</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">891</span>             <span class="n">input_columns</span><span class="o">=</span><span class="n">input_columns</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">892</span>             <span class="n">batched</span><span class="o">=</span><span class="n">batched</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">893</span>             <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">894</span>             <span class="n">drop_last_batch</span><span class="o">=</span><span class="n">drop_last_batch</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">895</span>             <span class="n">remove_columns</span><span class="o">=</span><span class="n">remove_columns</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">896</span>             <span class="n">keep_in_memory</span><span class="o">=</span><span class="n">keep_in_memory</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">897</span>             <span class="n">load_from_cache_file</span><span class="o">=</span><span class="n">load_from_cache_file</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">898</span>             <span class="n">cache_file_name</span><span class="o">=</span><span class="n">cache_file_names</span><span class="p">[</span><span class="n">k</span><span class="p">],</span>
<span class="g g-Whitespace">    </span><span class="mi">899</span>             <span class="n">writer_batch_size</span><span class="o">=</span><span class="n">writer_batch_size</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">900</span>             <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">901</span>             <span class="n">disable_nullable</span><span class="o">=</span><span class="n">disable_nullable</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">902</span>             <span class="n">fn_kwargs</span><span class="o">=</span><span class="n">fn_kwargs</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">903</span>             <span class="n">num_proc</span><span class="o">=</span><span class="n">num_proc</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">904</span>             <span class="n">desc</span><span class="o">=</span><span class="n">desc</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">905</span>         <span class="p">)</span>
<span class="nn">    906         for k, dataset</span> in <span class="ni">self.items</span><span class="nt">()</span>
<span class="g g-Whitespace">    </span><span class="mi">907</span>     <span class="p">}</span>
<span class="g g-Whitespace">    </span><span class="mi">908</span> <span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/datasets/arrow_dataset.py:560,</span> in <span class="ni">transmit_format.&lt;locals&gt;.wrapper</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">553</span> <span class="n">self_format</span> <span class="o">=</span> <span class="p">{</span>
<span class="g g-Whitespace">    </span><span class="mi">554</span>     <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_type</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">555</span>     <span class="s2">&quot;format_kwargs&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_kwargs</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">556</span>     <span class="s2">&quot;columns&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_columns</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">557</span>     <span class="s2">&quot;output_all_columns&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_all_columns</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">558</span> <span class="p">}</span>
<span class="g g-Whitespace">    </span><span class="mi">559</span> <span class="c1"># apply actual function</span>
<span class="ne">--&gt; </span><span class="mi">560</span> <span class="n">out</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;Dataset&quot;</span><span class="p">,</span> <span class="s2">&quot;DatasetDict&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">561</span> <span class="n">datasets</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;Dataset&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">out</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">562</span> <span class="c1"># re-apply format to the output</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/datasets/arrow_dataset.py:3073,</span> in <span class="ni">Dataset.map</span><span class="nt">(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)</span>
<span class="g g-Whitespace">   </span><span class="mi">3067</span> <span class="k">if</span> <span class="n">transformed_dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">3068</span>     <span class="k">with</span> <span class="n">hf_tqdm</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">3069</span>         <span class="n">unit</span><span class="o">=</span><span class="s2">&quot; examples&quot;</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3070</span>         <span class="n">total</span><span class="o">=</span><span class="n">pbar_total</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3071</span>         <span class="n">desc</span><span class="o">=</span><span class="n">desc</span> <span class="ow">or</span> <span class="s2">&quot;Map&quot;</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3072</span>     <span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">3073</span>         <span class="k">for</span> <span class="n">rank</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">content</span> <span class="ow">in</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">_map_single</span><span class="p">(</span><span class="o">**</span><span class="n">dataset_kwargs</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">3074</span>             <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">3075</span>                 <span class="n">shards_done</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/datasets/arrow_dataset.py:3476,</span> in <span class="ni">Dataset._map_single</span><span class="nt">(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)</span>
<span class="g g-Whitespace">   </span><span class="mi">3472</span> <span class="n">indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">3473</span>     <span class="nb">range</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">indices</span><span class="p">(</span><span class="n">shard</span><span class="o">.</span><span class="n">num_rows</span><span class="p">)))</span>
<span class="g g-Whitespace">   </span><span class="mi">3474</span> <span class="p">)</span>  <span class="c1"># Something simpler?</span>
<span class="g g-Whitespace">   </span><span class="mi">3475</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">3476</span>     <span class="n">batch</span> <span class="o">=</span> <span class="n">apply_function_on_filtered_inputs</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">3477</span>         <span class="n">batch</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3478</span>         <span class="n">indices</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3479</span>         <span class="n">check_same_num_examples</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">shard</span><span class="o">.</span><span class="n">list_indexes</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3480</span>         <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3481</span>     <span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">3482</span> <span class="k">except</span> <span class="n">NumExamplesMismatchError</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">3483</span>     <span class="k">raise</span> <span class="n">DatasetTransformationNotAllowedError</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">3484</span>         <span class="s2">&quot;Using `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn&#39;t create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.&quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">3485</span>     <span class="p">)</span> <span class="kn">from</span> <span class="kc">None</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/datasets/arrow_dataset.py:3338,</span> in <span class="ni">Dataset._map_single.&lt;locals&gt;.apply_function_on_filtered_inputs</span><span class="nt">(pa_inputs, indices, check_same_num_examples, offset)</span>
<span class="g g-Whitespace">   </span><span class="mi">3336</span> <span class="k">if</span> <span class="n">with_rank</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">3337</span>     <span class="n">additional_args</span> <span class="o">+=</span> <span class="p">(</span><span class="n">rank</span><span class="p">,)</span>
<span class="ne">-&gt; </span><span class="mi">3338</span> <span class="n">processed_inputs</span> <span class="o">=</span> <span class="n">function</span><span class="p">(</span><span class="o">*</span><span class="n">fn_args</span><span class="p">,</span> <span class="o">*</span><span class="n">additional_args</span><span class="p">,</span> <span class="o">**</span><span class="n">fn_kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">3339</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">processed_inputs</span><span class="p">,</span> <span class="n">LazyDict</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">3340</span>     <span class="n">processed_inputs</span> <span class="o">=</span> <span class="p">{</span>
<span class="g g-Whitespace">   </span><span class="mi">3341</span>         <span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">processed_inputs</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">processed_inputs</span><span class="o">.</span><span class="n">keys_to_format</span>
<span class="g g-Whitespace">   </span><span class="mi">3342</span>     <span class="p">}</span>

<span class="nn">Cell In[25], line 7,</span> in <span class="ni">extract_hidden_states</span><span class="nt">(batch)</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="c1"># Extract last hidden states</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="ne">----&gt; </span><span class="mi">7</span>     <span class="n">last_hidden_state</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">last_hidden_state</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> <span class="c1"># Return vector for [CLS] token</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span> <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;hidden_state&quot;</span><span class="p">:</span> <span class="n">last_hidden_state</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()}</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/torch/nn/modules/module.py:1553,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1551</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1552</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1553</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/torch/nn/modules/module.py:1562,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1557</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1558</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1559</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1560</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1561</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1562</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1564</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1565</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1013,</span> in <span class="ni">BertModel.forward</span><span class="nt">(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)</span>
<span class="g g-Whitespace">   </span><span class="mi">1004</span> <span class="n">head_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_head_mask</span><span class="p">(</span><span class="n">head_mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1006</span> <span class="n">embedding_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1007</span>     <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1008</span>     <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1011</span>     <span class="n">past_key_values_length</span><span class="o">=</span><span class="n">past_key_values_length</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1012</span> <span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1013</span> <span class="n">encoder_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1014</span>     <span class="n">embedding_output</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1015</span>     <span class="n">attention_mask</span><span class="o">=</span><span class="n">extended_attention_mask</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1016</span>     <span class="n">head_mask</span><span class="o">=</span><span class="n">head_mask</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1017</span>     <span class="n">encoder_hidden_states</span><span class="o">=</span><span class="n">encoder_hidden_states</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1018</span>     <span class="n">encoder_attention_mask</span><span class="o">=</span><span class="n">encoder_extended_attention_mask</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1019</span>     <span class="n">past_key_values</span><span class="o">=</span><span class="n">past_key_values</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1020</span>     <span class="n">use_cache</span><span class="o">=</span><span class="n">use_cache</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1021</span>     <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1022</span>     <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1023</span>     <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1024</span> <span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1025</span> <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1026</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooler</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/torch/nn/modules/module.py:1553,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1551</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1552</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1553</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/torch/nn/modules/module.py:1562,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1557</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1558</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1559</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1560</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1561</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1562</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1564</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1565</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:607,</span> in <span class="ni">BertEncoder.forward</span><span class="nt">(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)</span>
<span class="g g-Whitespace">    </span><span class="mi">596</span>     <span class="n">layer_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_checkpointing_func</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">597</span>         <span class="n">layer_module</span><span class="o">.</span><span class="fm">__call__</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">598</span>         <span class="n">hidden_states</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">604</span>         <span class="n">output_attentions</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">605</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">606</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">607</span>     <span class="n">layer_outputs</span> <span class="o">=</span> <span class="n">layer_module</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">608</span>         <span class="n">hidden_states</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">609</span>         <span class="n">attention_mask</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">610</span>         <span class="n">layer_head_mask</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">611</span>         <span class="n">encoder_hidden_states</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">612</span>         <span class="n">encoder_attention_mask</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">613</span>         <span class="n">past_key_value</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">614</span>         <span class="n">output_attentions</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">615</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">617</span> <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">layer_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">618</span> <span class="k">if</span> <span class="n">use_cache</span><span class="p">:</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/torch/nn/modules/module.py:1553,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1551</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1552</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1553</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/torch/nn/modules/module.py:1562,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1557</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1558</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1559</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1560</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1561</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1562</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1564</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1565</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:497,</span> in <span class="ni">BertLayer.forward</span><span class="nt">(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)</span>
<span class="g g-Whitespace">    </span><span class="mi">485</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">486</span>     <span class="bp">self</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">487</span>     <span class="n">hidden_states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">494</span> <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="g g-Whitespace">    </span><span class="mi">495</span>     <span class="c1"># decoder uni-directional self-attention cached key/values tuple is at positions 1,2</span>
<span class="g g-Whitespace">    </span><span class="mi">496</span>     <span class="n">self_attn_past_key_value</span> <span class="o">=</span> <span class="n">past_key_value</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="k">if</span> <span class="n">past_key_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
<span class="ne">--&gt; </span><span class="mi">497</span>     <span class="n">self_attention_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">498</span>         <span class="n">hidden_states</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">499</span>         <span class="n">attention_mask</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">500</span>         <span class="n">head_mask</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">501</span>         <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">502</span>         <span class="n">past_key_value</span><span class="o">=</span><span class="n">self_attn_past_key_value</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">503</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">504</span>     <span class="n">attention_output</span> <span class="o">=</span> <span class="n">self_attention_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">506</span>     <span class="c1"># if decoder, the last output is tuple of self-attn cache</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/torch/nn/modules/module.py:1553,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1551</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1552</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1553</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/torch/nn/modules/module.py:1562,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1557</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1558</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1559</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1560</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1561</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1562</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1564</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1565</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:427,</span> in <span class="ni">BertAttention.forward</span><span class="nt">(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)</span>
<span class="g g-Whitespace">    </span><span class="mi">417</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">418</span>     <span class="bp">self</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">419</span>     <span class="n">hidden_states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">425</span>     <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">426</span> <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="ne">--&gt; </span><span class="mi">427</span>     <span class="n">self_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">428</span>         <span class="n">hidden_states</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">429</span>         <span class="n">attention_mask</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">430</span>         <span class="n">head_mask</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">431</span>         <span class="n">encoder_hidden_states</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">432</span>         <span class="n">encoder_attention_mask</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">433</span>         <span class="n">past_key_value</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">434</span>         <span class="n">output_attentions</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">435</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">436</span>     <span class="n">attention_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">self_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">hidden_states</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">437</span>     <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">attention_output</span><span class="p">,)</span> <span class="o">+</span> <span class="n">self_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>  <span class="c1"># add attentions if we output them</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/torch/nn/modules/module.py:1553,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1551</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1552</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1553</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/torch/nn/modules/module.py:1562,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1557</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1558</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1559</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1560</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1561</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1562</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1564</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1565</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~/anaconda3/envs/jupyterbook/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:325,</span> in <span class="ni">BertSelfAttention.forward</span><span class="nt">(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)</span>
<span class="g g-Whitespace">    </span><span class="mi">322</span>     <span class="n">past_key_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">key_layer</span><span class="p">,</span> <span class="n">value_layer</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">324</span> <span class="c1"># Take the dot product between &quot;query&quot; and &quot;key&quot; to get the raw attention scores.</span>
<span class="ne">--&gt; </span><span class="mi">325</span> <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">query_layer</span><span class="p">,</span> <span class="n">key_layer</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">327</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embedding_type</span> <span class="o">==</span> <span class="s2">&quot;relative_key&quot;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embedding_type</span> <span class="o">==</span> <span class="s2">&quot;relative_key_query&quot;</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">328</span>     <span class="n">query_length</span><span class="p">,</span> <span class="n">key_length</span> <span class="o">=</span> <span class="n">query_layer</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">key_layer</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
</section>
<section id="id10">
<h3>分類器の学習<a class="headerlink" href="#id10" title="Link to this heading">#</a></h3>
<p>前処理されたデータセットには、分類器を学習させるために必要な情報がすべて含まれています。</p>
<p>具体的には、隠れ状態を入力特徴量として、ラベルをターゲットとして使用すると、様々な分類アルゴリズムに適用できるだろう。</p>
<p>ここで、ロジスティック回帰モデルを学習します。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dataset_hidden</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="s2">&quot;hidden_state&quot;</span><span class="p">])</span>
<span class="n">X_valid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dataset_hidden</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">][</span><span class="s2">&quot;hidden_state&quot;</span><span class="p">])</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dataset_hidden</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
<span class="n">y_valid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dataset_hidden</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">][</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_valid</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((1839, 768), (324, 768))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="n">lr_clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">3000</span><span class="p">)</span>
<span class="n">lr_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegression(max_iter=3000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression(max_iter=3000)</pre></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr_clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.5987654320987654
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">ConfusionMatrixDisplay</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="k">def</span> <span class="nf">plot_confusion_matrix</span><span class="p">(</span><span class="n">y_preds</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">disp</span> <span class="o">=</span> <span class="n">ConfusionMatrixDisplay</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="o">=</span><span class="n">cm</span><span class="p">,</span> <span class="n">display_labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">disp</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span> <span class="n">values_format</span><span class="o">=</span><span class="s2">&quot;.2f&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">colorbar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Normalized confusion matrix&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
<span class="n">y_preds</span> <span class="o">=</span> <span class="n">lr_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">y_preds</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;positive&quot;</span><span class="p">,</span><span class="s2">&quot;neutral&quot;</span><span class="p">,</span><span class="s2">&quot;negative&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/d05c1909c91dfbdb6d512c87132554795c8508252537302d64f066a2f51b72b0.png" src="../_images/d05c1909c91dfbdb6d512c87132554795c8508252537302d64f066a2f51b72b0.png" />
</div>
</div>
</section>
<section id="automodelforsequenceclassification">
<h3>AutoModelForSequenceClassificationのファインチューニング<a class="headerlink" href="#automodelforsequenceclassification" title="Link to this heading">#</a></h3>
<p>transformerライブラリは、ファインチューニングのタスクに応じてAPIを提供しています。</p>
<p>分類タスクの場合、<code class="docutils literal notranslate"><span class="pre">AutoModel</span></code>の代わりに<code class="docutils literal notranslate"><span class="pre">AutoModelForSequenceClassification</span></code>を使用します。</p>
<p><code class="docutils literal notranslate"><span class="pre">AutoModelForSequenceClassification</span></code>が事前学習済みモデルの出力の上に分類器ヘッドを持っており、モデルの設定がより簡単になります。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">num_labels</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">model</span> <span class="o">=</span> <span class="p">(</span><span class="n">AutoModelForSequenceClassification</span>
    <span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_ckpt</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span><span class="p">)</span>
    <span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: [&#39;pre_classifier.weight&#39;, &#39;pre_classifier.bias&#39;, &#39;classifier.bias&#39;, &#39;classifier.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DistilBertForSequenceClassification(
  (distilbert): DistilBertModel(
    (embeddings): Embeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layer): ModuleList(
        (0-5): 6 x TransformerBlock(
          (attention): MultiHeadSelfAttention(
            (dropout): Dropout(p=0.1, inplace=False)
            (q_lin): Linear(in_features=768, out_features=768, bias=True)
            (k_lin): Linear(in_features=768, out_features=768, bias=True)
            (v_lin): Linear(in_features=768, out_features=768, bias=True)
            (out_lin): Linear(in_features=768, out_features=768, bias=True)
          )
          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (ffn): FFN(
            (dropout): Dropout(p=0.1, inplace=False)
            (lin1): Linear(in_features=768, out_features=3072, bias=True)
            (lin2): Linear(in_features=3072, out_features=768, bias=True)
            (activation): GELUActivation()
          )
          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
      )
    )
  )
  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
  (classifier): Linear(in_features=768, out_features=3, bias=True)
  (dropout): Dropout(p=0.2, inplace=False)
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;I purchased these boots to use both for everyday wear and when riding my motorcycle.&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span> <span class="c1"># pytorch tensorに変換するためにreturn_tensors=&quot;pt&quot;を指定</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;I purchased these boots to use both for everyday wear and when riding my motorcycle.&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span> <span class="c1"># pytorch tensorに変換するためにreturn_tensors=&quot;pt&quot;を指定</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>

<span class="ne">NameError</span>: name &#39;tokenizer&#39; is not defined
</pre></div>
</div>
</div>
</div>
</section>
<section id="id11">
<h3>学習の準備<a class="headerlink" href="#id11" title="Link to this heading">#</a></h3>
<p>学習時に性能指標を与える必要があるため、それを関数化して定義しておきます。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">f1_score</span>

<span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">pred</span><span class="p">):</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">label_ids</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">predictions</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;weighted&quot;</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="n">acc</span><span class="p">,</span> <span class="s2">&quot;f1&quot;</span><span class="p">:</span> <span class="n">f1</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>学習を効率化するために、transformerライブラリの<code class="docutils literal notranslate"><span class="pre">Trainer</span></code> APIを使用します。</p>
<p><code class="docutils literal notranslate"><span class="pre">Trainer</span></code>クラスを初期化する際には、<code class="docutils literal notranslate"><span class="pre">TrainingArguments</span></code>という訓練に関する様々な設定値の集合を引数に与えることで、訓練の設定に関する細かい調整が可能です。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">logging_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset_encoded</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">])</span> <span class="o">//</span> <span class="n">batch_size</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;sample-text-classification-bert&quot;</span>

<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
    <span class="n">disable_tqdm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">logging_steps</span><span class="o">=</span><span class="n">logging_steps</span><span class="p">,</span>
    <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">log_level</span><span class="o">=</span><span class="s2">&quot;error&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Trainerクラスで実行します。</p>
<p>結果を確認すると、特徴ベースのアプローチよりも精度が改善されることがわかります。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset_encoded</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset_encoded</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span>
<span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
    <div>
      
      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [230/230 00:07, Epoch 2/2]
    </div>
    <table border="1" class="dataframe">
  <thead>
 <tr style="text-align: left;">
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
      <th>Accuracy</th>
      <th>F1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>1.001000</td>
      <td>0.822080</td>
      <td>0.623457</td>
      <td>0.598058</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.746200</td>
      <td>0.730626</td>
      <td>0.672840</td>
      <td>0.660265</td>
    </tr>
  </tbody>
</table><p></div><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>TrainOutput(global_step=230, training_loss=0.8717699584753617, metrics={&#39;train_runtime&#39;: 7.9795, &#39;train_samples_per_second&#39;: 460.93, &#39;train_steps_per_second&#39;: 28.824, &#39;total_flos&#39;: 74225497893768.0, &#39;train_loss&#39;: 0.8717699584753617, &#39;epoch&#39;: 2.0})
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id12">
<h2>学習済みモデルの使用<a class="headerlink" href="#id12" title="Link to this heading">#</a></h2>
<section id="id13">
<h3>モデル精度の検証<a class="headerlink" href="#id13" title="Link to this heading">#</a></h3>
<p>学習済みのモデルを他のデータセットに適用します。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">preds_output</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dataset_encoded</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">ConfusionMatrixDisplay</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="n">y_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">preds_output</span><span class="o">.</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_valid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dataset_encoded</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">][</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">dataset_encoded</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span>

<span class="k">def</span> <span class="nf">plot_confusion_matrix</span><span class="p">(</span><span class="n">y_preds</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">disp</span> <span class="o">=</span> <span class="n">ConfusionMatrixDisplay</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="o">=</span><span class="n">cm</span><span class="p">,</span> <span class="n">display_labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">disp</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span> <span class="n">values_format</span><span class="o">=</span><span class="s2">&quot;.2f&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">colorbar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Normalized confusion matrix&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">y_preds</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1d83e6438a47b3fa124e1937a2374dda486655a12d3bb29c73e8ee21c49dc64e.png" src="../_images/1d83e6438a47b3fa124e1937a2374dda486655a12d3bb29c73e8ee21c49dc64e.png" />
</div>
</div>
</section>
<section id="id14">
<h3>モデル保存<a class="headerlink" href="#id14" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">id2label</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">num_classes</span><span class="p">):</span>
    <span class="n">id2label</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">int2str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

<span class="n">label2id</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">num_classes</span><span class="p">):</span>
    <span class="n">label2id</span><span class="p">[</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">int2str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">i</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">id2label</span> <span class="o">=</span> <span class="n">id2label</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">label2id</span> <span class="o">=</span> <span class="n">label2id</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;./Data/sample-text-classification-bert&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id15">
<h3>学習済みモデルの読み込み<a class="headerlink" href="#id15" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span>\
    <span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;./Data/sample-text-classification-bert&quot;</span><span class="p">)</span>

<span class="n">new_model</span> <span class="o">=</span> <span class="p">(</span><span class="n">AutoModelForSequenceClassification</span>
    <span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;./Data/sample-text-classification-bert&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>サンプルテキストで推論の結果を確認します。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">id2label</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">label_dict</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="s2">&quot;positive&quot;</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="s2">&quot;neutral&quot;</span><span class="p">,</span><span class="mi">2</span><span class="p">:</span><span class="s2">&quot;negative&quot;</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">label_dict</span><span class="p">[</span><span class="n">x</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text1</span><span class="o">=</span><span class="s2">&quot;this week is not going as i had hoped&quot;</span>
<span class="n">text2</span><span class="o">=</span><span class="s2">&quot;awe i love you too!!!! 1 am here i miss you&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">new_tokenizer</span><span class="p">(</span><span class="n">text1</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>

<span class="n">new_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">new_model</span><span class="p">(</span>
        <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> 
        <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
    <span class="p">)</span>
<span class="n">outputs</span><span class="o">.</span><span class="n">logits</span>

<span class="n">y_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_preds</span> <span class="o">=</span> <span class="p">[</span><span class="n">id2label</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">y_preds</span><span class="p">]</span>
<span class="n">y_preds</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;negative&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">new_tokenizer</span><span class="p">(</span><span class="n">text2</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>

<span class="n">new_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">new_model</span><span class="p">(</span>
        <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> 
        <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
    <span class="p">)</span>
<span class="n">outputs</span><span class="o">.</span><span class="n">logits</span>

<span class="n">y_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_preds</span> <span class="o">=</span> <span class="p">[</span><span class="n">id2label</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">y_preds</span><span class="p">]</span>
<span class="n">y_preds</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;positive&#39;]
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebook"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">データセット</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hugging-face">Hugging Faceからサンプルデータの取得</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">サンプルデータの確認</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">テキストの確認</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">トークン化</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">トークナイザの動作確認</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">データセット全体のトークン化</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">分類器の実装</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">事前学習モデルの導入</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">分類器の学習</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#automodelforsequenceclassification">AutoModelForSequenceClassificationのファインチューニング</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">学習の準備</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">学習済みモデルの使用</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">モデル精度の検証</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">モデル保存</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">学習済みモデルの読み込み</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By 呂　沢宇
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=bd9e20870c6007c4c509"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=bd9e20870c6007c4c509"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>