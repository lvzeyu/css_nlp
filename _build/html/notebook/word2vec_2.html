
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>word2vec &#8212; 計算社会科学のための自然言語処理</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/tohoku-university-logo-vector.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">計算社会科学のための自然言語処理</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    計算社会科学と自然言語処理
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  イントロダクション
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="introduction.html">
   ガイダンス
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  基礎知識
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="nlp_basis.html">
   自然言語処理の基礎
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ml_basis.html">
   機械学習の基本概念
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ニューラルネットワーク
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="NN.html">
   ニューラルネットワーク
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="backpropagation.html">
   誤差逆伝播法
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  PyTorch
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="pytorch.html">
   Pytorch
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  単語分散表現
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="word2vec_1.html">
   単語分散表現
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="word2vec_2_embedding.html">
   word2vec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="word2vec_gensim.html">
   GensimによるWord2Vecの学習と使用
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="word2vec_sentiment.html">
   Word2Vecを用いるセンチメント分析
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="word2vec_application.html">
   Word2Vecが人文・社会科学研究における応用
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  RNN
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="rnn.html">
   RNN
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/lvzeyu/css_nlp/master?urlpath=lab/tree/notebook/word2vec_2.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/lvzeyu/css_nlp/blob/master/notebook/word2vec_2.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/lvzeyu/css_nlp/tree/master"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/lvzeyu/css_nlp/tree/master/issues/new?title=Issue%20on%20page%20%2Fnotebook/word2vec_2.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/notebook/word2vec_2.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   推論ベース手法とニューラルネットワーク
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     推論ベース手法の設計
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-hot">
     one-hot表現
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cbow-continuous-bag-of-words">
     CBOW（continuous bag-of-words）モデル
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id5">
       入力層から中間層(エンコード)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       中間層から出力層(デコード)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id7">
       word2vecの重みと分散表現
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   Word2Vecモデルの実装
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     学習データの準備
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id10">
       コンテキストとターゲット
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id11">
       one-hot表現への変換
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cbow">
     CBOWモデルの実装
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>word2vec</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   推論ベース手法とニューラルネットワーク
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     推論ベース手法の設計
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-hot">
     one-hot表現
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cbow-continuous-bag-of-words">
     CBOW（continuous bag-of-words）モデル
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id5">
       入力層から中間層(エンコード)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       中間層から出力層(デコード)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id7">
       word2vecの重みと分散表現
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   Word2Vecモデルの実装
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     学習データの準備
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id10">
       コンテキストとターゲット
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id11">
       one-hot表現への変換
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cbow">
     CBOWモデルの実装
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="word2vec">
<h1>word2vec<a class="headerlink" href="#word2vec" title="Permalink to this headline">#</a></h1>
<p>前章では、「カウントベースの手法」によって単語分散表現を得ました。具体的には、単語の共起行列を作り、その行列に対してSVDを適用することで、密なベクトくー 単語分散表現ーを獲得したのです。</p>
<p>しかし、カウントベースの手法にはいくつかの問題点があります。</p>
<ul class="simple">
<li><p>大規模なコーパスを扱う場合、巨大な共起行列に対してSVDを計算することが難しい。</p></li>
<li><p>コーパスの全体から一回の学習で単語分散表現を獲得していますので、新しい単語が追加される場合、再度最初から学習を行う必要があり、単語分散表現更新の効率が低い。</p></li>
</ul>
<p>「カウントベースの手法」に代わる強力な手法として「推論ベース」の手法が挙げられます。特に、Mikolov et al. <span id="id1">[<a class="reference internal" href="word2vec_application.html#id16" title="Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. Linguistic regularities in continuous space word representations. In Lucy Vanderwende, Hal Daumé III, and Katrin Kirchhoff, editors, Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 746–751. Atlanta, Georgia, June 2013. Association for Computational Linguistics. URL: https://aclanthology.org/N13-1090.">Mikolov <em>et al.</em>, 2013</a>]</span> <span id="id2">[<a class="reference internal" href="word2vec_application.html#id17" title="Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed representations of words and phrases and their compositionality. In C.J. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K.Q. Weinberger, editors, Advances in Neural Information Processing Systems, volume 26. Curran Associates, Inc., 2013. URL: https://proceedings.neurips.cc/paper_files/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf.">Mikolov <em>et al.</em>, 2013</a>]</span>　によって提案されたword2vecの有用性が多くの自然言語処理タスクにおいて示されてきたのです。</p>
<p>本章では、word2vecの仕組みについて説明し、それを実装することで理解を深めます。</p>
<section id="id3">
<h2>推論ベース手法とニューラルネットワーク<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h2>
<p>推論ベースの手法は、ミニバッチで学習する形で、ニューラルネットワークを用いて、重みを繰り返し更新することで単語分散表現を獲得します。</p>
<p><img alt="" src="../_images/inference.png" /></p>
<section id="id4">
<h3>推論ベース手法の設計<a class="headerlink" href="#id4" title="Permalink to this headline">#</a></h3>
<p>推論ベース手法では、<code class="docutils literal notranslate"><span class="pre">you</span> <span class="pre">【？】</span> <span class="pre">goodbye</span> <span class="pre">and</span> <span class="pre">I</span> <span class="pre">say</span> <span class="pre">hello</span> <span class="pre">.</span></code>のような、周囲の単語が与えられたときに、<code class="docutils literal notranslate"><span class="pre">【？】</span></code>にどのような単語が出現するのかを推測する推論問題を繰り返し解くことで、単語の出現バターンを学習します。</p>
<p>つまり、コンテキスト情報を入力として受け取り、各単語の出現する確率を出力する「モデル」を作成することは目標になります。ここで、正しい推測ができるように、コーパスを使って、ニューラルネットワークモデルの学習を行います。そして、その学習の結果として、単語の分散表現を得られます。</p>
<p><img alt="" src="../_images/inference2.png" /></p>
</section>
<section id="one-hot">
<h3>one-hot表現<a class="headerlink" href="#one-hot" title="Permalink to this headline">#</a></h3>
<p>ニューラルネットワークで単語を処理するには、それを「固定長のベクトル」に変換する必要があります。</p>
<p>そのための方法の一つは、単語をone-hot表現へと変換することです。one-hot表現とは、ベクトルの要素の中で一つだけが<span class="math notranslate nohighlight">\(1\)</span>で、残りは全て<span class="math notranslate nohighlight">\(0\)</span>であるようなベクトルと言います。</p>
<p>単語をone-hot表現に変換するには、語彙数分の要素を持つベクトルを用意して、単語IDの該当する箇所を<span class="math notranslate nohighlight">\(1\)</span>に、残りは全て<span class="math notranslate nohighlight">\(0\)</span>に設定します。</p>
<p><img alt="" src="../_images/one-hot.png" /></p>
</section>
<section id="cbow-continuous-bag-of-words">
<h3>CBOW（continuous bag-of-words）モデル<a class="headerlink" href="#cbow-continuous-bag-of-words" title="Permalink to this headline">#</a></h3>
<p>CBOWモデルは、コンテキストからターゲットを推測することを目的としたニューラルネットワークです。このCBOWモデルで、できるだけ正確な推測ができるように訓練することで、単語の分散表現を取得することができます。</p>
<p>ここで、例として、コンテキスト<code class="docutils literal notranslate"><span class="pre">[&quot;you&quot;,&quot;goodbye&quot;]</span></code>からターゲット<code class="docutils literal notranslate"><span class="pre">&quot;say&quot;</span></code>を予測するタスクを考えます。</p>
<p><img alt="" src="../_images/cbow.png" /></p>
<section id="id5">
<h4>入力層から中間層(エンコード)<a class="headerlink" href="#id5" title="Permalink to this headline">#</a></h4>
<p>one-hotエンコーディングで、単語を固定長のベクトルに変換するすることができます。</p>
<p>単語をベクトルで表すことができれば、そのベクトルはニューラルネットワークを構成する「レイヤ」によって処理することができるようになりました。</p>
<p>コンテキストを<span class="math notranslate nohighlight">\(\mathbf{c}\)</span>、重みを<span class="math notranslate nohighlight">\(\mathbf{W}\)</span>とし、それぞれ次の形状とします。</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>イメージしやすいように、ここでは添字を対応する単語で表すことにします。ただし「.(ピリオド)」については「priod」とします。</p>
</aside>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{c}
    = \begin{pmatrix}
          c_{\mathrm{you}} &amp; c_{\mathrm{say}} &amp; c_{\mathrm{goodbye}} &amp; c_{\mathrm{and}} &amp; c_{\mathrm{I}} &amp; c_{\mathrm{hello}} &amp; c_{\mathrm{period}}
      \end{pmatrix}
,\ 
\mathbf{W}
    = \begin{pmatrix}
          w_{\mathrm{you},1} &amp; w_{\mathrm{you},2} &amp; w_{\mathrm{you},3} \\
          w_{\mathrm{say},1} &amp; w_{\mathrm{say},2} &amp; w_{\mathrm{say},3} \\
          w_{\mathrm{goodbye},1} &amp; w_{\mathrm{goodbye},2} &amp; w_{\mathrm{goodbye},3} \\
          w_{\mathrm{and},1} &amp; w_{\mathrm{and},2} &amp; w_{\mathrm{and},3} \\
          w_{\mathrm{I},1} &amp; w_{\mathrm{I},2} &amp; w_{\mathrm{I},3} \\
          w_{\mathrm{hello},1} &amp; w_{\mathrm{hello},2} &amp; w_{\mathrm{hello},3} \\
          w_{\mathrm{period},1} &amp; w_{\mathrm{period},2} &amp; w_{\mathrm{period},3} \\
      \end{pmatrix}
\end{split}\]</div>
<p>コンテキストの要素数(列数)と重みの行数が、単語の種類数に対応します。</p>
<p>コンテキスト(単語)はone-hot表現として扱うため、例えば「you」の場合は</p>
<div class="math notranslate nohighlight">
\[
\mathbf{c}_{\mathrm{you}}
    = \begin{pmatrix}
          1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0
      \end{pmatrix}
\]</div>
<p>とすることで、単語「you」を表現できます。</p>
<p>重み付き和<span class="math notranslate nohighlight">\(\mathbf{h}\)</span>は、行列の積で求められます。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbf{h}
   &amp;= \mathbf{c}_{\mathrm{you}}
      \mathbf{W}
\\
   &amp;= \begin{pmatrix}
          h_1 &amp; h_2 &amp; h_3
      \end{pmatrix}
\end{aligned}
\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(h_1\)</span>の計算を詳しく見ると、次のようになります。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
h_1
   &amp;= c_{\mathrm{you}} w_{\mathrm{you},1}
      + c_{\mathrm{say}} w_{\mathrm{say},1}
      + c_{\mathrm{goodbye}} w_{\mathrm{goodbye},1}
      + c_{\mathrm{and}} w_{\mathrm{and},1}
      + c_{\mathrm{I}} w_{\mathrm{I},1}
      + c_{\mathrm{hello}} w_{\mathrm{hello},1}
      + c_{\mathrm{period}} w_{\mathrm{period},1}
\\
   &amp;= 1 w_{\mathrm{you},1}
      + 0 w_{\mathrm{say},1}
      + 0 w_{\mathrm{goodbye},1}
      + 0 w_{\mathrm{and},1}
      + 0 w_{\mathrm{I},1}
      + 0 w_{\mathrm{hello},1}
      + 0 w_{\mathrm{period},1}
\\
   &amp;= w_{\mathrm{you},1}
\end{aligned}
\end{split}\]</div>
<p>コンテキストと重みの対応する(同じ単語に関する)要素を掛けて、全ての単語で和をとります。しかしコンテキストは、<span class="math notranslate nohighlight">\(c_{you}\)</span>以外の要素が<span class="math notranslate nohighlight">\(0\)</span>なので、対応する重みの値の影響は消えていまします。また<span class="math notranslate nohighlight">\(c_{you}\)</span>は<span class="math notranslate nohighlight">\(1\)</span>なので、対応する重みの値<span class="math notranslate nohighlight">\(w_{\mathrm{you},1}\)</span>がそのまま中間層のニューロンに伝播します。</p>
<p>残りの2つの要素も同様に計算できるので、重み付き和</p>
<div class="math notranslate nohighlight">
\[
\mathbf{h}
    = \begin{pmatrix}
          w_{\mathrm{you},1} &amp; w_{\mathrm{you},2} &amp; w_{\mathrm{you},3}
      \end{pmatrix}
\]</div>
<p>は、単語「you」に関する重みの値となります。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># 適当にコンテキスト(one-hot表現)を指定</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;コンテキストの形状：</span><span class="si">{</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># 重みをランダムに生成</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;重み</span><span class="se">\n</span><span class="si">{</span><span class="n">W</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># 重み付き和を計算</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;重み付き和</span><span class="se">\n</span><span class="si">{</span><span class="n">h</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;重み付き和の形状：</span><span class="si">{</span><span class="n">h</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>コンテキストの形状：(1, 7)
重み
[[ 0.15934263  0.45679331 -0.7596429 ]
 [-1.64469721  0.70711971  1.08730806]
 [-0.24061154 -1.00736781  0.78578819]
 [ 1.17422763  0.87932174  0.49089718]
 [ 0.94867032 -1.64499429 -0.99757142]
 [-0.38434571  1.40087279 -0.35217056]
 [-0.28448281 -0.63479044 -1.56293268]]
重み付き和
[[ 0.15934263  0.45679331 -0.7596429 ]]
重み付き和の形状：(1, 3)
</pre></div>
</div>
</div>
</div>
<p>コンテキストに複数な単語がある場合、入力層も複数になります。このとき、中間層にあるニューロンは、各入力層の全結合による変換後の値が平均されたものになります。</p>
<p>中間層のニューロンの数を入力層よりも減らすことによって、中間層には、単語を予測するために必要な情報が”コンパクト”に収められて、結果としては密なベクトル表現が得られます。このとき、この中間層の情報は、人間には理解できない「ブラックボックス」ような状態になります。この作業は、「エンコード」と言います。</p>
</section>
<section id="id6">
<h4>中間層から出力層(デコード)<a class="headerlink" href="#id6" title="Permalink to this headline">#</a></h4>
<p>中間層の情報から目的の結果を得る作業は、「デコード」と言います。ここでは、中間層のニューロンの値<span class="math notranslate nohighlight">\(\mathbf{h}\)</span>を各単語に対応した値になるように、つまり要素(行)数が単語の種類数となるように再度変換したものを、CBOWモデルの出力とします。</p>
<p>出力層の重みを</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{W}_{\mathrm{out}}
    = \begin{pmatrix}
          w_{1,\mathrm{you}} &amp; w_{1,\mathrm{say}} &amp; w_{1,\mathrm{goodbye}} &amp; w_{1,\mathrm{and}} &amp;
          w_{1,\mathrm{I}} &amp; w_{1,\mathrm{hello}} &amp; w_{1,\mathrm{period}} \\
          w_{2,\mathrm{you}} &amp; w_{2,\mathrm{say}} &amp; w_{2,\mathrm{goodbye}} &amp; w_{2,\mathrm{and}} &amp;
          w_{2,\mathrm{I}} &amp; w_{2,\mathrm{hello}} &amp; w_{2,\mathrm{period}} \\
          w_{3,\mathrm{you}} &amp; w_{3,\mathrm{say}} &amp; w_{3,\mathrm{goodbye}} &amp; w_{3,\mathrm{and}} &amp;
          w_{3,\mathrm{I}} &amp; w_{3,\mathrm{hello}} &amp; w_{3\mathrm{period}} \\
      \end{pmatrix}
\end{split}\]</div>
<p>とします。行数が中間層のニューロン数、列数が単語の種類数になります。</p>
<p>出力層も全結合層とすると、最終的な出力は</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbf{s}
   &amp;= \mathbf{h}
      \mathbf{W}_{\mathrm{out}}
\\
   &amp;= \begin{pmatrix}
          s_{\mathrm{you}} &amp; s_{\mathrm{say}} &amp; s_{\mathrm{goodbye}} &amp; s_{\mathrm{and}} &amp;
          s_{\mathrm{I}} &amp; s_{\mathrm{hello}} &amp; s_{\mathrm{period}}
      \end{pmatrix}
\end{aligned}
\end{split}\]</div>
<p>例えば、「you」に関する要素の計算は、</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
s_{\mathrm{you}}
   &amp;= \frac{1}{2} (w_{\mathrm{you},1} + w_{\mathrm{goodbye},1}) w_{1,\mathrm{you}}
      + \frac{1}{2} (w_{\mathrm{you},2} + w_{\mathrm{goodbye},2}) w_{2,\mathrm{you}}
      + \frac{1}{2} (w_{\mathrm{you},3} + w_{\mathrm{goodbye},3}) w_{3,\mathrm{you}}
\\
   &amp;= \frac{1}{2}
      \sum_{i=1}^3
          (w_{\mathrm{you},i} + w_{\mathrm{goodbye},i}) w_{i,\mathrm{you}}
\end{aligned}\end{split}\]</div>
<p>コンテキストに対応する入力層の重みの平均と「you」に関する出力の重みの積になります。</p>
<p>他の要素(単語)についても同様に計算できるので、最終的な出力は</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbf{s}
   &amp;= \begin{pmatrix}
          s_{\mathrm{you}} &amp; s_{\mathrm{say}} &amp; s_{\mathrm{goodbye}} &amp; s_{\mathrm{and}} &amp;
          s_{\mathrm{I}} &amp; s_{\mathrm{hello}} &amp; s_{\mathrm{period}}
      \end{pmatrix}
\\
   &amp;= \begin{pmatrix}
          \frac{1}{2} \sum_{i=1}^3 (w_{\mathrm{you},i} + w_{\mathrm{goodbye},i}) w_{i,\mathrm{you}} &amp;
          \frac{1}{2} \sum_{i=1}^3 (w_{\mathrm{you},i} + w_{\mathrm{goodbye},i}) w_{i,\mathrm{say}} &amp;
          \cdots &amp;
          \frac{1}{2} \sum_{i=1}^3 (w_{\mathrm{you},i} + w_{\mathrm{goodbye},i}) w_{i,\mathrm{hello}} &amp;
          \frac{1}{2} \sum_{i=1}^3 (w_{\mathrm{you},i} + w_{\mathrm{goodbye},i}) w_{i,\mathrm{period}}
      \end{pmatrix}
\end{aligned}
\end{split}\]</div>
<p>となります。</p>
<p>ここで、出力層のニューロンは各単語に対応し、各単語の「スコア」と言います。</p>
<p>「スコア」の値が高ければ高いほど、それに対応する単語の出現確率も高くなり、ターゲットの単語であるとして採用します。そのため、スコアを求める処理を推論処理と言います。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Define the context data</span>
<span class="n">c0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># you</span>
<span class="n">c1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># goodbye</span>

<span class="c1"># Initialize weights randomly</span>
<span class="n">W_in</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># Input layer weights</span>
<span class="n">W_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># Output layer weights</span>

<span class="c1"># Define the layers using PyTorch&#39;s functional API</span>
<span class="k">def</span> <span class="nf">in_layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">out_layer</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">W</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>

<span class="c1"># Forward pass through the input layers</span>
<span class="n">h0</span> <span class="o">=</span> <span class="n">in_layer</span><span class="p">(</span><span class="n">c0</span><span class="p">,</span> <span class="n">W_in</span><span class="p">)</span> <span class="c1"># you</span>
<span class="n">h1</span> <span class="o">=</span> <span class="n">in_layer</span><span class="p">(</span><span class="n">c1</span><span class="p">,</span> <span class="n">W_in</span><span class="p">)</span> <span class="c1"># goodbye</span>
<span class="n">h</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">h0</span> <span class="o">+</span> <span class="n">h1</span><span class="p">)</span>

<span class="c1"># Forward pass through the output layer (scores)</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">out_layer</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">W_out</span><span class="p">)</span>

<span class="c1"># Print the outputs</span>
<span class="n">h0</span><span class="p">,</span> <span class="n">h1</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">decimals</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor([[ 0.2354, -0.4196, -0.5373]]),
 tensor([[ 0.2883,  0.8756, -0.2079]]),
 tensor([[ 0.2618,  0.2280, -0.3726]]),
 tensor([[0.6860, 0.8970, 0.4820, 0.0780, 0.3910, 0.3790, 0.2750]]))
</pre></div>
</div>
</div>
</div>
<div class="sd-tab-set docutils">
<input checked="checked" id="d89c1f10-7c97-4637-8648-74a9f7ff3775" name="8bb274ef-9cba-48f0-b69a-199843506efd" type="radio">
</input><label class="sd-tab-label" for="d89c1f10-7c97-4637-8648-74a9f7ff3775">
課題</label><div class="sd-tab-content docutils">
<p>正解は「say」として、Softmax関数によってスコア<code class="docutils literal notranslate"><span class="pre">s</span></code>を確率として扱えるように変換し、そして、正規化した値と教師ラベルを用いて損失を求めなさい。</p>
</div>
<input id="b64e6370-bdfb-44d2-926c-f67a1607ed1e" name="8bb274ef-9cba-48f0-b69a-199843506efd" type="radio">
</input><label class="sd-tab-label" for="b64e6370-bdfb-44d2-926c-f67a1607ed1e">
ヒント</label><div class="sd-tab-content docutils">
<p>正解は「say」の場合、教師ラベルは<code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1,</span> <span class="pre">0,</span> <span class="pre">0,</span> <span class="pre">0,</span> <span class="pre">0,</span> <span class="pre">0]</span></code>になります。</p>
</div>
</div>
</section>
<section id="id7">
<h4>word2vecの重みと分散表現<a class="headerlink" href="#id7" title="Permalink to this headline">#</a></h4>
<p>与えられたコンテキストに対して単語を予測するときに、「良い重み」のネットワークがあれば、「確率」を表すニューロンにおいて、正解に対応するニューロンが高くなっていることが期待できます。そして、大規模コーパスを使って得られる単語の分散表現は、単語の意味や文法のルールにおいて、人間の直感と合致するケースが多く見られます。</p>
<p>word2vecモデルの学習で行うことが、正しい予測ができるように重みを調整することです。つまり、「コンテキストから出現単語」を予測するという偽タスクをニューラルネットで解いてきましたが、目的はニューラルネットの重みを求めることになります。</p>
<p>もっと具体的に言えば、word2vecで使用されるネットワークには二つの重みがあります。それは、入力層の重み<span class="math notranslate nohighlight">\(\mathbf{W_{in}}\)</span>と、出力層の重み<span class="math notranslate nohighlight">\(\mathbf{W_{out}}\)</span>です。それでは、どちらの重みを使えば良いでしょうか？</p>
<ol class="simple">
<li><p>入力側の重みを利用する</p></li>
<li><p>出力側の重みを利用する</p></li>
<li><p>二つの重みの両方を利用する</p></li>
</ol>
<p>Word2Vecモデルに関しては、多くの研究や応用例で、入力層の重みを単語のベクトル表現として使用さており、良好なパフォーマンスを示しています。</p>
</section>
</section>
</section>
<section id="id8">
<h2>Word2Vecモデルの実装<a class="headerlink" href="#id8" title="Permalink to this headline">#</a></h2>
<section id="id9">
<h3>学習データの準備<a class="headerlink" href="#id9" title="Permalink to this headline">#</a></h3>
<section id="id10">
<h4>コンテキストとターゲット<a class="headerlink" href="#id10" title="Permalink to this headline">#</a></h4>
<p>Word2Vecモデルためのニューラルネットワークでは、「コンテキスト」を入力した時に、「ターゲット」が出現する確率を高くになるように学習を行います。</p>
<p>そのため、コーパスから「コンテキスト」と「ターゲット」が対応するデータを作成する必要があります。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 前処理関数の実装</span>
<span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1"># 前処理</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="c1"># 小文字に変換</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39; .&#39;</span><span class="p">)</span> <span class="c1"># ピリオドの前にスペースを挿入</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span> <span class="c1"># 単語ごとに分割</span>
    
    <span class="c1"># ディクショナリを初期化</span>
    <span class="n">word_to_id</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">id_to_word</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="c1"># 未収録の単語をディクショナリに格納</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">word_to_id</span><span class="p">:</span> <span class="c1"># 未収録の単語のとき</span>
            <span class="c1"># 次の単語のidを取得</span>
            <span class="n">new_id</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">)</span>
            
            <span class="c1"># 単語をキーとして単語IDを格納</span>
            <span class="n">word_to_id</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_id</span>
            
            <span class="c1"># 単語IDをキーとして単語を格納</span>
            <span class="n">id_to_word</span><span class="p">[</span><span class="n">new_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
    
    <span class="c1"># 単語IDリストを作成</span>
    <span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">word_to_id</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># テキストを設定</span>
<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;You say goodbye and I say hello.&#39;</span>

<span class="c1"># 前処理</span>
<span class="n">corpus</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">id_to_word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;you&#39;: 0, &#39;say&#39;: 1, &#39;goodbye&#39;: 2, &#39;and&#39;: 3, &#39;i&#39;: 4, &#39;hello&#39;: 5, &#39;.&#39;: 6}
{0: &#39;you&#39;, 1: &#39;say&#39;, 2: &#39;goodbye&#39;, 3: &#39;and&#39;, 4: &#39;i&#39;, 5: &#39;hello&#39;, 6: &#39;.&#39;}
[0, 1, 2, 3, 4, 1, 5, 6]
</pre></div>
</div>
</div>
</div>
<p>テキストの単語を単語IDに変換した<code class="docutils literal notranslate"><span class="pre">corpus</span></code>からターゲットを抽出します。</p>
<p>ターゲットはコンテキストの中央の単語なので、<code class="docutils literal notranslate"><span class="pre">corpus</span></code>の始めと終わりのウインドウサイズ分の単語は含めません。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ウインドウサイズを指定</span>
<span class="n">window_size</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># ターゲットを抽出</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">corpus</span><span class="p">[</span><span class="n">window_size</span><span class="p">:</span><span class="o">-</span><span class="n">window_size</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1, 2, 3, 4, 1, 5]
</pre></div>
</div>
</div>
</div>
<p>ターゲットの単語に対して、for文で前後ウィンドウサイズの範囲の単語を順番に抽出し<code class="docutils literal notranslate"><span class="pre">cs</span></code>に格納します。</p>
<p>つまりウィンドウサイズを<span class="math notranslate nohighlight">\(1\)</span>とすると、<code class="docutils literal notranslate"><span class="pre">corpus</span></code>におけるターゲットのインデックス<code class="docutils literal notranslate"><span class="pre">idx</span></code>に対して、1つ前(<code class="docutils literal notranslate"><span class="pre">idx</span> <span class="pre">-</span> <span class="pre">window_size</span></code>)から1つ後(<code class="docutils literal notranslate"><span class="pre">idx</span> <span class="pre">+</span> <span class="pre">window_size</span></code>)までの範囲の単語を順番に<code class="docutils literal notranslate"><span class="pre">cs</span></code>格納します。ただしターゲット自体の単語はコンテキストに含めません。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># コンテキストを初期化(受け皿を作成)</span>
<span class="n">contexts</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># 1つ目のターゲットのインデックス</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">window_size</span>

<span class="c1"># 1つ目のターゲットのコンテキストを初期化(受け皿を作成)</span>
<span class="n">cs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># 1つ目のターゲットのコンテキストを1単語ずつ格納</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">window_size</span><span class="p">,</span> <span class="n">window_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    
    <span class="c1"># tがターゲットのインデックスのとき処理しない</span>
    <span class="k">if</span> <span class="n">t</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">continue</span>
    
    <span class="c1"># コンテキストを格納</span>
    <span class="n">cs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">corpus</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="n">t</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">cs</span><span class="p">)</span>

<span class="c1"># 1つ目のターゲットのコンテキストを格納</span>
<span class="n">contexts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">contexts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0]
[0, 2]
[[0, 2]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># コンテキストとターゲットの作成関数の実装</span>
<span class="k">def</span> <span class="nf">create_contexts_target</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    
    <span class="c1"># ターゲットを抽出</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">corpus</span><span class="p">[</span><span class="n">window_size</span><span class="p">:</span><span class="o">-</span><span class="n">window_size</span><span class="p">]</span>
    
    <span class="c1"># コンテキストを初期化</span>
    <span class="n">contexts</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># ターゲットごとにコンテキストを格納</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">window_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span> <span class="o">-</span> <span class="n">window_size</span><span class="p">):</span>
        
        <span class="c1"># 現在のターゲットのコンテキストを初期化</span>
        <span class="n">cs</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="c1"># 現在のターゲットのコンテキストを1単語ずつ格納</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">window_size</span><span class="p">,</span> <span class="n">window_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            
            <span class="c1"># 0番目の要素はターゲットそのものなので処理を省略</span>
            <span class="k">if</span> <span class="n">t</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            
            <span class="c1"># コンテキストを格納</span>
            <span class="n">cs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">corpus</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="n">t</span><span class="p">])</span>
            
        <span class="c1"># 現在のターゲットのコンテキストのセットを格納</span>
        <span class="n">contexts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cs</span><span class="p">)</span>
    
    <span class="c1"># NumPy配列に変換</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">contexts</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">target</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># コンテキストとターゲットを作成</span>
<span class="n">contexts</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">create_contexts_target</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">contexts</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[0 2]
 [1 3]
 [2 4]
 [3 1]
 [4 5]
 [1 6]]
[1 2 3 4 1 5]
</pre></div>
</div>
</div>
</div>
</section>
<section id="id11">
<h4>one-hot表現への変換<a class="headerlink" href="#id11" title="Permalink to this headline">#</a></h4>
<p>単語IDを要素とするコンテキストとターゲットをone-hot表現のコンテキストとターゲットに変換する関数を実装します。</p>
<p>基本的な処理は、単語の種類数個の<span class="math notranslate nohighlight">\(0\)</span>を要素とするベクトルを作成し、単語ID番目の要素だけを<span class="math notranslate nohighlight">\(1\)</span>に置き換えます。</p>
<p>ターゲットは、要素数がターゲット数のベクトルです。変換後は、ターゲット数の行数、単語の種類数の列数の2次元配列になります。つまり、行が各ターゲットの単語、列が各単語IDに対応します。そして行ごとに1つだけ、値が<span class="math notranslate nohighlight">\(1\)</span>の要素を持ちます。</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">np.zeros()</span></code>で変換後の形状の2次元配列を作成し、for文で行ごとに単語ID番目の要素を1を代入します。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">enumerate()</span></code>で引数に渡したリストの要素とその要素のインデックスを出力します。</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ターゲットを確認</span>
<span class="nb">print</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># ターゲットの単語数を取得</span>
<span class="n">N</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># 単語の種類数を取得</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">)</span>

<span class="c1"># 全ての要素が0の変換後の形状の2次元配列を作成</span>
<span class="n">one_hot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">one_hot</span><span class="p">)</span>

<span class="c1"># 単語ID番目の要素を1に置換</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">word_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    <span class="n">one_hot</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="n">word_id</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="n">one_hot</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">one_hot</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1 2 3 4 1 5]
(6,)
[[0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0]]
[[0 1 0 0 0 0 0]
 [0 0 1 0 0 0 0]
 [0 0 0 1 0 0 0]
 [0 0 0 0 1 0 0]
 [0 1 0 0 0 0 0]
 [0 0 0 0 0 1 0]]
(6, 7)
</pre></div>
</div>
</div>
</div>
<p>コンテキストは、0次元目の要素数がターゲット数、1次元目の要素数がウィンドウサイズの<span class="math notranslate nohighlight">\(2\)</span>倍の2次元配列です。</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">np.zeros()</span></code>で形状が<code class="docutils literal notranslate"><span class="pre">(N,</span> <span class="pre">C,</span> <span class="pre">vocab_size)</span></code>である配列を作成し、単語ID番目の要素を1に置換します。</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># コンテキストを確認</span>
<span class="nb">print</span><span class="p">(</span><span class="n">contexts</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">contexts</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># ターゲットの単語数を取得</span>
<span class="n">N</span> <span class="o">=</span> <span class="n">contexts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># コンテキストサイズを取得</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">contexts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># 単語の種類数を取得</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">)</span>

<span class="c1"># 全ての要素が0の変換後の形状の3次元配列を作成</span>
<span class="n">one_hot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;全ての要素が0の変換後の形状の3次元配列を作成&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">one_hot</span><span class="p">)</span>

<span class="c1"># 単語ID番目の要素を1に置換</span>
<span class="k">for</span> <span class="n">idx_0</span><span class="p">,</span> <span class="n">word_ids</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">contexts</span><span class="p">):</span> <span class="c1"># 0次元方向</span>
    <span class="k">for</span> <span class="n">idx_1</span><span class="p">,</span> <span class="n">word_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">word_ids</span><span class="p">):</span> <span class="c1"># 1次元方向</span>
        <span class="n">one_hot</span><span class="p">[</span><span class="n">idx_0</span><span class="p">,</span> <span class="n">idx_1</span><span class="p">,</span> <span class="n">word_id</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;単語ID番目の要素を1に置換&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">one_hot</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">one_hot</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[0 2]
 [1 3]
 [2 4]
 [3 1]
 [4 5]
 [1 6]]
(6, 2)
全ての要素が0の変換後の形状の3次元配列を作成
[[[0 0 0 0 0 0 0]
  [0 0 0 0 0 0 0]]

 [[0 0 0 0 0 0 0]
  [0 0 0 0 0 0 0]]

 [[0 0 0 0 0 0 0]
  [0 0 0 0 0 0 0]]

 [[0 0 0 0 0 0 0]
  [0 0 0 0 0 0 0]]

 [[0 0 0 0 0 0 0]
  [0 0 0 0 0 0 0]]

 [[0 0 0 0 0 0 0]
  [0 0 0 0 0 0 0]]]
単語ID番目の要素を1に置換
[[[1 0 0 0 0 0 0]
  [0 0 1 0 0 0 0]]

 [[0 1 0 0 0 0 0]
  [0 0 0 1 0 0 0]]

 [[0 0 1 0 0 0 0]
  [0 0 0 0 1 0 0]]

 [[0 0 0 1 0 0 0]
  [0 1 0 0 0 0 0]]

 [[0 0 0 0 1 0 0]
  [0 0 0 0 0 1 0]]

 [[0 1 0 0 0 0 0]
  [0 0 0 0 0 0 1]]]
(6, 2, 7)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># one-hot表現への変換関数の実装</span>
<span class="k">def</span> <span class="nf">convert_one_hot</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
    
    <span class="c1"># ターゲットの単語数を取得</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">corpus</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="c1"># one-hot表現に変換</span>
    <span class="k">if</span> <span class="n">corpus</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span> <span class="c1"># 1次元配列のとき</span>
        
        <span class="c1"># 変換後の形状の2次元配列を作成</span>
        <span class="n">one_hot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        
        <span class="c1"># 単語ID番目の要素を1に置換</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">word_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
            <span class="n">one_hot</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="n">word_id</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    
    <span class="k">elif</span> <span class="n">corpus</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span> <span class="c1"># 2次元配列のとき</span>
        
        <span class="c1"># コンテキストサイズを取得</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">corpus</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># 変換後の形状の3次元配列を作成</span>
        <span class="n">one_hot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        
        <span class="c1"># 単語ID番目の要素を1に置換</span>
        <span class="k">for</span> <span class="n">idx_0</span><span class="p">,</span> <span class="n">word_ids</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span> <span class="c1"># 0次元方向</span>
            <span class="k">for</span> <span class="n">idx_1</span><span class="p">,</span> <span class="n">word_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">word_ids</span><span class="p">):</span> <span class="c1"># 1次元方向</span>
                <span class="n">one_hot</span><span class="p">[</span><span class="n">idx_0</span><span class="p">,</span> <span class="n">idx_1</span><span class="p">,</span> <span class="n">word_id</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    
    <span class="k">return</span> <span class="n">one_hot</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="cbow">
<h3>CBOWモデルの実装<a class="headerlink" href="#cbow" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="k">class</span> <span class="nc">SimpleCBOW</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SimpleCBOW</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 入力層と中間層の重み</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">)</span>
        <span class="c1"># 中間層の次元を調整するための線形層</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">middle_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embedding_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="c1"># 中間層と出力層の重み</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
        <span class="c1"># 単語の分散表現を初期化</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># 重みを標準正規分布で初期化</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">middle_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">contexts</span><span class="p">):</span>
        <span class="c1"># 入力層から中間層への順伝播</span>
        <span class="c1"># contextsは周囲の単語のインデックスのバッチ</span>
        <span class="n">embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layer</span><span class="p">(</span><span class="n">contexts</span><span class="p">)</span>  <span class="c1"># 埋め込みレイヤーを適用</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">embeds</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 埋め込みの平均を取る</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">middle_layer</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>  <span class="c1"># 中間層に適用</span>
        <span class="c1"># 中間層から出力層への順伝播</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_layer</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">contexts</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="c1"># 順伝播</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">contexts</span><span class="p">)</span>
        <span class="c1"># 損失の計算</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">=</span><span class="n">SimpleCBOW</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">contexts</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">IndexError</span><span class="g g-Whitespace">                                </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">14</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">contexts</span><span class="p">))</span>

<span class="nn">Cell In[12], line 26,</span> in <span class="ni">SimpleCBOW.forward</span><span class="nt">(self, contexts)</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">contexts</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">24</span>     <span class="c1"># 入力層から中間層への順伝播</span>
<span class="g g-Whitespace">     </span><span class="mi">25</span>     <span class="c1"># contextsは周囲の単語のインデックスのバッチ</span>
<span class="ne">---&gt; </span><span class="mi">26</span>     <span class="n">embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layer</span><span class="p">(</span><span class="n">contexts</span><span class="p">)</span>  <span class="c1"># 埋め込みレイヤーを適用</span>
<span class="g g-Whitespace">     </span><span class="mi">27</span>     <span class="n">h</span> <span class="o">=</span> <span class="n">embeds</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 埋め込みの平均を取る</span>
<span class="g g-Whitespace">     </span><span class="mi">28</span>     <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">middle_layer</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>  <span class="c1"># 中間層に適用</span>

<span class="nn">File /opt/anaconda3/envs/jupyterbook/lib/python3.10/site-packages/torch/nn/modules/module.py:1518,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1516</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1517</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1518</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File /opt/anaconda3/envs/jupyterbook/lib/python3.10/site-packages/torch/nn/modules/module.py:1527,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1522</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1523</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1524</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1525</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1526</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1527</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1529</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1530</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File /opt/anaconda3/envs/jupyterbook/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162,</span> in <span class="ni">Embedding.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">161</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">162</span>     <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">163</span>         <span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_norm</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">164</span>         <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_grad_by_freq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span><span class="p">)</span>

<span class="nn">File /opt/anaconda3/envs/jupyterbook/lib/python3.10/site-packages/torch/nn/functional.py:2233,</span> in <span class="ni">embedding</span><span class="nt">(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)</span>
<span class="g g-Whitespace">   </span><span class="mi">2227</span>     <span class="c1"># Note [embedding_renorm set_grad_enabled]</span>
<span class="g g-Whitespace">   </span><span class="mi">2228</span>     <span class="c1"># XXX: equivalent to</span>
<span class="g g-Whitespace">   </span><span class="mi">2229</span>     <span class="c1"># with torch.no_grad():</span>
<span class="g g-Whitespace">   </span><span class="mi">2230</span>     <span class="c1">#   torch.embedding_renorm_</span>
<span class="g g-Whitespace">   </span><span class="mi">2231</span>     <span class="c1"># remove once script supports set_grad_enabled</span>
<span class="g g-Whitespace">   </span><span class="mi">2232</span>     <span class="n">_no_grad_embedding_renorm_</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">max_norm</span><span class="p">,</span> <span class="n">norm_type</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">2233</span> <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="p">,</span> <span class="n">sparse</span><span class="p">)</span>

<span class="ne">IndexError</span>: index out of range in self
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># テキストを設定</span>
<span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;You say goodbye and I say hello.&#39;</span>

<span class="c1"># 前処理</span>
<span class="n">corpus</span><span class="p">,</span> <span class="n">word_to_id</span><span class="p">,</span> <span class="n">id_to_word</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">id_to_word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;you&#39;: 0, &#39;say&#39;: 1, &#39;goodbye&#39;: 2, &#39;and&#39;: 3, &#39;i&#39;: 4, &#39;hello&#39;: 5, &#39;.&#39;: 6}
{0: &#39;you&#39;, 1: &#39;say&#39;, 2: &#39;goodbye&#39;, 3: &#39;and&#39;, 4: &#39;i&#39;, 5: &#39;hello&#39;, 6: &#39;.&#39;}
[0, 1, 2, 3, 4, 1, 5, 6]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ウインドウサイズ</span>
<span class="n">window_size</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># 単語の種類数を取得</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_to_id</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>

<span class="c1"># コンテキストとターゲットを作成</span>
<span class="n">contexts</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">create_contexts_target</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">window_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">contexts</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">contexts</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># one-hot表現に変換</span>
<span class="n">contexts</span> <span class="o">=</span> <span class="n">convert_one_hot</span><span class="p">(</span><span class="n">contexts</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">convert_one_hot</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">contexts</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">contexts</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>7
[[0 2]
 [1 3]
 [2 4]
 [3 1]
 [4 5]
 [1 6]]
(6, 2)
[1 2 3 4 1 5]
(6,)
[[[1 0 0 0 0 0 0]
  [0 0 1 0 0 0 0]]

 [[0 1 0 0 0 0 0]
  [0 0 0 1 0 0 0]]

 [[0 0 1 0 0 0 0]
  [0 0 0 0 1 0 0]]

 [[0 0 0 1 0 0 0]
  [0 1 0 0 0 0 0]]

 [[0 0 0 0 1 0 0]
  [0 0 0 0 0 1 0]]

 [[0 1 0 0 0 0 0]
  [0 0 0 0 0 0 1]]]
(6, 2, 7)
[[0 1 0 0 0 0 0]
 [0 0 1 0 0 0 0]
 [0 0 0 1 0 0 0]
 [0 0 0 0 1 0 0]
 [0 1 0 0 0 0 0]
 [0 0 0 0 0 1 0]]
(6, 7)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="o">=</span><span class="n">model</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">contexts</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embeds</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[[-1.0733, -1.1314,  0.7917],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342]],

         [[-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-1.0733, -1.1314,  0.7917],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342]]],


        [[[-0.1738, -0.3991, -0.0342],
          [-1.0733, -1.1314,  0.7917],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342]],

         [[-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-1.0733, -1.1314,  0.7917],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342]]],


        [[[-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-1.0733, -1.1314,  0.7917],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342]],

         [[-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-1.0733, -1.1314,  0.7917],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342]]],


        [[[-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-1.0733, -1.1314,  0.7917],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342]],

         [[-0.1738, -0.3991, -0.0342],
          [-1.0733, -1.1314,  0.7917],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342]]],


        [[[-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-1.0733, -1.1314,  0.7917],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342]],

         [[-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-1.0733, -1.1314,  0.7917],
          [-0.1738, -0.3991, -0.0342]]],


        [[[-0.1738, -0.3991, -0.0342],
          [-1.0733, -1.1314,  0.7917],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342]],

         [[-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-0.1738, -0.3991, -0.0342],
          [-1.0733, -1.1314,  0.7917]]]], grad_fn=&lt;EmbeddingBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h</span> <span class="o">=</span> <span class="n">embeds</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([6, 7, 3])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleCBOW</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SimpleCBOW</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">)</span>  <span class="c1"># 単語埋め込み</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embedding_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>  <span class="c1"># 中間層</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>  <span class="c1"># 出力層</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">contexts</span><span class="p">):</span>
        <span class="c1"># contextは [batch_size, context_window * 2]</span>
        <span class="n">embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span><span class="n">contexts</span><span class="p">)</span>  <span class="c1"># [batch_size, context_window * 2, embedding_size]</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">embeds</span> <span class="o">=</span> <span class="n">embeds</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch_size, embedding_size]</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">embeds</span><span class="p">)</span>  <span class="c1"># [batch_size, hidden_size]</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>  <span class="c1"># 活性化関数</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>  <span class="c1"># [batch_size, vocab_size]</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">=</span><span class="n">SimpleCBOW</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">contexts</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([6, 7, 6])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">contexts</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[-9.3958e+00, -1.9546e+01, -1.3012e+01, -9.7609e-01, -2.8456e+01,
          -4.7300e-01],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-9.3958e+00, -1.9546e+01, -1.3012e+01, -9.7609e-01, -2.8456e+01,
          -4.7300e-01],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00]],

        [[-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-9.3958e+00, -1.9546e+01, -1.3012e+01, -9.7609e-01, -2.8456e+01,
          -4.7300e-01],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-9.3958e+00, -1.9546e+01, -1.3012e+01, -9.7609e-01, -2.8456e+01,
          -4.7300e-01],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00]],

        [[-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-9.3958e+00, -1.9546e+01, -1.3012e+01, -9.7609e-01, -2.8456e+01,
          -4.7300e-01],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-9.3958e+00, -1.9546e+01, -1.3012e+01, -9.7609e-01, -2.8456e+01,
          -4.7300e-01],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00]],

        [[-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-9.3958e+00, -1.9546e+01, -1.3012e+01, -9.7609e-01, -2.8456e+01,
          -4.7300e-01],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-9.3958e+00, -1.9546e+01, -1.3012e+01, -9.7609e-01, -2.8456e+01,
          -4.7300e-01],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00]],

        [[-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-9.3958e+00, -1.9546e+01, -1.3012e+01, -9.7609e-01, -2.8456e+01,
          -4.7300e-01],
         [-9.3958e+00, -1.9546e+01, -1.3012e+01, -9.7609e-01, -2.8456e+01,
          -4.7300e-01],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00]],

        [[-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-9.3958e+00, -1.9546e+01, -1.3012e+01, -9.7609e-01, -2.8456e+01,
          -4.7300e-01],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-7.3104e+00, -2.8340e+01, -1.1410e+01, -1.4202e-02, -3.5601e+01,
          -4.3108e+00],
         [-9.3958e+00, -1.9546e+01, -1.3012e+01, -9.7608e-01, -2.8456e+01,
          -4.7300e-01]]], grad_fn=&lt;LogSoftmaxBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebook"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By 呂　沢宇<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>