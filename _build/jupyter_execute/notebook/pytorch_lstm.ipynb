{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTMの実装\n",
    "\n",
    "## [torch.nn.LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorchの[torch.nn.LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)クラスを使用して、LSTMをモデルに簡単にレイヤーとして追加できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`torch.nn.LSTM`の主なパラメータは以下の通りです：\n",
    "\n",
    "- `input_size`：入力xの特徴量の数\n",
    "- `hidden_size`：隠れ状態の特徴量の数\n",
    "- `num_layers`：LSTMを重ねる層の数（デフォルトは$1$）\n",
    "- `bias`：バイアスを使用するかどうか（デフォルトは`True`）\n",
    "- `batch_first`：入力と出力のテンソルの形状が(`batch`, `seq`, `feature`)になるようにするかどうか（デフォルトは`False`）\n",
    "- `dropout`：ドロップアウトを適用する確率（デフォルトは$0$、つまりドロップアウトなし）\n",
    "- `bidirectional`：双方向LSTMを使用するかどうか（デフォルトは`False`）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `input_size=10`：各入力要素の特徴の数（入力ベクトルの次元数）は10です\n",
    "- `hidden_size=20`：隠れ状態とセル状態の各ベクトルのサイズは20です\n",
    "- `num_layers=2`： LSTMの層の数は2です\n",
    "    - 最初のLSTM層は入力シーケンスを受け取り、それを処理して一連の隠れ状態を生成します。\n",
    "    - 最初の層の出力（隠れ状態）は、次のLSTM層の入力となります。これが複数層にわたって繰り返されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# LSTMのインスタンス化\n",
    "lstm = nn.LSTM(input_size=10, hidden_size=20,num_layers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 入力データの生成（例：バッチサイズ=3, シーケンス長=5）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(5, 3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `h0`:隠れ状態の初期値\n",
    "    - `h0` のサイズは`(num_layers * num_directions, batch_size, hidden_size)`になります\n",
    "        - `num_directions`:LSTMが単方向か双方向かを示し（単方向の場合は$1$、双方向の場合は$2$）\n",
    "- `c0`:セル状態の初期値\n",
    "    - `c0` のサイズは同様に`(num_layers * num_directions, batch_size, hidden_size)`になります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隠れ状態とセル状態の初期化\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 出力\n",
    "\n",
    "`torch.nn.LSTM`の出力は、出力テンソル（通常は `output` と呼ばれます）と隠れ状態（`h_n` と `c_n`）から構成されています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 順伝播\n",
    "output, (hn, cn) = lstm(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: torch.Size([5, 3, 20])\n",
      "hn: torch.Size([2, 3, 20])\n",
      "cn: torch.Size([2, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "print(f\"output: {output.shape}\")\n",
    "print(f\"hn: {hn.shape}\")\n",
    "print(f\"cn: {cn.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 出力テンソル（`output`）\n",
    "    - シーケンス内の各時点におけるLSTMの隠れ状態を含んでいます。\n",
    "    - サイズは `(seq_len, batch, num_directions * hidden_size)` になります。\n",
    "- 最終隠れ状態(`h_n`)\n",
    "    - LSTMの最終的な隠れ状態です。\n",
    "    - サイズは`(num_layers * num_directions, batch, hidden_size)` になります。\n",
    "\n",
    "```{note}\n",
    "- outputの最終時点の隠れ状態（つまり output[-1] ）は、単層、単方向LSTMの場合、hn と同じです。\n",
    "- 多層LSTMの場合、hnは各層の最終隠れ状態を含むため、outputの最終時点の隠れ状態とは異なることがあります。この場合、outputの最後の要素は最終層の最終隠れ状態に対応し、hn にはそれぞれの層の最終隠れ状態が格納されます。\n",
    "```\n",
    "\n",
    "- 最終セル状態(`c_n`)\n",
    "    - LSTMの最終的なセル状態です。長期的な依存関係をどのように「記憶」しているかを示します。\n",
    "    - サイズは `(num_layers * num_directions, batch, hidden_size)` です\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{tab-set}\n",
    "```{tab-item} 質問1\n",
    "タスクに応じて、torch.nn.LSTMの出力を扱う必要があります。例えば、テキスト生成、機械通訳、文書分類はそれぞれどの出力を使うべきですか？\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}