{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install langchain openai tiktoken chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-KFB7J_u_3L",
    "outputId": "a29ed872-d0bc-41ef-bb72-b6a0fe426a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\r\n",
      "Version: 0.1.4\r\n",
      "Summary: Building applications with LLMs through composability\r\n",
      "Home-page: https://github.com/langchain-ai/langchain\r\n",
      "Author: \r\n",
      "Author-email: \r\n",
      "License: MIT\r\n",
      "Location: /Users/ryozawau/anaconda3/envs/jupyterbook/lib/python3.12/site-packages\r\n",
      "Requires: aiohttp, dataclasses-json, jsonpatch, langchain-community, langchain-core, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\r\n",
      "Required-by: langchain-experimental\r\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "l6XPLPVrqEaV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace new_articles/05-07-fintech-space-continues-to-be-competitive-and-drama-filled.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "!wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip\n",
    "!unzip -q new_articles.zip -d new_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AnZQpL_IZZZ"
   },
   "source": [
    "# LangChain multi-doc retriever with ChromaDB\n",
    "\n",
    "***New Points***\n",
    "- Multiple Files\n",
    "- ChromaDB\n",
    "- Source info\n",
    "- gpt-3.5-turbo API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqwsGJDhvAQ5"
   },
   "source": [
    "## Setting up LangChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNA4TsHpu6OM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XHVE9uFb3Ajj"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UcQKUId3X2M"
   },
   "source": [
    "## Load multiple and process documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRSeXXc_3Ypj"
   },
   "outputs": [],
   "source": [
    "# Load and process the text files\n",
    "# loader = TextLoader('single_text_file.txt')\n",
    "loader = DirectoryLoader('./new_articles/', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3__nT0D4Fkmg"
   },
   "outputs": [],
   "source": [
    "#splitting the text into\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TlU5AlqY4gwj",
    "outputId": "d78fb098-3161-42cd-8ce9-5f98f4ef91d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bg6-9jwU4ja_",
    "outputId": "02f45055-0e09-42ba-9ff3-0e7850f06cae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='on Banking, Housing, and Urban Affairs, wrote a letter to FDIC chairman Martin Gruenberg expressing concerns about Tellus’s claims. In that letter, Brown pressed the FDIC to review Tellus’s business practices “to ensure that customers are protected from financial fraud and abuse.” In a twist, I discovered that Lee was married to a16z general partner Connie Chan (not sure if he still is). Neither he nor the venture firm commented on the senator’s concerns but Tellus CEO/CTO Jeromee Johnson did provide me with a statement via email. Read more here.', metadata={'source': 'new_articles/05-07-fintech-space-continues-to-be-competitive-and-drama-filled.txt'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsYsIy8F4cdm"
   },
   "source": [
    "## create the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_eTIZwf4Dk2",
    "outputId": "1cd293c4-716c-402d-d41b-045b6a264041"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:chromadb:Using embedded DuckDB with persistence: data will be stored in: db\n"
     ]
    }
   ],
   "source": [
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'db'\n",
    "\n",
    "## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=texts,\n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uRfD_Te-47lb"
   },
   "outputs": [],
   "source": [
    "# persiste the db to disk\n",
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-h1y_eAHmD-",
    "outputId": "4a6097fb-e30e-4fa2-ff4d-b972ce7f6154"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:chromadb:Using embedded DuckDB with persistence: data will be stored in: db\n"
     ]
    }
   ],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal.\n",
    "vectordb = Chroma(persist_directory=persist_directory,\n",
    "                  embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siLXR-XT0JoI"
   },
   "source": [
    "## Make a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ObunFU30Lxh"
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cYA-H59u0Skn"
   },
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"How much money did Pando raise?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h0iAuh_B0ZjE",
    "outputId": "2ffd1da1-ff6c-4ea9-c361-7230dbd5bdc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVWgPJXs1yRq"
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "H4N0IhRM0hHL",
    "outputId": "f8058122-1c8a-4c5b-f046-14a90eed5a3b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'similarity'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4jXL9u-u0prF",
    "outputId": "2e6dd94e-bede-4e05-c841-9c755ecfef2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 2}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ia-4OXa5IeP"
   },
   "source": [
    "## Make a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MGx8XblM4shW"
   },
   "outputs": [],
   "source": [
    "# create the chain to answer questions\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(),\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=retriever,\n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZEo26mw8e5k"
   },
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wKfX4vX-5RFT",
    "outputId": "b3902fd2-86cc-4020-86a9-99883a996d20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pando raised $30 million in a Series B round, bringing its total raised to $45 million.\n",
      "\n",
      "\n",
      "Sources:\n",
      "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
     ]
    }
   ],
   "source": [
    "# full example\n",
    "query = \"How much money did Pando raise?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "olRm73t3rNt2",
    "outputId": "20fb1b17-6562-421d-a60e-c67b97ca67d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the news about Pando?',\n",
       " 'result': ' Pando raised $30 million in a Series B round, bringing their total raised to $45 million. The money will be used to expand their global sales, marketing and delivery capabilities, as well as to hire more staff and explore strategic partnerships and acquisitions.',\n",
       " 'source_documents': [Document(page_content='Pando was co-launched by Jayakrishnan and Abhijeet Manohar, who previously worked together at iDelivery, an India-based freight tech marketplace — and their first startup. The two saw firsthand manufacturers, distributors and retailers were struggling with legacy tech and point solutions to understand, optimize and manage their global logistics operations — or at least, that’s the story Jayakrishnan tells.\\n\\n“Supply chain leaders were trying to build their own tech and throwing people at the problem,” he said. “This caught our attention — we spent months talking to and building for enterprise users at warehouses, factories, freight yards and ports and eventually, in 2018, decided to start Pando to solve for global logistics through a software-as-a-service platform offering.”', metadata={'source': 'new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}),\n",
       "  Document(page_content='Signaling that investments in the supply chain sector remain robust, Pando, a startup developing fulfillment management technologies, today announced that it raised $30 million in a Series B round, bringing its total raised to $45 million.\\n\\nIron Pillar and Uncorrelated Ventures led the round, with participation from existing investors Nexus Venture Partners, Chiratae Ventures and Next47. CEO and founder Nitin Jayakrishnan says that the new capital will be put toward expanding Pando’s global sales, marketing and delivery capabilities.\\n\\n“We will not expand into new industries or adjacent product areas,” he told TechCrunch in an email interview. “Great talent is the foundation of the business — we will continue to augment our teams at all levels of the organization. Pando is also open to exploring strategic partnerships and acquisitions with this round of funding.”', metadata={'source': 'new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'})]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# break it down\n",
    "query = \"What is the news about Pando?\"\n",
    "llm_response = qa_chain(query)\n",
    "# process_llm_response(llm_response)\n",
    "llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wg-e6fh6rNwz",
    "outputId": "4b8d1e0e-b039-4e21-c233-a6c308cc5e25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iron Pillar and Uncorrelated Ventures.\n",
      "\n",
      "\n",
      "Sources:\n",
      "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"Who led the round in Pando?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cuFf8D-rrN0I",
    "outputId": "19c63b88-33e2-4400-eede-f2678231eccb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Databricks acquired Okera, a data governance platform with a focus on AI.\n",
      "\n",
      "\n",
      "Sources:\n",
      "new_articles/05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n",
      "new_articles/05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"What did databricks acquire?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t5KETxphrN3d",
    "outputId": "4f4a7dfb-0f5b-4b72-b678-6def5d056d20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generative AI is a type of artificial intelligence that is used to create new content associated with a company, such as content for a website or ads. It can also be used to automate processes and workflows.\n",
      "\n",
      "\n",
      "Sources:\n",
      "new_articles/05-04-slack-updates-aim-to-put-ai-at-the-center-of-the-user-experience.txt\n",
      "new_articles/05-03-nova-is-building-guardrails-for-generative-ai-content-to-protect-brand-integrity.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"What is generative ai?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "692pHNkFrN5z",
    "outputId": "85124452-c208-4ec4-a35d-be28503ddc42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The CMA stands for the Competition and Markets Authority.\n",
      "\n",
      "\n",
      "Sources:\n",
      "new_articles/05-04-cma-generative-ai-review.txt\n",
      "new_articles/05-04-cma-generative-ai-review.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is CMA?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPIhZWAR5n3X",
    "outputId": "68914c62-f8ed-4e22-d889-7991df441d53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('similarity', <langchain.vectorstores.chroma.Chroma at 0x7f9f7dc82aa0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.retriever.search_type , qa_chain.retriever.vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_lp0_796P_-",
    "outputId": "64c01726-6e78-4c12-e409-2fdc839f6611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "{context}\n",
      "\n",
      "Question: {question}\n",
      "Helpful Answer:\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSxVCnNi5h1-"
   },
   "source": [
    "## Deleteing the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7xmepGJ2GAE",
    "outputId": "92b53c84-ef81-4000-db5a-2c2ec09db311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: db/ (stored 0%)\n",
      "  adding: db/chroma-collections.parquet (deflated 50%)\n",
      "  adding: db/index/ (stored 0%)\n",
      "  adding: db/index/index_metadata_59c51927-205d-4fd7-88d8-c7ba851bd2a5.pkl (deflated 5%)\n",
      "  adding: db/index/uuid_to_id_59c51927-205d-4fd7-88d8-c7ba851bd2a5.pkl (deflated 39%)\n",
      "  adding: db/index/index_59c51927-205d-4fd7-88d8-c7ba851bd2a5.bin (deflated 17%)\n",
      "  adding: db/index/id_to_uuid_59c51927-205d-4fd7-88d8-c7ba851bd2a5.pkl (deflated 35%)\n",
      "  adding: db/chroma-embeddings.parquet (deflated 29%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r db.zip ./db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jl84qGQt5Wu5"
   },
   "outputs": [],
   "source": [
    "# To cleanup, you can delete the collection\n",
    "vectordb.delete_collection()\n",
    "vectordb.persist()\n",
    "\n",
    "# delete the directory\n",
    "!rm -rf db/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2r0ZIBPJp-K"
   },
   "source": [
    "## Starting again loading the db\n",
    "\n",
    "restart the runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8pc7CM_mTQAt",
    "outputId": "f8e311fb-7d68-43af-ffd6-f66a9259766a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  db.zip\n",
      "   creating: db/\n",
      "  inflating: db/chroma-collections.parquet  \n",
      "   creating: db/index/\n",
      "  inflating: db/index/index_metadata_59c51927-205d-4fd7-88d8-c7ba851bd2a5.pkl  \n",
      "  inflating: db/index/uuid_to_id_59c51927-205d-4fd7-88d8-c7ba851bd2a5.pkl  \n",
      "  inflating: db/index/index_59c51927-205d-4fd7-88d8-c7ba851bd2a5.bin  \n",
      "  inflating: db/index/id_to_uuid_59c51927-205d-4fd7-88d8-c7ba851bd2a5.pkl  \n",
      "  inflating: db/chroma-embeddings.parquet  \n"
     ]
    }
   ],
   "source": [
    "!unzip db.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "us3F8ZKeRiz2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qK1nY4PkKYGo"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "396RyNbS4EXx",
    "outputId": "502d5c81-0823-4c00-89ca-7b4dd08bee26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:chromadb:Using embedded DuckDB with persistence: data will be stored in: db\n"
     ]
    }
   ],
   "source": [
    "persist_directory = 'db'\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb2 = Chroma(persist_directory=persist_directory,\n",
    "                  embedding_function=embedding,\n",
    "                   )\n",
    "\n",
    "retriever = vectordb2.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3vkSxxYKCZ9"
   },
   "outputs": [],
   "source": [
    "# Set up the turbo LLM\n",
    "turbo_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PsR60NH5KCfj"
   },
   "outputs": [],
   "source": [
    "# create the chain to answer questions\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=turbo_llm,\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=retriever,\n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWulTG0eKCfk"
   },
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mDp-g2FtKCfk",
    "outputId": "766f131a-daaf-462f-842a-f7bd10a081fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pando raised $30 million in a Series B round, bringing its total raised to $45 million.\n",
      "\n",
      "\n",
      "Sources:\n",
      "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
     ]
    }
   ],
   "source": [
    "# full example\n",
    "query = \"How much money did Pando raise?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fPl26c-TbWw"
   },
   "source": [
    "### Chat prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwyuhrpu5XqM",
    "outputId": "0f2c8060-4002-49ba-8869-6a9990c2c6d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the users question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "{context}\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LcWXvSCHRvHO",
    "outputId": "d7a3acee-9ef1-4c08-b2a0-187f2cd90c8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{question}\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[1].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "978QWCeJSRdu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}