{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seqの応用：機械翻訳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import spacy\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "path = './Data/raw'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'r') as f:\n",
    "  raw_data = f.readlines()\n",
    "raw_list = [re.sub('\\n', '', s).split('\\t') for s in raw_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Japanese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you are back, aren't you, harold?</td>\n",
       "      <td>あなたは戻ったのね ハロルド?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my opponent is shark.</td>\n",
       "      <td>俺の相手は シャークだ。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is one thing in exchange for another.</td>\n",
       "      <td>引き換えだ ある事とある物の</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yeah, i'm fine.</td>\n",
       "      <td>もういいよ ごちそうさま ううん</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>don't come to the office anymore. don't call m...</td>\n",
       "      <td>もう会社には来ないでくれ 電話もするな</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             English             Japanese\n",
       "0                  you are back, aren't you, harold?      あなたは戻ったのね ハロルド?\n",
       "1                              my opponent is shark.         俺の相手は シャークだ。\n",
       "2         this is one thing in exchange for another.       引き換えだ ある事とある物の\n",
       "3                                    yeah, i'm fine.     もういいよ ごちそうさま ううん\n",
       "4  don't come to the office anymore. don't call m...  もう会社には来ないでくれ 電話もするな"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.DataFrame(raw_list,\n",
    "                  columns=['English', 'Japanese'])\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ja-core-news-md==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ja_core_news_md-3.7.0/ja_core_news_md-3.7.0-py3-none-any.whl (42.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from ja-core-news-md==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: sudachipy!=0.6.1,>=0.5.2 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from ja-core-news-md==3.7.0) (0.6.7)\n",
      "Requirement already satisfied: sudachidict-core>=20211220 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from ja-core-news-md==3.7.0) (20230927)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (2.5.2)\n",
      "Requirement already satisfied: jinja2 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (69.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (1.26.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ja-core-news-md==3.7.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ja_core_news_md')\n",
      "Collecting en-core-web-md==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from en-core-web-md==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.5.2)\n",
      "Requirement already satisfied: jinja2 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (69.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/lyuzeyu/anaconda3/envs/dl/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download ja_core_news_md\n",
    "!python3 -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "JA = spacy.load(\"ja_core_news_md\")\n",
    "EN = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'are', 'back', ',', 'are', \"n't\", 'you', ',', 'harold', '?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in EN.tokenizer(raw_df[\"English\"][0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['あなた', 'は', '戻っ', 'た', 'の', 'ね', 'ハロルド', '?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in JA.tokenizer(raw_df[\"Japanese\"][0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_ja(sentence):\n",
    "    return [tok.text for tok in JA.tokenizer(sentence)]\n",
    "\n",
    "def tokenize_en(sentence):\n",
    "    return [tok.text for tok in EN.tokenizer(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text,tokenizer,sos_token=\"<sos>\",eos_token=\"<eos>\"):\n",
    "    text = text.lower()\n",
    "    tokens = [tok.text for tok in tokenizer.tokenizer(text)]\n",
    "    tokens = [sos_token] + tokens + [eos_token]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df[\"en_tokens\"]=raw_df[\"English\"].apply(lambda x: preprocess_text(x,EN))\n",
    "raw_df[\"ja_tokens\"]=raw_df[\"Japanese\"].apply(lambda x: preprocess_text(x,JA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df, test_df = train_test_split(raw_df, test_size=0.2)\n",
    "# Split the training plus validation set into separate training and validation sets\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Japanese</th>\n",
       "      <th>en_tokens</th>\n",
       "      <th>ja_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>938480</th>\n",
       "      <td>just because.</td>\n",
       "      <td>分かったから</td>\n",
       "      <td>[&lt;sos&gt;, just, because, ., &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, 分かっ, た, から, &lt;eos&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161948</th>\n",
       "      <td>the west had corrupted me with divergent ideas</td>\n",
       "      <td>西洋の逸脱した概念が 私を堕落させた</td>\n",
       "      <td>[&lt;sos&gt;, the, west, had, corrupted, me, with, d...</td>\n",
       "      <td>[&lt;sos&gt;, 西洋, の, 逸脱, し, た, 概念, が, 私, を, 堕落, さ, せ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639794</th>\n",
       "      <td>right?</td>\n",
       "      <td>――でしょ?</td>\n",
       "      <td>[&lt;sos&gt;, right, ?, &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, ―, ―, でしょ, ?, &lt;eos&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023926</th>\n",
       "      <td>cut it out, christine.</td>\n",
       "      <td>よしなよ クリスチーネ 悪いね</td>\n",
       "      <td>[&lt;sos&gt;, cut, it, out, ,, christine, ., &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, よし, な, よ, クリスチーネ, 悪い, ね, &lt;eos&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561366</th>\n",
       "      <td>because when new cells are formed, these stran...</td>\n",
       "      <td>新しい細胞が作られる際に二本鎖が分離し</td>\n",
       "      <td>[&lt;sos&gt;, because, when, new, cells, are, formed...</td>\n",
       "      <td>[&lt;sos&gt;, 新しい, 細胞, が, 作ら, れる, 際, に, 二, 本, 鎖, が, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520478</th>\n",
       "      <td>how hard do you think</td>\n",
       "      <td>そんな事? 俺が どんな思いして</td>\n",
       "      <td>[&lt;sos&gt;, how, hard, do, you, think, &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, そんな, 事, ?, 俺, が, どんな, 思い, し, て, &lt;eos&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216870</th>\n",
       "      <td>you can't protect your children from the futur...</td>\n",
       "      <td>待ち構えている未来から 子供たちを護ることはできない.</td>\n",
       "      <td>[&lt;sos&gt;, you, ca, n't, protect, your, children,...</td>\n",
       "      <td>[&lt;sos&gt;, 待ち, 構え, て, いる, 未来, から, 子供, たち, を, 護る, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993714</th>\n",
       "      <td>and what does that mean?</td>\n",
       "      <td>何の意味がある?</td>\n",
       "      <td>[&lt;sos&gt;, and, what, does, that, mean, ?, &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, 何, の, 意味, が, ある, ?, &lt;eos&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565027</th>\n",
       "      <td>it's ok.</td>\n",
       "      <td>大丈夫。</td>\n",
       "      <td>[&lt;sos&gt;, it, 's, ok, ., &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, 大丈夫, 。, &lt;eos&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712002</th>\n",
       "      <td>now why did those people kidnap her?</td>\n",
       "      <td>ヤツらが その子を 拉致した理由は?</td>\n",
       "      <td>[&lt;sos&gt;, now, why, did, those, people, kidnap, ...</td>\n",
       "      <td>[&lt;sos&gt;, ヤツ, ら, が, その, 子, を, 拉致, し, た, 理由, は, ?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1680832 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   English  \\\n",
       "938480                                       just because.   \n",
       "2161948     the west had corrupted me with divergent ideas   \n",
       "1639794                                             right?   \n",
       "2023926                             cut it out, christine.   \n",
       "2561366  because when new cells are formed, these stran...   \n",
       "...                                                    ...   \n",
       "1520478                              how hard do you think   \n",
       "2216870  you can't protect your children from the futur...   \n",
       "993714                            and what does that mean?   \n",
       "2565027                                           it's ok.   \n",
       "1712002               now why did those people kidnap her?   \n",
       "\n",
       "                            Japanese  \\\n",
       "938480                        分かったから   \n",
       "2161948           西洋の逸脱した概念が 私を堕落させた   \n",
       "1639794                       ――でしょ?   \n",
       "2023926              よしなよ クリスチーネ 悪いね   \n",
       "2561366          新しい細胞が作られる際に二本鎖が分離し   \n",
       "...                              ...   \n",
       "1520478             そんな事? 俺が どんな思いして   \n",
       "2216870  待ち構えている未来から 子供たちを護ることはできない.   \n",
       "993714                      何の意味がある?   \n",
       "2565027                         大丈夫。   \n",
       "1712002           ヤツらが その子を 拉致した理由は?   \n",
       "\n",
       "                                                 en_tokens  \\\n",
       "938480                    [<sos>, just, because, ., <eos>]   \n",
       "2161948  [<sos>, the, west, had, corrupted, me, with, d...   \n",
       "1639794                           [<sos>, right, ?, <eos>]   \n",
       "2023926      [<sos>, cut, it, out, ,, christine, ., <eos>]   \n",
       "2561366  [<sos>, because, when, new, cells, are, formed...   \n",
       "...                                                    ...   \n",
       "1520478          [<sos>, how, hard, do, you, think, <eos>]   \n",
       "2216870  [<sos>, you, ca, n't, protect, your, children,...   \n",
       "993714      [<sos>, and, what, does, that, mean, ?, <eos>]   \n",
       "2565027                      [<sos>, it, 's, ok, ., <eos>]   \n",
       "1712002  [<sos>, now, why, did, those, people, kidnap, ...   \n",
       "\n",
       "                                                 ja_tokens  \n",
       "938480                          [<sos>, 分かっ, た, から, <eos>]  \n",
       "2161948  [<sos>, 西洋, の, 逸脱, し, た, 概念, が, 私, を, 堕落, さ, せ...  \n",
       "1639794                       [<sos>, ―, ―, でしょ, ?, <eos>]  \n",
       "2023926            [<sos>, よし, な, よ, クリスチーネ, 悪い, ね, <eos>]  \n",
       "2561366  [<sos>, 新しい, 細胞, が, 作ら, れる, 際, に, 二, 本, 鎖, が, ...  \n",
       "...                                                    ...  \n",
       "1520478     [<sos>, そんな, 事, ?, 俺, が, どんな, 思い, し, て, <eos>]  \n",
       "2216870  [<sos>, 待ち, 構え, て, いる, 未来, から, 子供, たち, を, 護る, ...  \n",
       "993714                  [<sos>, 何, の, 意味, が, ある, ?, <eos>]  \n",
       "2565027                             [<sos>, 大丈夫, 。, <eos>]  \n",
       "1712002  [<sos>, ヤツ, ら, が, その, 子, を, 拉致, し, た, 理由, は, ?...  \n",
       "\n",
       "[1680832 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 2\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "special_tokens = [\n",
    "    unk_token,\n",
    "    pad_token,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "]\n",
    "\n",
    "en_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_df[\"en_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")\n",
    "\n",
    "ja_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_df[\"ja_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert en_vocab[unk_token] == ja_vocab[unk_token]\n",
    "assert en_vocab[pad_token] == ja_vocab[pad_token]\n",
    "\n",
    "unk_index = en_vocab[unk_token]\n",
    "pad_index = en_vocab[pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab.set_default_index(unk_index)\n",
    "ja_vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['en_ids'] = train_df[\"en_tokens\"].apply(lambda x: [en_vocab[token] for token in x])\n",
    "train_df['ja_ids'] = train_df[\"ja_tokens\"].apply(lambda x: [ja_vocab[token] for token in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['en_ids'] = val_df[\"en_tokens\"].apply(lambda x: [en_vocab[token] for token in x])\n",
    "val_df['ja_ids'] = val_df[\"ja_tokens\"].apply(lambda x: [ja_vocab[token] for token in x])\n",
    "test_df['en_ids'] = test_df[\"en_tokens\"].apply(lambda x: [en_vocab[token] for token in x])\n",
    "test_df['ja_ids'] = test_df[\"ja_tokens\"].apply(lambda x: [ja_vocab[token] for token in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Japanese</th>\n",
       "      <th>en_tokens</th>\n",
       "      <th>ja_tokens</th>\n",
       "      <th>en_ids</th>\n",
       "      <th>ja_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2595121</th>\n",
       "      <td>if you wanna be in the gang, be cool like daddy!</td>\n",
       "      <td>ギャングなら パパみたいにクールになれ</td>\n",
       "      <td>[&lt;sos&gt;, if, you, wanna, be, in, the, gang, ,, ...</td>\n",
       "      <td>[&lt;sos&gt;, ギャング, なら, パパ, みたい, に, クール, に, なれ, &lt;eos&gt;]</td>\n",
       "      <td>[2, 51, 7, 422, 37, 19, 6, 2400, 5, 37, 599, 4...</td>\n",
       "      <td>[2, 3130, 73, 389, 190, 6, 3782, 6, 780, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721623</th>\n",
       "      <td>you really wanna know?</td>\n",
       "      <td>他の悪魔の仕業か おお 結構</td>\n",
       "      <td>[&lt;sos&gt;, you, really, wanna, know, ?, &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, 他, の, 悪魔, の, 仕業, か, おお, 結構, &lt;eos&gt;]</td>\n",
       "      <td>[2, 7, 97, 422, 45, 9, 3]</td>\n",
       "      <td>[2, 173, 4, 1325, 4, 2967, 18, 1222, 1017, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395742</th>\n",
       "      <td>it was at that time, with an awareness</td>\n",
       "      <td>その当時 バックミンスターの</td>\n",
       "      <td>[&lt;sos&gt;, it, was, at, that, time, ,, with, an, ...</td>\n",
       "      <td>[&lt;sos&gt;, その, 当時, バックミンスター, の, &lt;eos&gt;]</td>\n",
       "      <td>[2, 13, 26, 54, 14, 80, 5, 39, 75, 5357, 3]</td>\n",
       "      <td>[2, 56, 1264, 30037, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894248</th>\n",
       "      <td>i see. weak reaction.</td>\n",
       "      <td>えっ!? 披露宴 中止!? 気づくの 遅いなー。</td>\n",
       "      <td>[&lt;sos&gt;, i, see, ., weak, reaction, ., &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, えっ, !, ?, 披露, 宴, 中止, !, ?, 気づく, の, 遅い,...</td>\n",
       "      <td>[2, 8, 78, 4, 1352, 2383, 4, 3]</td>\n",
       "      <td>[2, 324, 25, 12, 6770, 10221, 2604, 25, 12, 46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712941</th>\n",
       "      <td>you've been thinking of him for a long time.</td>\n",
       "      <td>キサマが 長い間 あの男を 思っていたように➡</td>\n",
       "      <td>[&lt;sos&gt;, you, 've, been, thinking, of, him, for...</td>\n",
       "      <td>[&lt;sos&gt;, キサマ, が, 長い, 間, あの, 男, を, 思っ, て, い, た, ...</td>\n",
       "      <td>[2, 7, 79, 100, 328, 16, 68, 28, 11, 188, 80, ...</td>\n",
       "      <td>[2, 4567, 10, 786, 247, 96, 172, 9, 124, 7, 33...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  English  \\\n",
       "2595121  if you wanna be in the gang, be cool like daddy!   \n",
       "721623                             you really wanna know?   \n",
       "1395742            it was at that time, with an awareness   \n",
       "1894248                             i see. weak reaction.   \n",
       "712941       you've been thinking of him for a long time.   \n",
       "\n",
       "                         Japanese  \\\n",
       "2595121       ギャングなら パパみたいにクールになれ   \n",
       "721623             他の悪魔の仕業か おお 結構   \n",
       "1395742            その当時 バックミンスターの   \n",
       "1894248  えっ!? 披露宴 中止!? 気づくの 遅いなー。   \n",
       "712941    キサマが 長い間 あの男を 思っていたように➡   \n",
       "\n",
       "                                                 en_tokens  \\\n",
       "2595121  [<sos>, if, you, wanna, be, in, the, gang, ,, ...   \n",
       "721623         [<sos>, you, really, wanna, know, ?, <eos>]   \n",
       "1395742  [<sos>, it, was, at, that, time, ,, with, an, ...   \n",
       "1894248       [<sos>, i, see, ., weak, reaction, ., <eos>]   \n",
       "712941   [<sos>, you, 've, been, thinking, of, him, for...   \n",
       "\n",
       "                                                 ja_tokens  \\\n",
       "2595121   [<sos>, ギャング, なら, パパ, みたい, に, クール, に, なれ, <eos>]   \n",
       "721623          [<sos>, 他, の, 悪魔, の, 仕業, か, おお, 結構, <eos>]   \n",
       "1395742                [<sos>, その, 当時, バックミンスター, の, <eos>]   \n",
       "1894248  [<sos>, えっ, !, ?, 披露, 宴, 中止, !, ?, 気づく, の, 遅い,...   \n",
       "712941   [<sos>, キサマ, が, 長い, 間, あの, 男, を, 思っ, て, い, た, ...   \n",
       "\n",
       "                                                    en_ids  \\\n",
       "2595121  [2, 51, 7, 422, 37, 19, 6, 2400, 5, 37, 599, 4...   \n",
       "721623                           [2, 7, 97, 422, 45, 9, 3]   \n",
       "1395742        [2, 13, 26, 54, 14, 80, 5, 39, 75, 5357, 3]   \n",
       "1894248                    [2, 8, 78, 4, 1352, 2383, 4, 3]   \n",
       "712941   [2, 7, 79, 100, 328, 16, 68, 28, 11, 188, 80, ...   \n",
       "\n",
       "                                                    ja_ids  \n",
       "2595121        [2, 3130, 73, 389, 190, 6, 3782, 6, 780, 3]  \n",
       "721623       [2, 173, 4, 1325, 4, 2967, 18, 1222, 1017, 3]  \n",
       "1395742                         [2, 56, 1264, 30037, 4, 3]  \n",
       "1894248  [2, 324, 25, 12, 6770, 10221, 2604, 25, 12, 46...  \n",
       "712941   [2, 4567, 10, 786, 247, 96, 172, 9, 124, 7, 33...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dataset(df, pad_index):\n",
    "    # データをテンソルに変換\n",
    "    en_ids = [torch.LongTensor(ids) for ids in df['en_ids'].tolist()]\n",
    "    ja_ids = [torch.LongTensor(ids) for ids in df['ja_ids'].tolist()]\n",
    "\n",
    "    # pad_indexでパディング\n",
    "    en_ids = pad_sequence(en_ids, batch_first=True, padding_value=pad_index)\n",
    "    ja_ids = pad_sequence(ja_ids, batch_first=True, padding_value=pad_index)\n",
    "\n",
    "    # TensorDatasetを作成\n",
    "    dataset = TensorDataset(en_ids, ja_ids)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_dataset() got an unexpected keyword argument 'max_length'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/lyuzeyu/lyuzeyu/css_nlp/notebook/seq2seq_application.ipynb セル 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blyuzeyu_office/home/lyuzeyu/lyuzeyu/css_nlp/notebook/seq2seq_application.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_data \u001b[39m=\u001b[39m create_dataset(train_df, pad_index,max_length\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blyuzeyu_office/home/lyuzeyu/lyuzeyu/css_nlp/notebook/seq2seq_application.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m val_data \u001b[39m=\u001b[39m create_dataset(val_df, pad_index,max_len\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blyuzeyu_office/home/lyuzeyu/lyuzeyu/css_nlp/notebook/seq2seq_application.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m test_data \u001b[39m=\u001b[39m create_dataset(test_df, pad_index,max_len\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: create_dataset() got an unexpected keyword argument 'max_length'"
     ]
    }
   ],
   "source": [
    "train_data = create_dataset(train_df, pad_index)\n",
    "val_data = create_dataset(val_df, pad_index)\n",
    "test_data = create_dataset(test_df, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  2,  24, 130,  13, 317, 445,   9,   3,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1]),\n",
       " tensor([  2,  37, 131,  19,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        # src = [src length, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded = [src length, batch size, embedding dim]\n",
    "        outputs, hidden = self.rnn(embedded) # no cell state in GRU!\n",
    "        # outputs = [src length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # outputs are always from the top hidden layer\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim + hidden_dim, hidden_dim)\n",
    "        self.fc_out = nn.Linear(embedding_dim + hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, context):\n",
    "        # input = [batch size]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # context = [n layers * n directions, batch size, hidden dim]\n",
    "        # n layers and n directions in the decoder will both always be 1, therefore:\n",
    "        # hidden = [1, batch size, hidden dim]\n",
    "        # context = [1, batch size, hidden dim]\n",
    "        input = input.unsqueeze(0)\n",
    "        #input = [1, batch size]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        #embedded = [1, batch size, embedding dim]\n",
    "        emb_con = torch.cat((embedded, context), dim = 2)\n",
    "        #emb_con = [1, batch size, embedding dim + hidden dim]\n",
    "        output, hidden = self.rnn(emb_con, hidden)\n",
    "        # output = [seq len, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        # output = [1, batch size, hidden dim]\n",
    "        # hidden = [1, batch size, hidden dim]\n",
    "        output = torch.cat((\n",
    "            embedded.squeeze(0), \n",
    "            hidden.squeeze(0), \n",
    "            context.squeeze(0)\n",
    "        ),\n",
    "            dim=1)\n",
    "        # output = [batch size, embedding dim + hidden dim * 2]\n",
    "        prediction = self.fc_out(output)\n",
    "        # prediction = [batch size, output dim]\n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        assert encoder.hidden_dim == decoder.hidden_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio):\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing\n",
    "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        # last hidden state of the encoder is the context\n",
    "        context = self.encoder(src)\n",
    "        # context = [n layers * n directions, batch size, hidden dim]\n",
    "        # context also used as the initial hidden state of the decoder\n",
    "        hidden = context\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        for t in range(1, trg_length):\n",
    "            # insert input token embedding, previous hidden state and the context state\n",
    "            # receive output tensor (predictions) and new hidden state\n",
    "            output, hidden = self.decoder(input, hidden, context)\n",
    "            # output = [batch size, output dim]\n",
    "            # hidden = [1, batch size, hidden dim]\n",
    "            # place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            # get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            # input = [batch size]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(ja_vocab)\n",
    "output_dim = len(en_vocab)\n",
    "encoder_embedding_dim = 256\n",
    "decoder_embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    encoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    encoder_dropout,\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    decoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    decoder_dropout,\n",
    ")\n",
    "\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(75174, 256)\n",
       "    (rnn): GRU(256, 512)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(67254, 256)\n",
       "    (rnn): GRU(768, 512)\n",
       "    (fc_out): Linear(in_features=1280, out_features=67254, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        src = batch[\"de_ids\"].to(device)\n",
    "        trg = batch[\"en_ids\"].to(device)\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg, teacher_forcing_ratio)\n",
    "        # output = [trg length, batch size, trg vocab size]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "        trg = trg[1:].view(-1)\n",
    "        # trg = [(trg length - 1) * batch size]\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            src = batch[\"de_ids\"].to(device)\n",
    "            trg = batch[\"en_ids\"].to(device)\n",
    "            # src = [src length, batch size]\n",
    "            # trg = [trg length, batch size]\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "            # output = [trg length, batch size, trg vocab size]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "            trg = trg[1:].view(-1)\n",
    "            # trg = [(trg length - 1) * batch size]\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "clip = 1.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "        \n",
    "    train_loss = train_fn(\n",
    "        model, \n",
    "        train_loader, \n",
    "        optimizer, \n",
    "        criterion, \n",
    "        clip, \n",
    "        teacher_forcing_ratio, \n",
    "        device,\n",
    "    )\n",
    "    \n",
    "    valid_loss = evaluate_fn(\n",
    "        model, \n",
    "        valid_data_loader, \n",
    "        criterion, \n",
    "        device,\n",
    "    )\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"tut2-model.pt\")\n",
    "    \n",
    "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
