{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然言語処理の基礎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コーパス \n",
    "\n",
    "### コーパスとは\n",
    "\n",
    "「コーパス（Corpus）」とは、ひとことで言うと言語データの集まりのです。\n",
    "\n",
    "コーパスが大きく「ラベル付きコーパス」と「ラベルなしコーパス」に分けられます。\n",
    "\n",
    "- ラベルなしコーパス: 注釈付けを行わずにテキストを集めただけのコーパス。例えば、スクリーンスクレイピングによる取得するウェブベージの生テキストデータ。\n",
    "- ラベル付きコーパス: ラベル付きコーパスとは、テキストに付加情報（ラベルや注釈）が付与されているコーパスのことを指します。このラベルは、特定のタスクや研究の目的に応じてデータに追加されます。\n",
    "    - <u>**品詞**</u>タグ付きコーパス: 各単語に品詞（名詞、動詞、形容詞など, part of speech）のタグが付けられています。これは、文法的構造の理解や、品詞タガーの訓練データとして使用されます。\n",
    "    - 固有名詞抽出のためのコーパス: テキスト内の固有名詞（人名、地名、組織名など）に対して、該当するラベルが付けられています。\n",
    "\n",
    "```\n",
    "<sentence>\n",
    "　<LUW B=\"B\" SL=\"v\" l_lemma=\"公共工事請け負い金額\" l_lForm=\"コウキョウコウジウケオイキンガク\" l_wType=\"混\" l_pos=\"名詞-普通名詞-一般\" >\n",
    "　　<SUW lemma=\"公共\" lForm=\"コウキョウ\" wType=\"漢\" pos=\"名詞-普通名詞-一般\" pron=\"コーキョー\">\n",
    "　　　公共\n",
    "　　</SUW>\n",
    "　　<SUW lemma=\"工事\" lForm=\"コウジ\" wType=\"漢\" pos=\"名詞-普通名詞-サ変可能\" pron=\"コージ\">\n",
    "　　　工事\n",
    "　　</SUW>\n",
    "　　<SUW lemma=\"請け負い\" lForm=\"ウケオイ\" wType=\"和\" pos=\"名詞-普通名詞-一般\" pron=\"ウケオイ\">\n",
    "　　　請負\n",
    "　　</SUW>\n",
    "　　<SUW lemma=\"金額\" lForm=\"キンガク\" wType=\"漢\" pos=\"名詞-普通名詞-一般\" pron=\"キンガク\">\n",
    "　　　金額\n",
    "　　</SUW>\n",
    "　</LUW>\n",
    "　<LUW SL=\"v\" l_lemma=\"の\" l_lForm=\"ノ\" l_wType=\"和\" l_pos=\"助詞-格助詞\" >\n",
    "　　<SUW lemma=\"の\" lForm=\"ノ\" wType=\"和\" pos=\"助詞-格助詞\" pron=\"ノ\">の</SUW>\n",
    "　</LUW>\n",
    "　<LUW B=\"B\" SL=\"v\" l_lemma=\"動き\" l_lForm=\"ウゴキ\" l_wType=\"和\" l_pos=\"名詞-普通名詞-一般\" >\n",
    "　　<SUW lemma=\"動き\" lForm=\"ウゴキ\" wType=\"和\" pos=\"名詞-普通名詞-一般\" pron=\"ウゴキ\">\n",
    "　　　動き\n",
    "　　</SUW>\n",
    "　</LUW>\n",
    "（略）\n",
    "</sentence>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コーパスの読み込み\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多くのコーパスは、*txt*,*csv*,*tsv*, *json*フォーマットで格納されていますので、pythonでこれらのファイルを読み込む方法について紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ファイル読み込みの基礎\n",
    "\n",
    "読み込み・書き込みいずれの場合も組み込み関数```open()```でファイルを開きます。\n",
    "- 第一引数に指定したパスからコーパスファイルが開かれます。\n",
    "- 引数```mode```を```r```とすると読み込みモードでファイルが開かれます。デフォルト値は```r```なので省略してもよい。\n",
    "- テキストファイル読み込み時のデコード、書き込み時のエンコードで使われるエンコーディングは引数```encoding```で指定する。日本語環境で使われるものとしては```cp932```, ```euc_jp```, ```shift_jis```, ```utf_8```などがあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "この商品はとても素晴らしい。\n",
      "残念ながら、私の期待を下回る製品でした。\n",
      "非常に使いやすく、価格も手頃。おすすめです！\n",
      "この商品には全く魅力を感じませんでした。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"./Data/corpus.txt\",mode=\"r\",encoding=\"utf-8\") as f:\n",
    "    s = f.read()\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```readlines()```メソッドで、ファイル全体を行ごとに分割したリストとして取得できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "この商品はとても素晴らしい。\n",
      "\n",
      "-----------\n",
      "残念ながら、私の期待を下回る製品でした。\n",
      "\n",
      "-----------\n",
      "非常に使いやすく、価格も手頃。おすすめです！\n",
      "\n",
      "-----------\n",
      "この商品には全く魅力を感じませんでした。\n",
      "\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "with open(\"./Data/corpus.txt\",mode=\"r\",encoding=\"utf-8\") as f:\n",
    "    s = f.readlines()\n",
    "    for i in s:\n",
    "        print(i)\n",
    "        print(\"-----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### csvファイルとtsvファイルの読み込み\n",
    "\n",
    "csvは、値がカンマで区切られたファイル形式です。\n",
    "\n",
    "tsvは、値がタブで区切られたファイル形式です。\n",
    "\n",
    "ファイルの読み込みは、```Pandas```を使って行うことがでします。\n",
    "\n",
    "```\n",
    "pd.read_csv(\"example.csv\", encoding =\"uft-8\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### jsonファイルの読み込み\n",
    "\n",
    "<u>**JSONは、構造化されたデータをテキスト形式で表現するためのフォーマットです。**</u>\n",
    "\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"Taro Yamada\",\n",
    "        \"age\": 25,\n",
    "        \"city\": \"Tokyo\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"name\": \"Hanako Tanaka\",\n",
    "        \"age\": 30,\n",
    "        \"city\": \"Osaka\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"name\": \"Jiro Suzuki\",\n",
    "        \"age\": 35,\n",
    "        \"city\": \"Kyoto\"\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "```Pandas```の```read_json```メソッドを使って読み込めます。\n",
    "\n",
    "特に、改行で区切られたJSONファイルはjsonlで呼ばれます。\n",
    "\n",
    "```\n",
    "{\"id\": 1, \"name\": \"Taro Yamada\", \"age\": 25, \"city\": \"Tokyo\"}\n",
    "{\"id\": 2, \"name\": \"Hanako Tanaka\", \"age\": 30, \"city\": \"Osaka\"}\n",
    "{\"id\": 3, \"name\": \"Jiro Suzuki\", \"age\": 35, \"city\": \"Kyoto\"}\n",
    "```\n",
    "\n",
    "jsonl形式のファイルを読み込むには、```read_json```メソッドの```lines```引数に```lines=True```を設定する必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テキストの前処理\n",
    "\n",
    "### 正規表現によるノイズの除去\n",
    "\n",
    "テキスト分析における、テキストから不要な情報やノイズを取り除き、解析や処理を行いやすくするための前処理が不可欠になります。\n",
    "\n",
    "テキストクリーニングを行う際に、**<u>正規表現**</u>を利用すると非常に柔軟にノイズの除去が可能です。以下、いくつかの一般的なケースを例に、テキストからノイズを除去する方法を紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "正規表現とは、文字列内で文字の組み合わせを照合するために用いられるパターンです。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`re.sub`は、正規表現にマッチした文字列を別の文字列に置換するための関数です。対象となる文字列の中で正規表現パターンにマッチする部分を、置換後の文字列に置換します。\n",
    "\n",
    "第1引数には正規表現パターン、第2引数には置換後の文字列、第3引数には対象となる文字列を指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "この記事は に投稿されました。\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#ウェブページやSNSのテキストからURLを取り除く場合:\n",
    "text = \"この記事はhttp://example.com に投稿されました。\"\n",
    "cleaned_text = re.sub(r'http\\S+', '', text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "`http` から始まり、その後に1つ以上の非空白文字 (`\\S+`) が続く文字列にマッチする正規表現パターン `r'http\\S+'` を指定しています。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今日は年月日です。\n"
     ]
    }
   ],
   "source": [
    "# HTMLタグの除去: HTMLコンテンツからタグを取り除く場合:\n",
    "text = \"今日は2023年9月16日です。\"\n",
    "cleaned_text = re.sub(r'\\d', '', text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "`\\d` は、0から9までの数字にマッチする特殊文字です。この正規表現パターンにマッチする部分は、空文字列 `''` に置換されます。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "これはテストです。\n"
     ]
    }
   ],
   "source": [
    "#テキストからアルファベットのみを取り除く場合:\n",
    "text = \"これはテストtextです。\"\n",
    "cleaned_text = re.sub(r'[a-zA-Z]', '', text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "`[a-zA-Z]` は、英字の大文字と小文字にマッチする文字クラスです。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トークン化\n",
    "\n",
    "トークン化は、文字列をモデルで使用される最小単位に分解するステップです。トークンは通常、言語の基本的な構成要素である単語や部分文字列を指します。\n",
    "\n",
    "日本語は英語などとは異なり、単語の間に（スペースなどの）区切りをつけないので、文から単語を取り出すこと自体が一つのタスクとなります。文から単語（正確には形態素と呼ばれる意味の最小単位）を取り出す解析を形態素解析といいます。\n",
    "\n",
    "\n",
    "イメージとしては以下のように分割します。\n",
    "\n",
    "- 分かち書き（文章を形態素で分ける）\n",
    "- 品詞わけ（名詞や動詞などに分類する）\n",
    "- 原型付与（単語の基本形をだす） 例：食べた ⇒ 食べる、た\n",
    "\n",
    "![](./Figure/token.png)\n",
    "\n",
    "\n",
    "日本語の形態素解析ツールとしては、MeCabやJUMAN++、Janomeなどが挙げられます。ここでは、MeCabを使って形態素解析をしてみましょう。\n",
    "\n",
    "初めてMeCabを使う場合、```!```が付いたコードをJupyter Notebookで実行するか、```!```を除去したコードをターミナルで実行し、MeCabを導入してください。\n",
    "\n",
    "```\n",
    "!pip install mecab-python3 # mecab-python3のインストール\n",
    "!pip install unidic\n",
    "!python -m unidic download # 辞書のダウンロード\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果を確認すると、単語に分割しただけでなく、品詞などの情報も得られました。\n",
    "\n",
    "ただ、デフォルトの設定では新語に対する解析は強くないことがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'MeCab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb セル 22\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# !pip install mecab-python3 # mecab-python3のインストール\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# !pip install unidic\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# !python -m unidic download # 辞書のダウンロード\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mMeCab\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39munidic\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m tagger \u001b[39m=\u001b[39m MeCab\u001b[39m.\u001b[39mTagger() \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'MeCab'"
     ]
    }
   ],
   "source": [
    "# !pip install mecab-python3 # mecab-python3のインストール\n",
    "# !pip install unidic\n",
    "# !python -m unidic download # 辞書のダウンロード\n",
    "import MeCab\n",
    "import unidic\n",
    "tagger = MeCab.Tagger() \n",
    "print(tagger.parse(\"友たちと国立新美術館に行った。\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この問題は形態素解析器に辞書を追加することである程度解決することが出来ます。特に、*NEologd*という辞書には、通常の辞書と比べて多くの新語が含まれています。\n",
    "\n",
    "*NEologd*のインストールについては、以下のベージに参照してください。\n",
    "- [Windows](https://resanaplaza.com/2022/05/08/%E3%80%90%E8%B6%85%E7%B5%B6%E7%B0%A1%E5%8D%98%E3%80%91windows-%E3%81%AEpython%EF%BC%8Bmecab%E3%81%A7%E3%83%A6%E3%83%BC%E3%82%B6%E3%83%BC%E8%BE%9E%E6%9B%B8%E3%81%ABneologd%E3%82%92%E4%BD%BF%E3%81%86/)\n",
    "- [Mac](https://qiita.com/berry-clione/items/b3a537962c84244a2a09)\n",
    "\n",
    "辞書を指定して、タガーを生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MeCab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb セル 24\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sample_txt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m友たちと国立新美術館に行った。\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-d /opt/homebrew/lib/mecab/dic/mecab-ipadic-neologd\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m m \u001b[39m=\u001b[39m MeCab\u001b[39m.\u001b[39mTagger(path)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMecab ipadic NEologd:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,m\u001b[39m.\u001b[39mparse(sample_txt))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MeCab' is not defined"
     ]
    }
   ],
   "source": [
    "sample_txt = \"友たちと国立新美術館に行った。\"\n",
    "path = \"-d /opt/homebrew/lib/mecab/dic/mecab-ipadic-neologd\"\n",
    "m = MeCab.Tagger(path)\n",
    "print(\"Mecab ipadic NEologd:\\n\",m.parse(sample_txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "*NEologd*のインストールについては、以下のベージに参照してください。\n",
    "- [Windows](https://resanaplaza.com/2022/05/08/%E3%80%90%E8%B6%85%E7%B5%B6%E7%B0%A1%E5%8D%98%E3%80%91windows-%E3%81%AEpython%EF%BC%8Bmecab%E3%81%A7%E3%83%A6%E3%83%BC%E3%82%B6%E3%83%BC%E8%BE%9E%E6%9B%B8%E3%81%ABneologd%E3%82%92%E4%BD%BF%E3%81%86/)\n",
    "- [Mac]()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上の例から分かるように、NEologdは「国立新美術館」のような固有表現にも対応し、ソーシャルメディアのテキストなど新語が多数含まれている場合こちらの方が適切です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parseToNode()メソッドは、形態素（ノード）ごとに出力をしていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb セル 28\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m n\u001b[39m=\u001b[39mm\u001b[39m.\u001b[39mparseToNode(sample_txt)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "n=m.parseToNode(sample_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最初は、BOS/EOS(文頭／文末)を示す符号となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb セル 30\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m n\u001b[39m.\u001b[39mfeature\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "n.feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```.next```で次のノードに進みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb セル 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m n \u001b[39m=\u001b[39m n\u001b[39m.\u001b[39mnext\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "n = n.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb セル 33\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m n\u001b[39m.\u001b[39mfeature\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "n.feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ところでfeatureは形態素の特徴を表す要素を格納しています。\n",
    "  - $0$番目が品詞、$6$番目が基本形であり、今回はこの2つを用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb セル 35\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m品詞: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mn\u001b[39m.\u001b[39mfeature\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X50sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m基本形: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mn\u001b[39m.\u001b[39mfeature\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m6\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"品詞: \"+n.feature.split(',')[0])\n",
    "print(\"基本形: \"+n.feature.split(',')[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文章を解析するためには、whileループを使います。その際、品詞を指定して特定の品詞の基本形だけを取り出すなどという操作が可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb セル 37\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m n\u001b[39m=\u001b[39mm\u001b[39m.\u001b[39mparseToNode(sample_txt)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X52sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwhile\u001b[39;00m n:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ryotakusakai/css_nlp/notebook/nlp_basis.ipynb#X52sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   \u001b[39mif\u001b[39;00m n\u001b[39m.\u001b[39mfeature\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39m名詞\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m形容詞\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m動詞\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "n=m.parseToNode(sample_txt)\n",
    "while n:\n",
    "  if n.feature.split(',')[0] in [\"名詞\",\"形容詞\",\"動詞\"]:\n",
    "    print(n.feature.split(',')[6])\n",
    "  n = n.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ストップワードの除去"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ストップワードとは、助詞など単独で用いられなかったり、一般的に使用されすぎていて文の意味の分析に寄与しない、あるいや逆に使用頻度が少ないため、含めると分析結果が歪んでしまうなどの理由で分析からあらかじめ除外しておく語のことをいいます。\n",
    "\n",
    "一般的には、あらかじめストップワードを辞書に定義しておき、辞書内に含まれる単語をテキスとから除外します。\n",
    "\n",
    "一般的な用語のストップリストは例えばSlothLibプロジェクトから取得することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "slothlib_path = 'http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt'\n",
    "slothlib_file = urllib.request.urlopen(slothlib_path)\n",
    "slothlib_stopwords = [line.decode(\"utf-8\").strip() for line in slothlib_file]\n",
    "slothlib_stopwords = [ss for ss in slothlib_stopwords if not ss==u'']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単語のID化\n",
    "\n",
    "```{margin} \n",
    "先取りですが、ここからは機械学習・深層学習の適用するための前処理について解説します。\n",
    "```\n",
    "\n",
    "ほとんどの機械学習・深層学習モデルは数値データを入力として受け取りますので、テキストデータを数値形式に変換する必要があります。\n",
    "\n",
    "単語のID化とは、テキストデータを機械学習モデルなどで処理する際に、単語を一意の整数値（ID）に変換するプロセスを指します。これは、テキストデータをベクトルや行列の形でモデルに入力するための前処理として行われます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パディング\n",
    "\n",
    "パディング(Padding)とは、データの一定の長さや形状を持つように調整するためのテクニックです。\n",
    "\n",
    "多くの機械学習・深層学習モデルでは、固定サイズの入力を要求しています。しかし、異なる文書や文はさまざまな長さを持っていますので、テキストデータは可変長である場合が多いです。したがって、すべての文書や文を同じ長さにするためにパディングを使用します。主な手順としては、\n",
    "\n",
    "- 最大長を決定\n",
    "- 最大長に達するまで、各文の末尾または先頭に特定の「パッドトークン」を追加します。パディングに使用するトークンは、モデルが誤って意味を学習しないように、他の実際の単語やトークンとは異なるものである必要があります。\n",
    "- 長すぎる文は、最大長に合わせるために切り捨て\n",
    "\n",
    "![](./Figure/attention_id.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
