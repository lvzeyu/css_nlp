<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>ガイダンス - 計算社会科学と自然言語処理</title><meta property="og:title" content="ガイダンス - 計算社会科学と自然言語処理"/><meta name="generator" content="mystmd"/><meta name="description" content="このページで、行動科学演習(LB63310)と計算人文社会学研究演習Ⅱ (LM23309)の授業資料を公開しています。"/><meta property="og:description" content="このページで、行動科学演習(LB63310)と計算人文社会学研究演習Ⅱ (LM23309)の授業資料を公開しています。"/><meta name="keywords" content=""/><meta name="image" content="/build/NLP_history-80702ee1d37040856a480174f5bcbbfc.png"/><meta property="og:image" content="/build/NLP_history-80702ee1d37040856a480174f5bcbbfc.png"/><link rel="stylesheet" href="/build/_assets/app-AIT5GAEP.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-85RFPTYEE3"></script><script>window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-85RFPTYEE3');</script><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="myst-skip-to-article fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="myst-skip-to-link block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="myst-skip-to-link block px-2 py-1 text-black underline">Skip to article content</a></div><dialog id="myst-no-css" style="position:fixed;left:0px;top:0px;width:100vw;height:100vh;font-size:4rem;padding:1rem;color:black;background:white"><strong>Site not loading correctly?</strong><p>This may be due to an incorrect <code>BASE_URL</code> configuration. See<!-- --> <a href="https://mystmd.org/guide/deployment#deploy-base-url">the MyST Documentation</a> <!-- -->for reference.</p><script>
    (() => {
            // Test for has-styling variable set by the MyST stylesheet
            const node = document.currentScript.parentNode;
            const hasCSS = window.getComputedStyle(node).getPropertyValue("--has-styling");
            if (hasCSS === ""){
                    node.showModal();
            }

    })()
</script></dialog><div class="myst-top-nav bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="myst-top-nav-bar flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="myst-top-nav-menu-button flex items-center justify-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100 w-10 h-10"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="myst-home-link flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><div class="myst-home-link-logo mr-3 flex items-center dark:bg-white dark:rounded px-1"><img src="/build/tohoku-university-lo-68dede7d9dcb965aff25e8429e755296.svg" class="h-9" height="2.25rem"/></div><span class="text-md sm:text-xl tracking-tight sm:mr-5 sr-only">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R75cp:" data-state="closed" class="myst-search-bar flex items-center h-10 aspect-square sm:w-64 text-left text-gray-600 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 myst-search-bar-disabled hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="myst-search-text-placeholder hidden sm:block grow">Search</span><div aria-hidden="true" class="myst-search-shortcut items-center hidden mx-1 font-mono text-sm text-gray-600 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="myst-theme-button theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-10 h-10 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="myst-theme-moon-icon h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="myst-theme-sun-icon h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="myst-primary-sidebar fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="myst-primary-sidebar-pointer pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="myst-primary-sidebar-nav flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="myst-primary-sidebar-topnav overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="myst-primary-sidebar-toc flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="myst-toc w-full px-1 dark:text-white"><a title="計算社会科学と自然言語処理" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/">計算社会科学と自然言語処理</a><div data-state="open" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="イントロダクション" class="block break-words rounded py-2 grow font-semibold text-blue-800 dark:text-blue-200 cursor-pointer">イントロダクション</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rmpsp:" aria-expanded="true" data-state="open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="open" id="radix-:Rmpsp:" class="pl-3 pr-[2px] collapsible-content"><a title="ガイダンス" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg myst-toc-item-exact bg-blue-300/30 active" href="/introduction">ガイダンス</a></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="基礎知識" class="block break-words rounded py-2 grow cursor-pointer">基礎知識</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rupsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rupsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="ニューラルネットワーク" class="block break-words rounded py-2 grow cursor-pointer">ニューラルネットワーク</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R16psp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R16psp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="PyTorch" class="block break-words rounded py-2 grow cursor-pointer">PyTorch</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1epsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1epsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="単語分散表現" class="block break-words rounded py-2 grow cursor-pointer">単語分散表現</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1mpsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1mpsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="RNN" class="block break-words rounded py-2 grow cursor-pointer">RNN</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1upsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1upsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="Transformer" class="block break-words rounded py-2 grow cursor-pointer">Transformer</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R26psp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R26psp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="大規模言語モデル" class="block break-words rounded py-2 grow cursor-pointer">大規模言語モデル</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2epsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2epsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div></div></nav></div><div class="myst-primary-sidebar-footer flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="myst-made-with-myst flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><main class="article-grid grid-gap"><article class="article-grid subgrid-gap col-screen article content"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="myst-fm-block mb-8 pt-9"><div class="myst-fm-block-header flex items-center mb-5 h-6 text-sm font-light"><div class="flex-grow"></div><div class="myst-fm-block-badges"><a href="https://github.com/lvzeyu/css_nlp" title="GitHub Repository: lvzeyu/css_nlp" target="_blank" rel="noopener noreferrer" class="myst-fm-github-link text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="myst-fm-github-icon inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a></div><a href="https://github.com/lvzeyu/css_nlp/edit/master/notebook/introduction.ipynb" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="myst-fm-edit-link text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="myst-fm-edit-icon inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="myst-fm-downloads-dropdown relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="myst-fm-downloads-button relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8ucp:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="myst-fm-downloads-icon"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="myst-fm-block-title mb-0">ガイダンス</h1><header class="myst-fm-authors-affiliations mt-4 not-prose"><div class="myst-fm-authors-grid grid grid-cols-1 sm:grid-cols-2 gap-y-1"><div class="myst-fm-author-col"><span class="myst-fm-author font-semibold text-sm"><button class="myst-fm-author-popover focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R2t8ucp:" data-state="closed"><span class="myst-fm-author-name">呂沢宇　ZEYU LYU</span></button><a class="myst-fm-author-icon-link ml-1" href="mailto:lyu.zeyu.e8@tohoku.ac.jp" title="呂沢宇　ZEYU LYU &lt;lyu.zeyu.e8@tohoku.ac.jp&gt;" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1rem" height="1rem" class="myst-fm-author-icon inline-block text-gray-400 -translate-y-[0.1em] myst-fm-author-icon-email hover:text-blue-400"><path d="M21.8 18c0 1.1-.9 2-1.9 2H4.2c-1.1 0-1.9-.9-1.9-2V9.9c0-.5.3-.7.8-.4l7.8 4.7c.7.4 1.7.4 2.4 0L21 9.5c.4-.2.8-.1.8.4V18z"></path><path d="M21.8 6c0-1.1-.9-2-1.9-2H4.2c-1.1 0-2 .9-2 2v.4c0 .5.3 1.1.8 1.3l8.5 5.1c.2.1.7.1.9 0l8.6-5c.4-.3.8-.9.8-1.3-.1-.1-.1-.5 0-.5z"></path></svg></a></span></div><div class="myst-fm-affiliation-col text-sm"><div class="myst-fm-affiliation-item">東北大学　計算人文社会学<!-- --> </div></div></div></header></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="vOP45qEoXk" class="myst-jp-nb-block relative group/block"><h2 id="id" class="relative group"><span class="mr-3 select-none">1</span><span class="heading-text">自然言語処理</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#id" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>自然言語処理（NLP: Natural Language Processing）は、人間が日常的に使っている自然言語をコンピュータに処理させる一連の技術であり、人工知能（AI）の研究分野で中核を成す要素技術の一つといえます。</p><p>私たちは普段、自分たちの言語の複雑さについて考えることはありません。人間にとっては、言語は歩くのと同じように、訓練された反復可能な行動であるため、習得しやすく、青年期にはより自然に使用できるようになると言われています。ただ、人間にとって自然なことでも、大量の非構造化データを処理し、正式なルールがないばかりか、現実世界のコンテキストや意図もないコンピューターにとっては、それを成すことは非常に困難です。</p></div><div id="kxED3nF5Ts" class="myst-jp-nb-block relative group/block"><details class="myst-admonition myst-admonition-note my-5 shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-gray-50/10 dark:bg-stone-800 overflow-hidden myst-admonition-default rounded border-l-4 border-blue-500 dropdown tohokupurple"><summary class="myst-admonition-header m-0 font-medium py-1 flex min-w-0 text-lg text-blue-600 bg-blue-50 dark:bg-slate-900 cursor-pointer hover:shadow-[inset_0_0_0px_30px_#00000003] dark:hover:shadow-[inset_0_0_0px_30px_#FFFFFF03]"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="myst-admonition-header-icon inline-block pl-2 mr-2 self-center flex-none text-blue-600"><path stroke-linecap="round" stroke-linejoin="round" d="m11.25 11.25.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0 9 9 0 0 1 18 0Zm-9-3.75h.008v.008H12V8.25Z"></path></svg><div class="myst-admonition-header-text text-neutral-900 dark:text-white grow self-center overflow-hidden break-words">なぜ自然言語処理は難しいのか</div><div class="self-center flex-none text-sm font-thin text-neutral-700 dark:text-neutral-200"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="myst-admonition-header-icon inline-block pl-2 mr-2 self-center flex-none transition-transform details-toggle"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></div></summary><div class="myst-admonition-body px-4 py-1 details-body"><p>私たちは普段、自分たちの言語の複雑さについて考えることはありません。人間にとっては、言語は歩くのと同じように、訓練された反復可能な行動であるため、習得しやすく、青年期にはより自然に使用できるようになると言われています。ただ、人間にとって自然なことでも、大量の非構造化データを処理し、正式なルールがないばかりか、現実世界のコンテキストや意図もないコンピューターにとっては、それを成すことは非常に困難です。</p></div></details></div><div id="YL13fI1VCI" class="myst-jp-nb-block relative group/block"><p>近年、自然言語処理技術の急速な進歩に驚きの声が上がっていました。</p><p>実際、自然言語処理において昨今の支配的な手法は、隠れマルコフモデル(HMM)、線型サポートベクトルマシン(SVM)やロジスティック回帰など統計的機械学習(statistical machine learning)に基づいていました。</p><p>2014年頃、この分野において、<a href="https://ja.wikipedia.org/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" class="italic" target="_blank" rel="noreferrer" data-state="closed">ニューラルネットワーク</a>という技術が導入され、多くのタスクにより高い性能を達成できました。さらに、これに基づいて、より先進的なモデリング方法の開発も進めました。特に、<a href="https://ja.wikipedia.org/wiki/%E5%9B%9E%E5%B8%B0%E5%9E%8B%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" class="italic" target="_blank" rel="noreferrer" data-state="closed">再帰的ニューラルネットワーク(RNN)</a>に基づく方法は言語の時系列性質も学習できるになって、様々なタスクにおいて精度向上に大きく貢献しました。</p><p>2018年にGoogleが発表した<a href="https://ja.wikipedia.org/wiki/BERT_(%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB)" class="italic" target="_blank" rel="noreferrer" data-state="closed">BERT</a>というモデルでは、大規模なテキストで一般的な言語パターンや文脈を学習します。その後、この事前学習済みモデルを特定のNLPタスクに<a href="https://ja.wikipedia.org/wiki/%E3%83%95%E3%82%A1%E3%82%A4%E3%83%B3%E3%83%81%E3%83%A5%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0_(%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92)" class="italic" target="_blank" rel="noreferrer" data-state="closed">ファインチューニング</a>することで、少ないラベル付きデータで高性能を発揮することができます。</p><p>それだけでも驚きでしたが、一般人の中でも話題になる「ChatGPT」をはじめとする生成AIの<a href="https://ja.wikipedia.org/wiki/%E5%A4%A7%E8%A6%8F%E6%A8%A1%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB" class="italic" target="_blank" rel="noreferrer" data-state="closed">大規模な言語モデル(LLM:Large Language Model)</a>の進展により、質問への回答、文章の要約や翻訳、ソフトウエアのプログラミングなど、言語に関わるさまざまなタスクができるようになりました。</p><p>高機能化のカギは、<a href="https://ja.wikipedia.org/wiki/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0" class="italic" target="_blank" rel="noreferrer" data-state="closed">深層学習</a>技術の発展があります。深層学習を用いた自然言語処理には、あらかじめ用意した膨大な文章を使って、<a href="https://ja.wikipedia.org/wiki/%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB" class="italic" target="_blank" rel="noreferrer" data-state="closed">「言語モデル」</a>と呼ばれるシステムを学習させる方法があります。
言語モデルの実体は簡単な計算式を大量に組み合わせた超巨大な数式といえます。最先端の言語モデルでは、想像を絶するほど大量の文章を使い、パラメータ（数式の係数）が数千億に達するほどの大規模な言語モデルを学習させて使っています。LLMが人間に匹敵するほどの高度な能力を持つ、文章の作成や会話を利用するさまざまな仕事を、コンピュータに任せることが可能になってきました。</p></div><div id="agKl94eAb6" class="myst-jp-nb-block relative group/block"><figure id="WY9UWE6IOH" class="fig-figure"><img id="RcPAtZGKR3" style="margin-left:auto;margin-right:auto" src="/build/NLP_history-80702ee1d37040856a480174f5bcbbfc.png" alt="Sunset at the beach" data-canonical-url="./Figure/NLP_history.png" class=""/><figcaption class="group"><p>自然言語処理の歴史</p></figcaption></figure></div><div id="bqdqVQpHTP" class="myst-jp-nb-block relative group/block"><h2 id="id-1" class="relative group"><span class="mr-3 select-none">2</span><span class="heading-text">計算社会科学において自然言語処理の応用</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#id-1" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>人間の社会行動に関するデジタル化された高密度・大容量のデータの蓄積を背景に、近年、計算社会科学と呼ばれる新たな学問領域が勃興し、急速な発展を遂げています<span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://doi.org/10.1126/science.1167742" target="_blank" rel="noreferrer" class="hover-link">Lazer <em>et al.</em>, 2009</a></cite><cite class="" data-state="closed"><a href="https://doi.org/10.1038/s41586-021-03659-0" target="_blank" rel="noreferrer" class="hover-link">Hofman, 2021</a></cite></span>。</p><p>計算社会科学において，テキストデータの収集・分析は広く用いられている研究手法です。ここで、自然言語処理技術の発展が計算社会科学にす新たな可能性をもたらせます。</p><p>本講義の目的は、<span style="text-decoration:underline"><strong>計算社会科学に多く応用された自然言語処理技術を理解し、実問題に適用するための基礎力を身につけることです。</strong></span></p><p>その目的を達成するために、<span style="text-decoration:underline"><strong>自然言語処理と深層学習の基礎、重要な概念と主な手法(モデル)</strong></span>を学習する。さらに、Python用いて、自然言語処理によく用いられるライブラリとツールを学習しつつ、<span style="text-decoration:underline"><strong>自然言語処理技術を応用するスキル</strong></span>を修得する。</p></div><div id="iRtTBN5LiX" class="myst-jp-nb-block relative group/block"><h3 id="id-2" class="relative group"><span class="mr-3 select-none">2.1</span><span class="heading-text">単語分散表現</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#id-2" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p><a href="https://ja.wikipedia.org/wiki/%E5%8D%98%E8%AA%9E%E3%81%AE%E5%9F%8B%E3%82%81%E8%BE%BC%E3%81%BF" class="italic" target="_blank" rel="noreferrer" data-state="closed">単語分散表現</a>とは、「文字・単語をベクトル空間に埋め込み、その空間上のひとつの点として捉える」ことを指します。</p><ul><li><p>類似性: ある概念を表現する際に、ほかの概念との共通点や類似性と紐づけながら、ベクトル空間上に表現します。</p></li><li><p>単語類推: 分散表現では異なる概念を表現するベクトル同士での計算が可能です</p></li></ul></div><div id="MnOpbAihfM" class="myst-jp-nb-block relative group/block"><figure id="HZBTbeT6i3" class="fig-figure"><img id="NSsQD2llW8" style="margin-left:auto;margin-right:auto" src="/build/word2vec-e9464d85d29ea83b24cfeb53aedc1339.png" alt="Sunset at the beach" data-canonical-url="./Figure/word2vec.png" class=""/><figcaption class="group"><p>単語分散表現のイメージ</p></figcaption></figure></div><div id="nW8eumsAp5" class="myst-jp-nb-block relative group/block"><ul><li><p>1910年代からのテキストデータで単語分散表現を学習し、単語分散表現で男性と女性はそれぞれどのような単語と関連していることを検証することで、ジェンダーのステレオタイプの実態と変化を定量的に分析する <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://doi.org/10.1073/pnas.1720347115" target="_blank" rel="noreferrer" class="hover-link">Garg <em>et al.</em>, 2018</a></cite></span></p></li></ul><img id="KxWeD7yuup" style="margin-left:auto;margin-right:auto" src="/build/word2vec_gender-c3f35f5223c49f64de120ebbd85a7c56.jpeg" data-canonical-url="./Figure/word2vec_gender.jpeg" class=""/><ul><li><p>単語分散表現の類似性と単語類推特性で、単語分散表現の計算を通じて、文化概念の潜在的意味と関係を定量的に測定できました<span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://doi.org/10.1177/0003122419877135" target="_blank" rel="noreferrer" class="hover-link">Kozlowski <em>et al.</em>, 2019</a></cite></span></p></li></ul><img id="hBicxdMDri" style="margin-left:auto;margin-right:auto" src="/build/city-e6c77b7ca4a215fa59796ccdb43bdc18.png" data-canonical-url="./Figure/city.png" class=""/></div><div id="YPMhPV3vL4" class="myst-jp-nb-block relative group/block"><h3 id="id-3" class="relative group"><span class="mr-3 select-none">2.2</span><span class="heading-text">テキスト分類</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#id-3" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>テキスト分類とは、事前定義済みカテゴリまたはラベルを非構造化テキスト形式に割り当てる処理のことです。主な使用例として、感情分析、偽情報の検出や内容判定などが挙げられます。</p><p>言語は本質的に曖昧で、変化し続け、適切に定義されていないため、テキスト分類は決して簡単なタスクではないが、深層学習による自然言語処理が発展したことにより、高精度化させることが可能になってきています。</p><p>とくに<abbr aria-label="Bidirectional Encoder Representations from Transformers" class="border-b border-dotted cursor-help" data-state="closed">BERT</abbr> <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://doi.org/10.18653/v1/n19-1423" target="_blank" rel="noreferrer" class="hover-link">Devlin <em>et al.</em>, 2019</a></cite></span> はセンチメント分析を含めた多くのタスクに関して、当時の最高性能(<abbr aria-label="State of the Art" class="border-b border-dotted cursor-help" data-state="closed">SOTA</abbr>)を達成する画期的な技術でした。</p><ul><li><p>BERTは事前学習モデルの一種で、事前に一定のタスクに基づいて事前学習することで汎用性を獲得することに特徴があります。そのため、特定のタスクについてより少ないデータで性能を発揮することができます。</p></li><li><p>BERTのような事前学習モデルによるテキスト分類の社会科学における応用可能性について多くの注目を集めています <span class="cite-group parenthetical"><cite class="" data-state="closed"><a href="https://doi.org/10.1017/pan.2023.20" target="_blank" rel="noreferrer" class="hover-link">Laurer <em>et al.</em>, 2023</a></cite></span>。</p></li></ul><img id="yObnftyXAt" style="margin-left:auto;margin-right:auto" src="/build/text_class-115dfcd8b8d11560d0d6593638a513b2.png" data-canonical-url="./Figure/text_class.png" class=""/></div><div id="bNZmANuoB6" class="myst-jp-nb-block relative group/block"><p>さらに、近年、ChatGPTをはじめとする生成AIの大規模な言語モデルの進展により、テキスト分類に含めて言語に関わるさまざまなタスクができるようになりました。</p><p>これらのモデルは、学習済みのパラメータを更新することなく、プロンプト中に提示された少数の例や指示から新しい分類規則を即座に獲得し、タスクを遂行できるようになっています。</p></div><div id="IDXncRuknJ" class="myst-jp-nb-block relative group/block"><h2 id="id-4" class="relative group"><span class="mr-3 select-none">3</span><span class="heading-text">講義の構成</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#id-4" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><ol start="1"><li><p>イントロダクション</p></li><li><p>基礎知識  💻 🔣</p><ul><li><p>自然言語処理の基本概念</p></li><li><p>機械学習の基本概念</p></li><li><p>深層学習による自然言語処理ための数学の復習</p></li></ul></li><li><p>ニューラルネットワーク 💻 🔣</p><ul><li><p>ニューラルネットワークの構造</p></li><li><p>ニューラルネットワークの学習</p></li><li><p>誤差逆伝播法</p></li></ul></li><li><p>PyTorch 💻</p></li><li><p>単語埋め込みモデル(Word Embedding) 💻 🔣</p><ul><li><p>単語埋め込みアルゴリズム</p></li><li><p>単語埋め込みモデルの性質</p></li><li><p>word2vecの原理</p></li></ul></li><li><p>word2vecの実装 💻📄</p><ul><li><p>gensimによるword2vecモデルの学習</p></li><li><p>既存word2vecモデルの利用</p></li></ul></li><li><p>word2vecが人文・社会科学研究における応用 📄</p></li><li><p>シーケンスモデリング(1) 💻 🔣</p><ul><li><p>RNN</p></li><li><p>LSTM</p></li><li><p>seq2seq</p></li></ul></li><li><p>Transformer(1) 💻 🔣</p><ul><li><p>Attentionモデル</p></li><li><p>Self-attention</p></li><li><p>Transformerの構成要素</p></li></ul></li><li><p>BERTによるテキスト分類の実装(1) 💻</p><ul><li><p>事前学習済みモデルと転移学習</p></li><li><p>HuggingFace</p></li><li><p>GPUの設定</p></li></ul></li><li><p>BERTによるテキスト分類の実装(2) 💻</p></li><li><p>大規模言語モデルの概要</p></li><li><p>大規模言語モデルの応用(1) 💻</p></li><li><p>大規模言語モデルの応用(2) 💻</p></li><li><p>大規模言語モデルの応用(3) 💻</p></li></ol><ul><li><p>💻 : プログラミング作業が含む講義、PythonとJupyterの基本の使い方を把握することが前提となります</p></li><li><p>🔣　: 数学に関わる解説が含む講義、基本的な微積分と線形代数の知識が前提となります</p></li><li><p>📄　: 英語論文を読む必要がある講義</p></li></ul></div><div id="sHptbjIZtl" class="myst-jp-nb-block relative group/block"><h2 id="id-5" class="relative group"><span class="mr-3 select-none">4</span><span class="heading-text">到達目標</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#id-5" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><ul><li><p>自然言語処理と深層学習の基礎概念について学ぶとともに、自然言語処理手法を実装する能力を習得する</p></li><li><p>自然言語処理を用いる研究論文を理解できるようになることを目指す</p></li></ul></div><div id="rzTuQPEp2L" class="myst-jp-nb-block relative group/block"><h2 id="id-6" class="relative group"><span class="mr-3 select-none">5</span><span class="heading-text">授業設計と成績評価</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#id-6" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><ul><li><p>プログラミング操作が含む講義では、必ずPCをご持参する上で、Python環境を整備してください。また、インターネットとの接続が必要される操作もありますので、PCのインターネット接続も事前に設定してください。</p></li><li><p>授業後課題提出を求める場合があります。基本的には授業の理解度を確認するためのプログラミング課題と想定しています。</p></li><li><p>成績評価の分配は以下の通りです</p><ul><li><p>出席: <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">50\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">50%</span></span></span></span></span></p></li><li><p>課題: <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">50\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">50%</span></span></span></span></span></p></li></ul></li><li><p>授業の内容に関して不明点あるいはご要望があれば、随時<a target="_blank" rel="noreferrer" href="mailto:lyu.zeyu.e8@tohoku.ac.jp" class="">メール</a>でご連絡ください。また、プログラミングやソフトウェア操作の質問については、Google ClassroomまたはGitHub Issueでも受け付けます。</p></li><li><p>授業のオフィスアワーは、できれば二日前アポイントを取ってくだい。</p></li></ul></div><div class="myst-backmatter-parts"></div><section id="references" class="myst-bibliography article-grid subgrid-gap col-screen"><div><header class="myst-bibliography-header text-lg font-semibold text-stone-900 dark:text-white group">References<a class="no-underline text-inherit hover:text-inherit ml-2 select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#references" title="Link to References" aria-label="Link to References">¶</a></header></div><div class="myst-bibliography-list pl-3 mb-8 text-xs text-stone-500 dark:text-stone-300"><ol><li class="myst-bibliography-item break-words" id="cite-lazer2009">Lazer, D., Pentland, A., Adamic, L., Aral, S., Barabási, A.-L., Brewer, D., Christakis, N., Contractor, N., Fowler, J., Gutmann, M., Jebara, T., King, G., Macy, M., Roy, D., & Marshall Van Alstyne. (2009). Computational Social Science. <i>Science</i>, <i>323</i>(5915), 721–723. <a target="_blank" rel="noreferrer" href="https://doi.org/10.1126/science.1167742">10.1126/science.1167742</a></li><li class="myst-bibliography-item break-words" id="cite-hofman2021">Hofman, J. M. and W. (2021). Integrating Explanation and Prediction in Computational Social Science. <i>Nature</i>, <i>595</i>(7866), 181–188. <a target="_blank" rel="noreferrer" href="https://doi.org/10.1038/s41586-021-03659-0">10.1038/s41586-021-03659-0</a></li><li class="myst-bibliography-item break-words" id="cite-Garg2018">Garg, N., Schiebinger, L., Jurafsky, D., & Zou, J. (2018). Word embeddings quantify 100 years of gender and ethnic stereotypes. <i>Proceedings of the National Academy of Sciences</i>, <i>115</i>(16), E3635–E3644. <a target="_blank" rel="noreferrer" href="https://doi.org/10.1073/pnas.1720347115">10.1073/pnas.1720347115</a></li><li class="myst-bibliography-item break-words" id="cite-Kozlowski2019">Kozlowski, A. C., Taddy, M., & Evans, J. A. (2019). The Geometry of Culture: Analyzing the Meanings of Class through Word Embeddings. <i>American Sociological Review</i>, <i>84</i>(5), 905–949. <a target="_blank" rel="noreferrer" href="https://doi.org/10.1177/0003122419877135">10.1177/0003122419877135</a></li><li class="myst-bibliography-item break-words" id="cite-Devlin2019">Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). {BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding. <i>Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</i>, 4171–4186. <a target="_blank" rel="noreferrer" href="https://doi.org/10.18653/v1/n19-1423">10.18653/v1/n19-1423</a></li><li class="myst-bibliography-item break-words" id="cite-laurer_van">Laurer, M., van Atteveldt, W., Casas, A., & Welbers, K. (2023). Less Annotating, More Classifying: Addressing the Data Scarcity Issue of Supervised Machine Learning with Deep Transfer Learning and BERT-NLI. <i>Political Analysis</i>, 1–17. <a target="_blank" rel="noreferrer" href="https://doi.org/10.1017/pan.2023.20">10.1017/pan.2023.20</a></li></ol></div></section><div class="myst-footer-links flex pt-10 mb-10 space-x-4"><a class="myst-footer-link flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700 myst-footer-link-prev" href="/"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-footer-link-icon self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="myst-footer-link-group text-xs text-gray-500 dark:text-gray-400">計算社会科学と自然言語処理</div>計算社会科学と自然言語処理</div></div></a><a class="myst-footer-link flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700 myst-footer-link-next" href="/nlp-basis2"><div class="flex h-full align-middle"><div class="flex-grow"><div class="myst-footer-link-group text-xs text-gray-500 dark:text-gray-400">基礎知識</div>自然言語処理の基礎</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-footer-link-icon self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></article></main><script>((a,l)=>{if(!window.history.state||!window.history.state.key){let u=Math.random().toString(32).slice(2);window.history.replaceState({key:u},"")}try{let d=JSON.parse(sessionStorage.getItem(a)||"{}")[l||window.history.state.key];typeof d=="number"&&window.scrollTo(0,d)}catch(u){console.error(u),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-PCJPW7TK.js"/><link rel="modulepreload" href="/build/_shared/chunk-AQ2CODAG.js"/><link rel="modulepreload" href="/build/_shared/chunk-JJXTQVMA.js"/><link rel="modulepreload" href="/build/_shared/chunk-OZE3FFNP.js"/><link rel="modulepreload" href="/build/_shared/chunk-OYMW4E3D.js"/><link rel="modulepreload" href="/build/_shared/chunk-C4DFGG5C.js"/><link rel="modulepreload" href="/build/_shared/chunk-J7TUH54J.js"/><link rel="modulepreload" href="/build/_shared/chunk-FZ2S7OYD.js"/><link rel="modulepreload" href="/build/_shared/chunk-JEM6JXYA.js"/><link rel="modulepreload" href="/build/_shared/chunk-34XIY2DH.js"/><link rel="modulepreload" href="/build/_shared/chunk-KQM5FBHR.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/build/_shared/chunk-7HNKBP4B.js"/><link rel="modulepreload" href="/build/_shared/chunk-CUKUDK3R.js"/><link rel="modulepreload" href="/build/_shared/chunk-3EBOCCHJ.js"/><link rel="modulepreload" href="/build/_shared/chunk-O4VQNZ62.js"/><link rel="modulepreload" href="/build/_shared/chunk-4OEDG4JQ.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-CXYA7X5D.js"/><link rel="modulepreload" href="/build/_shared/chunk-DATP5P2X.js"/><link rel="modulepreload" href="/build/routes/$-JRBPULBO.js"/><script>window.__remixContext = {"url":"/introduction","state":{"loaderData":{"root":{"config":{"version":3,"myst":"1.7.0","options":{"favicon":"/build/tohoku-university-lo-68dede7d9dcb965aff25e8429e755296.svg","logo":"/build/tohoku-university-lo-68dede7d9dcb965aff25e8429e755296.svg","analytics_google":"G-85RFPTYEE3"},"nav":[],"actions":[],"projects":[{"numbering":{"heading_1":{"template":"enabled","enabled":true},"heading_2":{"template":"enabled","enabled":true},"heading_3":{"template":"enabled","enabled":true},"heading_4":{"template":"enabled","enabled":true},"heading_5":{"template":"enabled","enabled":true},"heading_6":{"template":"enabled","enabled":true}},"title":"計算社会科学と自然言語処理","github":"https://github.com/lvzeyu/css_nlp","id":"356ed62a-cf04-49ae-b7bc-d9f79f2ef8bb","exports":[],"bibliography":[],"index":"intro","pages":[{"title":"イントロダクション","level":1},{"slug":"introduction","title":"ガイダンス","description":"このページで、行動科学演習(LB63310)と計算人文社会学研究演習Ⅱ (LM23309)の授業資料を公開しています。","date":"","thumbnail":"/build/NLP_history-80702ee1d37040856a480174f5bcbbfc.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"基礎知識","level":1},{"slug":"nlp-basis2","title":"自然言語処理の基礎","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"ml-basis2","title":"機械学習の基本概念","description":"","date":"","thumbnail":"/build/supervised-learning-b5be7f5e73313e60f2c06d545c226553.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"math-basis2","title":"数学基礎","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"ニューラルネットワーク","level":1},{"slug":"nn2","title":"ニューラルネットワーク","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"backpropagation","title":"誤差逆伝播法","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"sgd","title":"学習に関するテクニック","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"PyTorch","level":1},{"slug":"pytorch2","title":"Pytorch","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"単語分散表現","level":1},{"slug":"word2vec-1","title":"単語分散表現","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"word2vec-2-embedding","title":"word2vec","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"word2vec-gensim","title":"GensimによるWord2Vecの学習と使用","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"word2vec-application","title":"Word2Vecが人文・社会科学研究における応用","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"RNN","level":1},{"slug":"rnn","title":"RNNの基礎","description":"","date":"","thumbnail":"/build/rnn-4dbf33ec81abf2baa6d5bbe97bb61683.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"lstm","title":"LSTM","description":"","date":"","thumbnail":"/build/lstm1-4ea8525c2f72b4f2ff8298a9f7b9c0be.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"pytorch-lstm","title":"LSTMの実装","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"lstm-classification","title":"LSTMによる文書分類","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"seq2seq","title":"Seq2seq","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"Transformer","level":1},{"slug":"attention","title":"Attention","description":"","date":"","thumbnail":"/build/attention-eed7f8fafc28c8cb6bd5276bbd04714b.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"self-attention","title":"Self-Attention","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"transformer","title":"Transformerアーキテクチャ","description":"","date":"","thumbnail":"/build/transformer-493148401fbb971a745b29ab5b44e10f.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"bert","title":"BERT","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"bert-sentiment","title":"BERTによるセンチメント分析","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"bert-topic","title":"BERTopic","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"大規模言語モデル","level":1},{"slug":"gpt","title":"GPT","description":"","date":"","thumbnail":"/build/gpt_history-c08ab6ce749d3aed300b023e318cb96c.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"llm","title":"大規模言語モデルの基本","description":"","date":"","thumbnail":"/build/LLMs_parameter-ec157a4028abc601fb429210b7f4b07c.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"langchain-basic","title":"LLMSの応用(1)：Langchainの基礎","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static"},"routes/$":{"config":{"version":3,"myst":"1.7.0","options":{"favicon":"/build/tohoku-university-lo-68dede7d9dcb965aff25e8429e755296.svg","logo":"/build/tohoku-university-lo-68dede7d9dcb965aff25e8429e755296.svg","analytics_google":"G-85RFPTYEE3"},"nav":[],"actions":[],"projects":[{"numbering":{"heading_1":{"template":"enabled","enabled":true},"heading_2":{"template":"enabled","enabled":true},"heading_3":{"template":"enabled","enabled":true},"heading_4":{"template":"enabled","enabled":true},"heading_5":{"template":"enabled","enabled":true},"heading_6":{"template":"enabled","enabled":true}},"title":"計算社会科学と自然言語処理","github":"https://github.com/lvzeyu/css_nlp","id":"356ed62a-cf04-49ae-b7bc-d9f79f2ef8bb","exports":[],"bibliography":[],"index":"intro","pages":[{"title":"イントロダクション","level":1},{"slug":"introduction","title":"ガイダンス","description":"このページで、行動科学演習(LB63310)と計算人文社会学研究演習Ⅱ (LM23309)の授業資料を公開しています。","date":"","thumbnail":"/build/NLP_history-80702ee1d37040856a480174f5bcbbfc.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"基礎知識","level":1},{"slug":"nlp-basis2","title":"自然言語処理の基礎","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"ml-basis2","title":"機械学習の基本概念","description":"","date":"","thumbnail":"/build/supervised-learning-b5be7f5e73313e60f2c06d545c226553.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"math-basis2","title":"数学基礎","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"ニューラルネットワーク","level":1},{"slug":"nn2","title":"ニューラルネットワーク","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"backpropagation","title":"誤差逆伝播法","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"sgd","title":"学習に関するテクニック","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"PyTorch","level":1},{"slug":"pytorch2","title":"Pytorch","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"単語分散表現","level":1},{"slug":"word2vec-1","title":"単語分散表現","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"word2vec-2-embedding","title":"word2vec","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"word2vec-gensim","title":"GensimによるWord2Vecの学習と使用","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"word2vec-application","title":"Word2Vecが人文・社会科学研究における応用","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"RNN","level":1},{"slug":"rnn","title":"RNNの基礎","description":"","date":"","thumbnail":"/build/rnn-4dbf33ec81abf2baa6d5bbe97bb61683.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"lstm","title":"LSTM","description":"","date":"","thumbnail":"/build/lstm1-4ea8525c2f72b4f2ff8298a9f7b9c0be.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"pytorch-lstm","title":"LSTMの実装","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"lstm-classification","title":"LSTMによる文書分類","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"seq2seq","title":"Seq2seq","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"Transformer","level":1},{"slug":"attention","title":"Attention","description":"","date":"","thumbnail":"/build/attention-eed7f8fafc28c8cb6bd5276bbd04714b.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"self-attention","title":"Self-Attention","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"transformer","title":"Transformerアーキテクチャ","description":"","date":"","thumbnail":"/build/transformer-493148401fbb971a745b29ab5b44e10f.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"bert","title":"BERT","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"bert-sentiment","title":"BERTによるセンチメント分析","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"bert-topic","title":"BERTopic","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"大規模言語モデル","level":1},{"slug":"gpt","title":"GPT","description":"","date":"","thumbnail":"/build/gpt_history-c08ab6ce749d3aed300b023e318cb96c.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"llm","title":"大規模言語モデルの基本","description":"","date":"","thumbnail":"/build/LLMs_parameter-ec157a4028abc601fb429210b7f4b07c.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"langchain-basic","title":"LLMSの応用(1)：Langchainの基礎","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"page":{"version":3,"kind":"Notebook","sha256":"412e6b0bc2681a84b8ec40939d7ac31c5f934e46bad91a227b241e9a93fcd207","slug":"introduction","location":"/notebook/introduction.ipynb","dependencies":[],"frontmatter":{"title":"ガイダンス","description":"このページで、行動科学演習(LB63310)と計算人文社会学研究演習Ⅱ (LM23309)の授業資料を公開しています。","authors":[{"nameParsed":{"literal":"呂沢宇　ZEYU LYU","given":"呂沢宇 ZEYU","family":"LYU"},"name":"呂沢宇　ZEYU LYU","email":"lyu.zeyu.e8@tohoku.ac.jp","affiliations":["東北大学　計算人文社会学"],"id":"contributors-introduction-generated-uid-0","corresponding":true}],"affiliations":[{"id":"東北大学　計算人文社会学","name":"東北大学　計算人文社会学"}],"github":"https://github.com/lvzeyu/css_nlp","numbering":{"heading_1":{"enabled":true,"template":"enabled"},"heading_2":{"enabled":true,"template":"enabled"},"heading_3":{"enabled":true,"template":"enabled"},"heading_4":{"enabled":true,"template":"enabled"},"heading_5":{"enabled":true,"template":"enabled"},"heading_6":{"enabled":true,"template":"enabled"},"title":{"offset":1}},"source_url":"https://github.com/lvzeyu/css_nlp/blob/master/notebook/introduction.ipynb","edit_url":"https://github.com/lvzeyu/css_nlp/edit/master/notebook/introduction.ipynb","thumbnail":"/build/NLP_history-80702ee1d37040856a480174f5bcbbfc.png","exports":[{"format":"ipynb","filename":"introduction.ipynb","url":"/build/introduction-f3963315f94dcbb82d9b6b23bf01632e.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"自然言語処理","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Gz9uo8iaOc"}],"identifier":"id","label":"自然言語処理","html_id":"id","implicit":true,"enumerator":"1","key":"r8BrNmTuQG"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"自然言語処理（NLP: Natural Language Processing）は、人間が日常的に使っている自然言語をコンピュータに処理させる一連の技術であり、人工知能（AI）の研究分野で中核を成す要素技術の一つといえます。","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"dD0GnNSpnX"}],"key":"Yri0NOu1gW"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"私たちは普段、自分たちの言語の複雑さについて考えることはありません。人間にとっては、言語は歩くのと同じように、訓練された反復可能な行動であるため、習得しやすく、青年期にはより自然に使用できるようになると言われています。ただ、人間にとって自然なことでも、大量の非構造化データを処理し、正式なルールがないばかりか、現実世界のコンテキストや意図もないコンピューターにとっては、それを成すことは非常に困難です。","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"n84UUlo78A"}],"key":"l6o9nCeSLa"}],"key":"vOP45qEoXk"},{"type":"block","kind":"notebook-content","children":[{"type":"admonition","kind":"custom","class":"dropdown tohokupurple","icon":"question","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"なぜ自然言語処理は難しいのか","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"nmOzgmOEQK"}],"key":"F4WkmCn3Ga"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"私たちは普段、自分たちの言語の複雑さについて考えることはありません。人間にとっては、言語は歩くのと同じように、訓練された反復可能な行動であるため、習得しやすく、青年期にはより自然に使用できるようになると言われています。ただ、人間にとって自然なことでも、大量の非構造化データを処理し、正式なルールがないばかりか、現実世界のコンテキストや意図もないコンピューターにとっては、それを成すことは非常に困難です。","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"eshTPTMoUr"}],"key":"oKXmXmozso"}],"key":"G4mDskySbw"}],"key":"kxED3nF5Ts"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"近年、自然言語処理技術の急速な進歩に驚きの声が上がっていました。","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OKhgOWQHFd"}],"key":"pnnbvf0Z99"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"実際、自然言語処理において昨今の支配的な手法は、隠れマルコフモデル(HMM)、線型サポートベクトルマシン(SVM)やロジスティック回帰など統計的機械学習(statistical machine learning)に基づいていました。","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"lwZtv9NeRw"}],"key":"KJCTSHZGe6"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"2014年頃、この分野において、","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"bZMAD9id1K"},{"type":"link","url":"https://ja.wikipedia.org/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"ニューラルネットワーク","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"bCzeuiMLLd"}],"urlSource":"https://ja.wikipedia.org/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF","data":{"page":"%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF","wiki":"https://ja.wikipedia.org/","lang":"ja"},"internal":false,"protocol":"wiki","key":"nV1ge731o7"},{"type":"text","value":"という技術が導入され、多くのタスクにより高い性能を達成できました。さらに、これに基づいて、より先進的なモデリング方法の開発も進めました。特に、","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"hwezdYfcrn"},{"type":"link","url":"https://ja.wikipedia.org/wiki/%E5%9B%9E%E5%B8%B0%E5%9E%8B%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"再帰的ニューラルネットワーク(RNN)","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Rl50mvWl6S"}],"urlSource":"https://ja.wikipedia.org/wiki/%E5%9B%9E%E5%B8%B0%E5%9E%8B%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF","data":{"page":"%E5%9B%9E%E5%B8%B0%E5%9E%8B%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF","wiki":"https://ja.wikipedia.org/","lang":"ja"},"internal":false,"protocol":"wiki","key":"Z7X287O3IM"},{"type":"text","value":"に基づく方法は言語の時系列性質も学習できるになって、様々なタスクにおいて精度向上に大きく貢献しました。","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"A2HNMQZKOf"}],"key":"YTP6mKRn8R"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"2018年にGoogleが発表した","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"JGSL94ppiU"},{"type":"link","url":"https://ja.wikipedia.org/wiki/BERT_(%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB)","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"BERT","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"WeYSyQcfk6"}],"urlSource":"https://ja.wikipedia.org/wiki/BERT_(%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB)","data":{"page":"BERT_(%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB)","wiki":"https://ja.wikipedia.org/","lang":"ja"},"internal":false,"protocol":"wiki","key":"UqfEI9Ldfd"},{"type":"text","value":"というモデルでは、大規模なテキストで一般的な言語パターンや文脈を学習します。その後、この事前学習済みモデルを特定のNLPタスクに","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Ih8vzsXtBI"},{"type":"link","url":"https://ja.wikipedia.org/wiki/%E3%83%95%E3%82%A1%E3%82%A4%E3%83%B3%E3%83%81%E3%83%A5%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0_(%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92)","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"ファインチューニング","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"fj9QMwuHyY"}],"urlSource":"https://ja.wikipedia.org/wiki/%E3%83%95%E3%82%A1%E3%82%A4%E3%83%B3%E3%83%81%E3%83%A5%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0_(%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92)","data":{"page":"%E3%83%95%E3%82%A1%E3%82%A4%E3%83%B3%E3%83%81%E3%83%A5%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0_(%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92)","wiki":"https://ja.wikipedia.org/","lang":"ja"},"internal":false,"protocol":"wiki","key":"qjCrZg1w3B"},{"type":"text","value":"することで、少ないラベル付きデータで高性能を発揮することができます。","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"tvCRxc8wlb"}],"key":"fo22MZY0S7"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"それだけでも驚きでしたが、一般人の中でも話題になる「ChatGPT」をはじめとする生成AIの","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"SP9HyIbVZB"},{"type":"link","url":"https://ja.wikipedia.org/wiki/%E5%A4%A7%E8%A6%8F%E6%A8%A1%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"大規模な言語モデル(LLM:Large Language Model)","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"ypL1xUfPdL"}],"urlSource":"https://ja.wikipedia.org/wiki/%E5%A4%A7%E8%A6%8F%E6%A8%A1%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB","data":{"page":"%E5%A4%A7%E8%A6%8F%E6%A8%A1%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB","wiki":"https://ja.wikipedia.org/","lang":"ja"},"internal":false,"protocol":"wiki","key":"kQEYAwnuRp"},{"type":"text","value":"の進展により、質問への回答、文章の要約や翻訳、ソフトウエアのプログラミングなど、言語に関わるさまざまなタスクができるようになりました。","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"we9uBLX243"}],"key":"CJAF43SvFA"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"高機能化のカギは、","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"x1I7Mib5OM"},{"type":"link","url":"https://ja.wikipedia.org/wiki/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"深層学習","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"aoZblvumAn"}],"urlSource":"https://ja.wikipedia.org/wiki/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0","data":{"page":"%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0","wiki":"https://ja.wikipedia.org/","lang":"ja"},"internal":false,"protocol":"wiki","key":"RrwOHvY9Lh"},{"type":"text","value":"技術の発展があります。深層学習を用いた自然言語処理には、あらかじめ用意した膨大な文章を使って、","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"diFctvWrim"},{"type":"link","url":"https://ja.wikipedia.org/wiki/%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"「言語モデル」","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"wgcA27vN1b"}],"urlSource":"https://ja.wikipedia.org/wiki/%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB","data":{"page":"%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB","wiki":"https://ja.wikipedia.org/","lang":"ja"},"internal":false,"protocol":"wiki","key":"sB1RUQ6ZtU"},{"type":"text","value":"と呼ばれるシステムを学習させる方法があります。\n言語モデルの実体は簡単な計算式を大量に組み合わせた超巨大な数式といえます。最先端の言語モデルでは、想像を絶するほど大量の文章を使い、パラメータ（数式の係数）が数千億に達するほどの大規模な言語モデルを学習させて使っています。LLMが人間に匹敵するほどの高度な能力を持つ、文章の作成や会話を利用するさまざまな仕事を、コンピュータに任せることが可能になってきました。","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"tzYpDpGSRn"}],"key":"Cz9jldsSZC"}],"key":"YL13fI1VCI"},{"type":"block","kind":"notebook-content","children":[{"type":"container","kind":"figure","children":[{"type":"image","url":"/build/NLP_history-80702ee1d37040856a480174f5bcbbfc.png","alt":"Sunset at the beach","align":"center","key":"RcPAtZGKR3","urlSource":"./Figure/NLP_history.png"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"自然言語処理の歴史","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"ZTjgQyuawg"}],"key":"fnF7sb2Q0x"}],"key":"IzJzvoVCbz"}],"enumerator":"1","key":"WY9UWE6IOH"}],"key":"agKl94eAb6"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"計算社会科学において自然言語処理の応用","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zsfKxXz6eC"}],"identifier":"id","label":"計算社会科学において自然言語処理の応用","html_id":"id-1","implicit":true,"enumerator":"2","key":"aRMzEQihgx"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"人間の社会行動に関するデジタル化された高密度・大容量のデータの蓄積を背景に、近年、計算社会科学と呼ばれる新たな学問領域が勃興し、急速な発展を遂げています","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"NB7JtElezR"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"cite","identifier":"lazer2009","label":"lazer2009","kind":"parenthetical","position":{"start":{"line":3,"column":78},"end":{"line":3,"column":88}},"children":[{"type":"text","value":"Lazer ","key":"VsZ5HnDbF1"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"CaYNV0j29R"}],"key":"DIXxkw8STB"},{"type":"text","value":", 2009","key":"ImBj3zgIU1"}],"enumerator":"1","key":"l0SmwxcHwi"},{"type":"cite","identifier":"hofman2021","label":"hofman2021","kind":"parenthetical","position":{"start":{"line":3,"column":89},"end":{"line":3,"column":100}},"children":[{"type":"text","value":"Hofman, 2021","key":"bAHt4PIdnZ"}],"enumerator":"2","key":"hUuhkGDm3a"}],"key":"JENCQJ6vrC"},{"type":"text","value":"。","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"lmw0nY0dwY"}],"key":"Cmce3ivfN2"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"計算社会科学において，テキストデータの収集・分析は広く用いられている研究手法です。ここで、自然言語処理技術の発展が計算社会科学にす新たな可能性をもたらせます。","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"DpqiroziDW"}],"key":"JiBp7fKXGU"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"本講義の目的は、","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"LYhVnLFfdd"},{"type":"underline","children":[{"type":"strong","children":[{"type":"text","value":"計算社会科学に多く応用された自然言語処理技術を理解し、実問題に適用するための基礎力を身につけることです。","key":"GA7CGX6hhL"}],"key":"zy0f3jEWwN"}],"key":"iwyJwgMjJR"}],"key":"SFqKuzW2bi"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"その目的を達成するために、","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"U67vZqX5jo"},{"type":"underline","children":[{"type":"strong","children":[{"type":"text","value":"自然言語処理と深層学習の基礎、重要な概念と主な手法(モデル)","key":"YnrcRxT4lr"}],"key":"OyXDcgQkLE"}],"key":"OZlCwLn6BF"},{"type":"text","value":"を学習する。さらに、Python用いて、自然言語処理によく用いられるライブラリとツールを学習しつつ、","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"UMsHZHPDwZ"},{"type":"underline","children":[{"type":"strong","children":[{"type":"text","value":"自然言語処理技術を応用するスキル","key":"FxNq1JsX1j"}],"key":"LYmZevHsbO"}],"key":"LLDwHzzx4R"},{"type":"text","value":"を修得する。","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"W7Q2M1lxky"}],"key":"f6ROkFNymr"}],"key":"bqdqVQpHTP"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"単語分散表現","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BnXH7slnUE"}],"identifier":"id","label":"単語分散表現","html_id":"id-2","implicit":true,"enumerator":"2.1","key":"czvvAy5qlf"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"link","url":"https://ja.wikipedia.org/wiki/%E5%8D%98%E8%AA%9E%E3%81%AE%E5%9F%8B%E3%82%81%E8%BE%BC%E3%81%BF","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"単語分散表現","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"bLhl9Ra528"}],"urlSource":"https://ja.wikipedia.org/wiki/%E5%8D%98%E8%AA%9E%E3%81%AE%E5%9F%8B%E3%82%81%E8%BE%BC%E3%81%BF","data":{"page":"%E5%8D%98%E8%AA%9E%E3%81%AE%E5%9F%8B%E3%82%81%E8%BE%BC%E3%81%BF","wiki":"https://ja.wikipedia.org/","lang":"ja"},"internal":false,"protocol":"wiki","key":"Np8BxWV6rm"},{"type":"text","value":"とは、「文字・単語をベクトル空間に埋め込み、その空間上のひとつの点として捉える」ことを指します。","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Mj9H6YWGk9"}],"key":"bE6OFoiEfR"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":4,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"類似性: ある概念を表現する際に、ほかの概念との共通点や類似性と紐づけながら、ベクトル空間上に表現します。","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"k9EgUz3K2j"}],"key":"zWxRfRKPrZ"}],"key":"X2e3VORRxi"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"単語類推: 分散表現では異なる概念を表現するベクトル同士での計算が可能です","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"uA08u7k62w"}],"key":"HhB6Ba8iba"}],"key":"DRucFYHWpC"}],"key":"zQLhZnkoLO"}],"key":"iRtTBN5LiX"},{"type":"block","kind":"notebook-content","children":[{"type":"container","kind":"figure","children":[{"type":"image","url":"/build/word2vec-e9464d85d29ea83b24cfeb53aedc1339.png","alt":"Sunset at the beach","align":"center","key":"NSsQD2llW8","urlSource":"./Figure/word2vec.png"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"単語分散表現のイメージ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"O2JTo2sNiz"}],"key":"ZRuOqz1rWs"}],"key":"caCFqzSDEE"}],"enumerator":"2","key":"HZBTbeT6i3"}],"key":"MnOpbAihfM"},{"type":"block","kind":"notebook-content","children":[{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"1910年代からのテキストデータで単語分散表現を学習し、単語分散表現で男性と女性はそれぞれどのような単語と関連していることを検証することで、ジェンダーのステレオタイプの実態と変化を定量的に分析する ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"l5V7h7VE6w"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"cite","identifier":"garg2018","label":"Garg2018","kind":"parenthetical","position":{"start":{"line":2,"column":101},"end":{"line":2,"column":110}},"children":[{"type":"text","value":"Garg ","key":"iz8tGEObTs"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"efkHW688Ba"}],"key":"GaqTN1RX7K"},{"type":"text","value":", 2018","key":"U356P1yyhp"}],"enumerator":"3","key":"wHD5A7IEZg"}],"key":"lOb9D2EJI9"}],"key":"gDS9ibyIZc"}],"key":"euO8Pkc5OA"}],"key":"sEVLfz9OS4"},{"type":"image","url":"/build/word2vec_gender-c3f35f5223c49f64de120ebbd85a7c56.jpeg","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"KxWeD7yuup","urlSource":"./Figure/word2vec_gender.jpeg"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":6,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"単語分散表現の類似性と単語類推特性で、単語分散表現の計算を通じて、文化概念の潜在的意味と関係を定量的に測定できました","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"tcziNdNQvC"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"cite","identifier":"kozlowski2019","label":"Kozlowski2019","kind":"parenthetical","position":{"start":{"line":6,"column":60},"end":{"line":6,"column":74}},"children":[{"type":"text","value":"Kozlowski ","key":"TW9V9Z9q9R"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"SnjGGkZm6Q"}],"key":"ACmQYauMYe"},{"type":"text","value":", 2019","key":"MC09m0G0Ts"}],"enumerator":"4","key":"bks8crpnyT"}],"key":"qoF6IruFyr"}],"key":"cgqwcZqoOr"}],"key":"PPamKuBiVe"}],"key":"MXDBLpN80E"},{"type":"image","url":"/build/city-e6c77b7ca4a215fa59796ccdb43bdc18.png","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"hBicxdMDri","urlSource":"./Figure/city.png"}],"key":"nW8eumsAp5"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"テキスト分類","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GUXIIDac8s"}],"identifier":"id","label":"テキスト分類","html_id":"id-3","implicit":true,"enumerator":"2.2","key":"mG59JUljyX"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"テキスト分類とは、事前定義済みカテゴリまたはラベルを非構造化テキスト形式に割り当てる処理のことです。主な使用例として、感情分析、偽情報の検出や内容判定などが挙げられます。","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"pAD3OOGqsN"}],"key":"qP9aO9v3Nb"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"言語は本質的に曖昧で、変化し続け、適切に定義されていないため、テキスト分類は決して簡単なタスクではないが、深層学習による自然言語処理が発展したことにより、高精度化させることが可能になってきています。","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"KOcPD0fl8G"}],"key":"ZD8ty7NQrF"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"とくに","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"aw75NADbUd"},{"type":"abbreviation","title":"Bidirectional Encoder Representations from Transformers","children":[{"type":"text","value":"BERT","key":"tNhYTONCgg"}],"key":"MZPYIys9Bx"},{"type":"text","value":" ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"WjgI4MLn4t"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"cite","identifier":"devlin2019","label":"Devlin2019","kind":"parenthetical","position":{"start":{"line":7,"column":75},"end":{"line":7,"column":86}},"children":[{"type":"text","value":"Devlin ","key":"e6CsgLnj8z"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"QI3Nf33DW1"}],"key":"ZmntK5neTO"},{"type":"text","value":", 2019","key":"Ulifz2zN84"}],"enumerator":"5","key":"j2c9f1j42N"}],"key":"zIsZPZvfTI"},{"type":"text","value":" はセンチメント分析を含めた多くのタスクに関して、当時の最高性能(","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"W2QkVemhB0"},{"type":"abbreviation","title":"State of the Art","children":[{"type":"text","value":"SOTA","key":"rdQEqsBK1s"}],"key":"QlhkxImuff"},{"type":"text","value":")を達成する画期的な技術でした。","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"kUmUYMR4vm"}],"key":"dZiHS6P2O9"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":9,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"BERTは事前学習モデルの一種で、事前に一定のタスクに基づいて事前学習することで汎用性を獲得することに特徴があります。そのため、特定のタスクについてより少ないデータで性能を発揮することができます。","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"LI9rrJudHa"}],"key":"Ew4GvpI45L"}],"key":"QIzLK6LS1w"},{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"BERTのような事前学習モデルによるテキスト分類の社会科学における応用可能性について多くの注目を集めています ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"rBghPXHZy2"},{"type":"citeGroup","kind":"parenthetical","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"cite","identifier":"laurer_van","label":"laurer_van","kind":"parenthetical","position":{"start":{"line":11,"column":57},"end":{"line":11,"column":68}},"children":[{"type":"text","value":"Laurer ","key":"KPcu5260Qz"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"UFyRugBG73"}],"key":"kUCSDMOH3Q"},{"type":"text","value":", 2023","key":"DpLWc22riv"}],"enumerator":"6","key":"tOV4zGKsVU"}],"key":"AcYvfMfgnD"},{"type":"text","value":"。","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"bFgDhtrxIQ"}],"key":"uhOPCVvWKm"}],"key":"tgMgDm2Is3"}],"key":"ySih2EkoS9"},{"type":"image","url":"/build/text_class-115dfcd8b8d11560d0d6593638a513b2.png","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"yObnftyXAt","urlSource":"./Figure/text_class.png"}],"key":"YPMhPV3vL4"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"さらに、近年、ChatGPTをはじめとする生成AIの大規模な言語モデルの進展により、テキスト分類に含めて言語に関わるさまざまなタスクができるようになりました。","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JRsip4vWtX"}],"key":"lRz5KUDcUC"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"これらのモデルは、学習済みのパラメータを更新することなく、プロンプト中に提示された少数の例や指示から新しい分類規則を即座に獲得し、タスクを遂行できるようになっています。","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"xlpLoWYTSG"}],"key":"QuU7UjzdbU"}],"key":"bNZmANuoB6"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"講義の構成","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UaOJruYMtX"}],"identifier":"id","label":"講義の構成","html_id":"id-4","implicit":true,"enumerator":"3","key":"PEzfy9P3iN"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":3,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"イントロダクション","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"PDkX81KJZe"}],"key":"h6iGgMlGTe"}],"key":"CTSqtmEY5Y"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"基礎知識  💻 🔣","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"Zs6PFixR7p"}],"key":"phPG6ea71y"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"自然言語処理の基本概念","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"ryW6fQMDdk"}],"key":"MP8NCAZEBs"}],"key":"dhEPDNuUWg"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"機械学習の基本概念","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"dYYxyYKJLZ"}],"key":"p8YUMGZOGv"}],"key":"E3IzpU0TTq"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"深層学習による自然言語処理ための数学の復習","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"OXOAQyyMn5"}],"key":"gvddqvrdFD"}],"key":"z14XBnx9ef"}],"key":"bnj9lpexL6"}],"key":"HDeHiWxP5u"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"ニューラルネットワーク 💻 🔣","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"reqr3uivbK"}],"key":"qTRoAFrDjy"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":9,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"ニューラルネットワークの構造","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"mezQWd2f2v"}],"key":"nGYGBnkDt6"}],"key":"ueJrXT5IZD"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"ニューラルネットワークの学習","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"kB23xp7SIn"}],"key":"eRDGtIBWB0"}],"key":"SO99wroHVO"},{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"誤差逆伝播法","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"jDUGI2EKBh"}],"key":"Zv5AH5qJEV"}],"key":"DLeueD2RLv"}],"key":"bzZVROcyh9"}],"key":"IaidaA3rE3"},{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"PyTorch 💻","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"CK4xBFFzEn"}],"key":"Ysal05eyG3"}],"key":"DSH4rsUm4y"},{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"単語埋め込みモデル(Word Embedding) 💻 🔣","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"NrC2Wh5wMY"}],"key":"nbShdgEmdK"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":14,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"単語埋め込みアルゴリズム","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"dEvjF6EpqH"}],"key":"VnNB5T94BJ"}],"key":"uR1faIby2m"},{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"単語埋め込みモデルの性質","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"afqMWiLcAE"}],"key":"YB4CJENQ96"}],"key":"Q0l0qCXuS7"},{"type":"listItem","spread":true,"position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"word2vecの原理","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"vEkp6VFHg6"}],"key":"kKoWzlCIUU"}],"key":"VP650XPRhp"}],"key":"A3jDCKblnS"}],"key":"m57xpkbWRs"},{"type":"listItem","spread":true,"position":{"start":{"line":17,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"word2vecの実装 💻📄","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"gsbS65zom2"}],"key":"JXlF0W3sRI"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":18,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"gensimによるword2vecモデルの学習","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"oMGptQ2mhQ"}],"key":"YtKZg1brnv"}],"key":"HTsM0RG3Q0"},{"type":"listItem","spread":true,"position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"既存word2vecモデルの利用","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"GOQTqOnM60"}],"key":"y8SIFvi2Un"}],"key":"i2MIdOQiH2"}],"key":"lTCe2qKVkf"}],"key":"aauDJ5HCs9"},{"type":"listItem","spread":true,"position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"word2vecが人文・社会科学研究における応用 📄","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"GqXiHJxRm2"}],"key":"kUMgJiz4ds"}],"key":"NJXBEP9DO2"},{"type":"listItem","spread":true,"position":{"start":{"line":21,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"シーケンスモデリング(1) 💻 🔣","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"hR2i8HPDgA"}],"key":"bAAIRFHqPs"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":22,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"RNN","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"Gp8gAABNS4"}],"key":"ZdeiaVHxqH"}],"key":"M0cwfpatpi"},{"type":"listItem","spread":true,"position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"LSTM","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"MwU2K3JTq8"}],"key":"cFyCqBJd48"}],"key":"Yk3ZeGnpV2"},{"type":"listItem","spread":true,"position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"seq2seq","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"key":"BdRfK99YUq"}],"key":"VdNzbC0Btj"}],"key":"h77lrSjUNU"}],"key":"OGDo5yN9pB"}],"key":"wBxQTHRKBw"},{"type":"listItem","spread":true,"position":{"start":{"line":25,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Transformer(1) 💻 🔣","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"StLFXWb3w6"}],"key":"t5yLo1SJNG"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":26,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Attentionモデル","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"uhQvb2JQvn"}],"key":"ERS3HaGDB7"}],"key":"Y9fq9K3JLL"},{"type":"listItem","spread":true,"position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Self-attention","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"gPK2WROM8P"}],"key":"I4MOBkcwij"}],"key":"JSDtJbR7d0"},{"type":"listItem","spread":true,"position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Transformerの構成要素","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"FO0DCa4UI9"}],"key":"Je3OaenjHn"}],"key":"LagcDjSixY"}],"key":"H69uHNLTcD"}],"key":"iPdd85l9H0"},{"type":"listItem","spread":true,"position":{"start":{"line":29,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"BERTによるテキスト分類の実装(1) 💻","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"OMZL4dgu1W"}],"key":"Y37TutyndH"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":30,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"事前学習済みモデルと転移学習","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"WlodEGFwEv"}],"key":"CIYiOH47jq"}],"key":"rczwJmMKXo"},{"type":"listItem","spread":true,"position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"HuggingFace","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"OTpxMxu41n"}],"key":"Ie22JOnJNF"}],"key":"wkhtgsfZvl"},{"type":"listItem","spread":true,"position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"GPUの設定","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"lC8b0Ni9qz"}],"key":"wZLHO5aSXG"}],"key":"oFgzgNgYBm"}],"key":"XqI1lcD7Dp"}],"key":"IiTN42FGQp"},{"type":"listItem","spread":true,"position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"BERTによるテキスト分類の実装(2) 💻","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"AySXczOJKg"}],"key":"zniiTjf8FB"}],"key":"GlAeJT0981"},{"type":"listItem","spread":true,"position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"大規模言語モデルの概要","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"wp0TbxYs6j"}],"key":"bnwkvSKTE5"}],"key":"vLfNDIsfiH"},{"type":"listItem","spread":true,"position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"大規模言語モデルの応用(1) 💻","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"Gy7jK009Eo"}],"key":"xieqzaebeb"}],"key":"IzLmqfY4El"},{"type":"listItem","spread":true,"position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"大規模言語モデルの応用(2) 💻","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"Eq7ESEB4W2"}],"key":"FwXUIGvIrI"}],"key":"kwYmdAzxKf"},{"type":"listItem","spread":true,"position":{"start":{"line":37,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"大規模言語モデルの応用(3) 💻","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"WYadt2nCqY"}],"key":"wyDBGfNyXA"}],"key":"UDY7LvDYKb"}],"key":"YTfgFOYMFY"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":40,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"💻 : プログラミング作業が含む講義、PythonとJupyterの基本の使い方を把握することが前提となります","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"key":"DQ8qEjCrIh"}],"key":"OD8jI01rB4"}],"key":"x6a4TnooGC"},{"type":"listItem","spread":true,"position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"🔣　: 数学に関わる解説が含む講義、基本的な微積分と線形代数の知識が前提となります","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"XhQPoHznJX"}],"key":"kdb1FN8FHw"}],"key":"IUSCgLJyKB"},{"type":"listItem","spread":true,"position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"📄　: 英語論文を読む必要がある講義","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"key":"ImWdETis5Z"}],"key":"BMflbFeCFW"}],"key":"n9w6XUZsu8"}],"key":"ND1SHusbGO"}],"key":"IDXncRuknJ"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"到達目標","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hSXloki4Nq"}],"identifier":"id","label":"到達目標","html_id":"id-5","implicit":true,"enumerator":"4","key":"WzIgxK7nw3"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":3,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"自然言語処理と深層学習の基礎概念について学ぶとともに、自然言語処理手法を実装する能力を習得する","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"GL6SGQziJw"}],"key":"nppxxZmy94"}],"key":"LjdTlfl0z3"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"自然言語処理を用いる研究論文を理解できるようになることを目指す","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"hXdvsxVT2R"}],"key":"FjisypxIxR"}],"key":"YWEpYqhnP4"}],"key":"kgIufaoEDi"}],"key":"sHptbjIZtl"},{"type":"block","kind":"notebook-content","data":{"vscode":{"languageId":"plaintext"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"授業設計と成績評価","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Q9mQsZBMU6"}],"identifier":"id","label":"授業設計と成績評価","html_id":"id-6","implicit":true,"enumerator":"5","key":"nCMpqf0qMs"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":3,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"プログラミング操作が含む講義では、必ずPCをご持参する上で、Python環境を整備してください。また、インターネットとの接続が必要される操作もありますので、PCのインターネット接続も事前に設定してください。","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"jJN6C3XsPN"}],"key":"MunB80Psgm"}],"key":"I3arMBnArN"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"授業後課題提出を求める場合があります。基本的には授業の理解度を確認するためのプログラミング課題と想定しています。","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"Buy4sNFuIL"}],"key":"ZBpKHutq62"}],"key":"aYijaZK1wS"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"成績評価の分配は以下の通りです","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"UDaVsE32bT"}],"key":"S4QfDMLA2X"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":7,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"出席: ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"If5b4ERZv9"},{"type":"inlineMath","value":"50\\%","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e50\u003c/mn\u003e\u003cmi mathvariant=\"normal\"\u003e%\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e50\\%\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8056em;vertical-align:-0.0556em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e50%\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"T84TtSPrzP"}],"key":"v5edB6vQW9"}],"key":"r4zKL0t17i"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"課題: ","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"l9E4dF268U"},{"type":"inlineMath","value":"50\\%","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e50\u003c/mn\u003e\u003cmi mathvariant=\"normal\"\u003e%\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e50\\%\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8056em;vertical-align:-0.0556em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e50%\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"w0oMPK1cpA"}],"key":"Hhhse9yIM9"}],"key":"OALDBVfNsS"}],"key":"D7odfmODTa"}],"key":"yISjRxAdHU"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"授業の内容に関して不明点あるいはご要望があれば、随時","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"lIhdpzfDyl"},{"type":"link","url":"mailto:lyu.zeyu.e8@tohoku.ac.jp","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"メール","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"M6qchAW40z"}],"urlSource":"mailto:lyu.zeyu.e8@tohoku.ac.jp","key":"noB5ZtC7ce"},{"type":"text","value":"でご連絡ください。また、プログラミングやソフトウェア操作の質問については、Google ClassroomまたはGitHub Issueでも受け付けます。","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"xM5tkXAt8a"}],"key":"FjX920nKTQ"}],"key":"oJ3uljPBKm"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"授業のオフィスアワーは、できれば二日前アポイントを取ってくだい。","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"xcheKWsqNp"}],"key":"lUBMHXP4gd"}],"key":"Jf2A2rrxRu"}],"key":"aeXAxxS1IX"}],"key":"rzTuQPEp2L"}],"key":"tIiaTvSro9"},"references":{"cite":{"order":["lazer2009","hofman2021","Garg2018","Kozlowski2019","Devlin2019","laurer_van"],"data":{"lazer2009":{"label":"lazer2009","enumerator":"1","doi":"10.1126/science.1167742","html":"Lazer, D., Pentland, A., Adamic, L., Aral, S., Barabási, A.-L., Brewer, D., Christakis, N., Contractor, N., Fowler, J., Gutmann, M., Jebara, T., King, G., Macy, M., Roy, D., \u0026 Marshall Van Alstyne. (2009). Computational Social Science. \u003ci\u003eScience\u003c/i\u003e, \u003ci\u003e323\u003c/i\u003e(5915), 721–723. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1126/science.1167742\"\u003e10.1126/science.1167742\u003c/a\u003e","url":"https://doi.org/10.1126/science.1167742"},"hofman2021":{"label":"hofman2021","enumerator":"2","doi":"10.1038/s41586-021-03659-0","html":"Hofman, J. M. and W. (2021). Integrating Explanation and Prediction in Computational Social Science. \u003ci\u003eNature\u003c/i\u003e, \u003ci\u003e595\u003c/i\u003e(7866), 181–188. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1038/s41586-021-03659-0\"\u003e10.1038/s41586-021-03659-0\u003c/a\u003e","url":"https://doi.org/10.1038/s41586-021-03659-0"},"Garg2018":{"label":"Garg2018","enumerator":"3","doi":"10.1073/pnas.1720347115","html":"Garg, N., Schiebinger, L., Jurafsky, D., \u0026 Zou, J. (2018). Word embeddings quantify 100 years of gender and ethnic stereotypes. \u003ci\u003eProceedings of the National Academy of Sciences\u003c/i\u003e, \u003ci\u003e115\u003c/i\u003e(16), E3635–E3644. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1073/pnas.1720347115\"\u003e10.1073/pnas.1720347115\u003c/a\u003e","url":"https://doi.org/10.1073/pnas.1720347115"},"Kozlowski2019":{"label":"Kozlowski2019","enumerator":"4","doi":"10.1177/0003122419877135","html":"Kozlowski, A. C., Taddy, M., \u0026 Evans, J. A. (2019). The Geometry of Culture: Analyzing the Meanings of Class through Word Embeddings. \u003ci\u003eAmerican Sociological Review\u003c/i\u003e, \u003ci\u003e84\u003c/i\u003e(5), 905–949. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1177/0003122419877135\"\u003e10.1177/0003122419877135\u003c/a\u003e","url":"https://doi.org/10.1177/0003122419877135"},"Devlin2019":{"label":"Devlin2019","enumerator":"5","doi":"10.18653/v1/n19-1423","html":"Devlin, J., Chang, M.-W., Lee, K., \u0026 Toutanova, K. (2019). {BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding. \u003ci\u003eProceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)\u003c/i\u003e, 4171–4186. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.18653/v1/n19-1423\"\u003e10.18653/v1/n19-1423\u003c/a\u003e","url":"https://doi.org/10.18653/v1/n19-1423"},"laurer_van":{"label":"laurer_van","enumerator":"6","doi":"10.1017/pan.2023.20","html":"Laurer, M., van Atteveldt, W., Casas, A., \u0026 Welbers, K. (2023). Less Annotating, More Classifying: Addressing the Data Scarcity Issue of Supervised Machine Learning with Deep Transfer Learning and BERT-NLI. \u003ci\u003ePolitical Analysis\u003c/i\u003e, 1–17. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1017/pan.2023.20\"\u003e10.1017/pan.2023.20\u003c/a\u003e","url":"https://doi.org/10.1017/pan.2023.20"}}}},"footer":{"navigation":{"prev":{"title":"計算社会科学と自然言語処理","url":"/","group":"計算社会科学と自然言語処理"},"next":{"title":"自然言語処理の基礎","url":"/nlp-basis2","group":"基礎知識"}}},"domain":"http://localhost:3000"},"project":{"numbering":{"heading_1":{"template":"enabled","enabled":true},"heading_2":{"template":"enabled","enabled":true},"heading_3":{"template":"enabled","enabled":true},"heading_4":{"template":"enabled","enabled":true},"heading_5":{"template":"enabled","enabled":true},"heading_6":{"template":"enabled","enabled":true}},"title":"計算社会科学と自然言語処理","github":"https://github.com/lvzeyu/css_nlp","id":"356ed62a-cf04-49ae-b7bc-d9f79f2ef8bb","exports":[],"bibliography":[],"index":"intro","pages":[{"title":"イントロダクション","level":1},{"slug":"introduction","title":"ガイダンス","description":"このページで、行動科学演習(LB63310)と計算人文社会学研究演習Ⅱ (LM23309)の授業資料を公開しています。","date":"","thumbnail":"/build/NLP_history-80702ee1d37040856a480174f5bcbbfc.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"基礎知識","level":1},{"slug":"nlp-basis2","title":"自然言語処理の基礎","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"ml-basis2","title":"機械学習の基本概念","description":"","date":"","thumbnail":"/build/supervised-learning-b5be7f5e73313e60f2c06d545c226553.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"math-basis2","title":"数学基礎","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"ニューラルネットワーク","level":1},{"slug":"nn2","title":"ニューラルネットワーク","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"backpropagation","title":"誤差逆伝播法","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"sgd","title":"学習に関するテクニック","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"PyTorch","level":1},{"slug":"pytorch2","title":"Pytorch","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"単語分散表現","level":1},{"slug":"word2vec-1","title":"単語分散表現","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"word2vec-2-embedding","title":"word2vec","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"word2vec-gensim","title":"GensimによるWord2Vecの学習と使用","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"word2vec-application","title":"Word2Vecが人文・社会科学研究における応用","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"RNN","level":1},{"slug":"rnn","title":"RNNの基礎","description":"","date":"","thumbnail":"/build/rnn-4dbf33ec81abf2baa6d5bbe97bb61683.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"lstm","title":"LSTM","description":"","date":"","thumbnail":"/build/lstm1-4ea8525c2f72b4f2ff8298a9f7b9c0be.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"pytorch-lstm","title":"LSTMの実装","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"lstm-classification","title":"LSTMによる文書分類","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"seq2seq","title":"Seq2seq","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"Transformer","level":1},{"slug":"attention","title":"Attention","description":"","date":"","thumbnail":"/build/attention-eed7f8fafc28c8cb6bd5276bbd04714b.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"self-attention","title":"Self-Attention","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"transformer","title":"Transformerアーキテクチャ","description":"","date":"","thumbnail":"/build/transformer-493148401fbb971a745b29ab5b44e10f.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"bert","title":"BERT","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"bert-sentiment","title":"BERTによるセンチメント分析","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"bert-topic","title":"BERTopic","description":"","date":"","thumbnail":"/build/7e2db436150c38a00650f96925aa5581.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"大規模言語モデル","level":1},{"slug":"gpt","title":"GPT","description":"","date":"","thumbnail":"/build/gpt_history-c08ab6ce749d3aed300b023e318cb96c.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"llm","title":"大規模言語モデルの基本","description":"","date":"","thumbnail":"/build/LLMs_parameter-ec157a4028abc601fb429210b7f4b07c.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"langchain-basic","title":"LLMSの応用(1)：Langchainの基礎","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-86A905A4.js";
import * as route0 from "/build/root-CXYA7X5D.js";
import * as route1 from "/build/routes/$-JRBPULBO.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-PCJPW7TK.js");</script></body></html>